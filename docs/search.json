[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IAB R Crash Course 2025",
    "section": "",
    "text": "Welcome!\nIntroduction to R for GradAB and IAB people.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#course-dates",
    "href": "index.html#course-dates",
    "title": "IAB R Crash Course 2025",
    "section": "Course dates",
    "text": "Course dates\n\n   24.06.2025      9:00 – 15:30    414\n   27.06.2025      9:00 – 15:30    E09",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "01_intro.html",
    "href": "01_intro.html",
    "title": "1  Getting started with R",
    "section": "",
    "text": "1.1 Installing and Setting Up R & RStudio\nR is a completely free program that you can download from CRAN. The RStudio extension is also free and can be downloaded here. RStudio enhances R by providing a significantly more informative and appealing interface, help, and auto-completion when writing syntax, as well as an overall improved user interface. However, RStudio is an extension of R, so you need both programs.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "01_intro.html#installing-and-setting-up-r-rstudio",
    "href": "01_intro.html#installing-and-setting-up-r-rstudio",
    "title": "1  Getting started with R",
    "section": "",
    "text": "Install R first and then RStudio, so that RStudio recognizes the installed R version, and the two programs usually connect automatically. R is essentially the engine, and RStudio is our cockpit. We could work directly with R, but RStudio offers a more comfortable option and a better overview.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.1: R and RStudio",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "01_intro.html#setting-up-rstudio",
    "href": "01_intro.html#setting-up-rstudio",
    "title": "1  Getting started with R",
    "section": "1.2 Setting Up RStudio",
    "text": "1.2 Setting Up RStudio\nAfter successful installation, open the RStudio application  and you should see the following view:\n\nTo avoid problems when working with R in the future, please disable the automatic saving and loading of the workspace. To do this, go to the appropriate menu under the “Tools -&gt; Global options” tab, disable “Restore .RData into workspace at startup,” and set “Save workspace to .RData on exit:” to Never. Otherwise, RStudio will save all loaded objects when you end the session and automatically load them the next time you open the program, which can lead to problems.\n\nConfirm the settings with “Apply” and close the window with “OK.”",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "01_intro.html#first-steps-in-r",
    "href": "01_intro.html#first-steps-in-r",
    "title": "1  Getting started with R",
    "section": "1.3 First Steps in R",
    "text": "1.3 First Steps in R\nAfter these basic settings, we can start with the first steps in R. To do this, first open a script by clicking on the white icon in the top left corner or pressing CTRL/Command + Shift + N simultaneously.\n\nA fourth window opens, so you should now see the following view:\n\nThis script editor is where we will create and execute commands. The script editor serves as a collection of all commands to be executed. We can save these collections to revisit them later, and, more importantly, we can share command collections with others or use scripts from others for ourselves. So, we first draft a calculation in the script editor:\n\nTo execute it, click on the line to be executed so that the cursor is in that line, and then press CTRL and Enter simultaneously (Mac users: Command and Enter):\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.2: Shortcuts for Calculations\n\n\n\nR outputs the results in the console below:\n\nThis also works for multiple calculations at once by selecting multiple lines and then pressing CTRL and Enter again (Mac users: Command and Enter):\n\nInputs from the script editor and results from the console will be presented like this in the future:\n\n2+5\n\n[1] 7\n\n3-4\n\n[1] -1\n\n5*6\n\n[1] 30\n\n7/8\n\n[1] 0.875\n\n\nOf course, R also handles longer calculations, such as following the order of operations:\n\n2+3*2\n\n[1] 8\n\n(2+3)*2\n\n[1] 10\n\n\nOther operations are also possible:\n\n4^2 ## 4²\nsqrt(4) ## Square root \nexp(1) ## Exponential function (Euler's number)\nlog(5) ## Natural logarithm\nlog(exp(5)) ## log and exp cancel each other out\n\nWe can create sequences of numbers using seq() or ::\n\n2:6\n\n[1] 2 3 4 5 6\n\nseq(2,11,3)\n\n[1]  2  5  8 11\n\n\n\n1.3.1 Creating Objects\nSo far, we have always displayed our calculations directly. For more extensive calculations—since we want to work with datasets starting in the next chapter—we want to save the intermediate steps.\nResults can be saved as objects under any name using &lt;-. R will then not display the result but will repeat the command in the console:\n\nx &lt;- 4/2\n\nIn the “Environment” window at the top right, you can now see the stored object x:\n\nWe can retrieve it later:\n\nx\n\n[1] 2\n\n\nAdditionally, we can use objects in calculations—we simply use x and create, for example, y:\n\ny &lt;- x * 5\ny\n\n[1] 10\n\n\n\n\n\n1.3.2 Storing Multiple Values\nWith c(), we can store multiple values under one object, and these can also be used in calculations:\n\nx1 &lt;- c(1,2,3)\nx1\n\n[1] 1 2 3\n\nx1* 2\n\n[1] 2 4 6\n\n\nWith length(), we can check the number of stored values:\n\nlength(x1)\n\n[1] 3\n\n\n\ny1 &lt;- c(10,11,9)\ny1\n\n[1] 10 11  9\n\ny1/x1\n\n[1] 10.0  5.5  3.0\n\n\nls() lists all existing objects, we can use the pattern = option to display only objects with a name that contains “1”:\n\nls()\n\n[1] \"path\" \"x\"    \"x1\"   \"y\"    \"y1\"  \n\nls(pattern = \"1\")\n\n[1] \"x1\" \"y1\"\n\n\n\n\n1.3.3 Deleting Values\nOf course, we can also delete objects using rm(). If we try to call a non-existent object, we will get an error message:\n\nrm(x1)\nx1\n\nError: Objekt 'x1' nicht gefunden\n\n\nWith rm(list = ls()), all objects can be removed from the environment.\n\n\n1.3.4 Saving Scripts\nWe can save the script to call it again later.\n\nIt is important to give the saved file the extension “.R”, for example, “01_Script.R”.\n\n\n1.3.5 Comments\nBesides the actual commands, comments are a central part of a data analysis syntax. This allows future users (especially ourselves in 3 weeks or 2 years) to understand what is happening. Comments in R can be added with #:\n\n2+ 5 # this is a comment\n\n[1] 7\n\n2+ # a comment can also be placed here\n  5\n\n[1] 7\n\n\n\n( 2 + # a \n    3) * # comment\n  2 # across multiple lines\n\n[1] 10\n\n\nTip: It’s best to create a folder right away where you can store all R scripts and datasets from this course.\n\n\n1.3.6 Structuring Scripts\n\n# Heading 1 ----\n\n## Section 1.1 ----\n3+2*4\n3+2*3\n## Section 1.2 ----\n3+2*sqrt(3)\n\n# Heading 2 ----\nx &lt;- c(2,6,8,2,35)\ny &lt;- seq(2,10,2)\n\ny/x",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "01_intro.html#exercises",
    "href": "01_intro.html#exercises",
    "title": "1  Getting started with R",
    "section": "1.4 Exercises",
    "text": "1.4 Exercises\n\nStore the number of students at the University of Oldenburg (15643) in stud.\nStore the number of professorships at the University of Oldenburg (210) in prof.\nCalculate the number of students per professorship at the University of Oldenburg using the objects stud and prof.\nStore the result in studprof and recall the object again!\nDo you see the created variables in the Environment window?\nStore the student numbers of the University of Bremen (19173), University of Vechta (5333), and University of Oldenburg (15643) together in studs.\nStore the number of professors at the University of Bremen (322), University of Vechta (67), and University of Oldenburg (210) together in profs.\nCalculate the number of students per professorship for all three universities.\nYou also want to include the student numbers (14000) and professorships (217) of the University of Osnabrück in studs and profs. How would you do that?\nCalculate the ratio of students to professorships for all four universities!\nDelete the object stud. How can you tell that it worked?\nDelete all objects from the Environment. How can you tell that it worked?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "02_intro.html",
    "href": "02_intro.html",
    "title": "2  Working with Datasets",
    "section": "",
    "text": "2.1 Data Structures in R: data.frame\nIn the previous chapter, we combined the student numbers of the University of Bremen (19173), University of Vechta (5333), and University of Oldenburg (15643) under studs and related them to the professor numbers stored in profs. While this works fine, it is more organized to store related values together. For this, R provides the data.frame. We can store the two objects in a dataset by entering them into data.frame and storing the new object under dat1. When we call dat1, we see that the values have been combined row by row:\nstuds &lt;- c(19173, 5333, 15643)  # Store student numbers under \"studs\"\nprofs &lt;- c(322, 67, 210)        # Store professor numbers under \"profs\"\ndat1_orig &lt;- data.frame(studs, profs)\ndat1_orig\n\n  studs profs\n1 19173   322\n2  5333    67\n3 15643   210\ndat1 &lt;- data.frame(studs = c(19173, 5333, 15643), \n                   profs = c(322, 67, 210),\n                   gegr  = c(1971, 1830, 1973)) # Without intermediate objects\ndat1    # Display the entire dataset\n\n  studs profs gegr\n1 19173   322 1971\n2  5333    67 1830\n3 15643   210 1973\nIn the first row, we see the values for the University of Bremen, in the second row for the University of Vechta, and so on. We can access the columns using dataset_name$variable_name. For example, we can display the profs column:\ndat1$profs \n\n[1] 322  67 210\nWe can display the variable/column names of the dataset with colnames()/names(). Additionally, we can call the number of rows and columns using nrow and ncol:\ncolnames(dat1) ## Display variable/column names\n\n[1] \"studs\" \"profs\" \"gegr\" \n\nnames(dat1) ## Display variable/column names\n\n[1] \"studs\" \"profs\" \"gegr\" \n\nncol(dat1) ## Number of columns/variables\n\n[1] 3\n\nnrow(dat1) ## Number of rows/cases\n\n[1] 3\nWe can add new variables to the dataset by using dataset_name$new_variable:\ndat1$stu_prof &lt;- dat1$studs/dat1$profs\n## dat1 now has one more column:\nncol(dat1) \n\n[1] 4\n\ndat1\n\n  studs profs gegr stu_prof\n1 19173   322 1971 59.54348\n2  5333    67 1830 79.59701\n3 15643   210 1973 74.49048\nWe can also store one or more words in a variable, but letters/words must always be enclosed in \"\".\ndat1$uni &lt;- c(\"Uni Bremen\", \"Uni Vechta\", \"Uni Oldenburg\")\ndat1\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2  5333    67 1830 79.59701    Uni Vechta\n3 15643   210 1973 74.49048 Uni Oldenburg\nWith View(dat1), a new window opens where we can view the entire dataset:\nView(dat1)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#data-types-in-r",
    "href": "02_intro.html#data-types-in-r",
    "title": "2  Working with Datasets",
    "section": "2.2 Data Types in R",
    "text": "2.2 Data Types in R\nSo far, we have encountered two variable types: numeric (contains numbers) and character (contains text or numbers that are understood as text). We also learned an organization method: data.frame.\nThe following variable types in R are important for us:2\n\n\n\n\n\n\n\n\n\n\n\n\nVectors (Variables)\n\n\n\n\ninteger  double\nNumeric values (numeric)\n\n\ncharacter\nText (or numbers understood as text)\n\n\nfactor\nText or numbers understood as text with predefined sorting and fixed value universe\n\n\nlogical\nTRUE or FALSE—mostly the result of a comparison (greater/less/equal)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCombined Vectors\n\n\n\n\ndata.frame  tibble\nTwo-dimensional data structure organized in tabular form—tibble is an enhancement of data.frame in the tidyverse (more on this later)\n\n\nlist\nOrdered collection of vectors of different types—can contain other value types, data.frame, or even other lists\n\n\n\n\n\n\n\nFor now, we focus on character and numeric variables. We will discuss the other types when they are needed. With class(), we can examine the type of a variable, or with is.numeric() or is.character(), we can check whether a variable belongs to a certain type:\n\nclass(dat1$profs)\n\n[1] \"numeric\"\n\nclass(dat1$uni)\n\n[1] \"character\"\n\n\nWe can enforce a type change with as.character() or as.numeric():\n\nas.character(dat1$profs) ## The \"\" indicate that the variable is defined as character\n\n[1] \"322\" \"67\"  \"210\"\n\n\nThis does not change the original variable dat1$profs:\n\nclass(dat1$profs)\n\n[1] \"numeric\"\n\n\nIf we want to keep this conversion for dat1$profs, we need to overwrite the variable:\n\ndat1$profs &lt;- as.character(dat1$profs)\nclass(dat1$profs)\n\n[1] \"character\"\n\n\nWe cannot perform calculations with character variables, even if they contain numbers:\n\ndat1$profs / 2 \n\nError in dat1$profs/2: nicht-numerisches Argument für binären Operator\n\n\nHowever, we can convert dat1$profs to numeric on the fly to perform calculations:\n\nas.numeric(dat1$profs) / 2\n\n[1] 161.0  33.5 105.0\n\n\nIf we convert text variables to numeric, calculations result in NA. NA in R stands for missing values:\n\nas.numeric(dat1$uni)\n\nWarning: NAs durch Umwandlung erzeugt\n\n\n[1] NA NA NA\n\n\nR, understandably, does not know how to convert university names into numbers.\n\n\n\n\n\n\nA common issue in calculations is due to incorrect variable types.\n\n\n\n\n2.2.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#selecting-rows-columns",
    "href": "02_intro.html#selecting-rows-columns",
    "title": "2  Working with Datasets",
    "section": "2.3 Selecting Rows & Columns",
    "text": "2.3 Selecting Rows & Columns\nA typical task when working with datasets is selecting rows (“cases”) and columns (“variables”).\nFor this, R in its base version3 provides a selection method using []. The basic structure is [row_selection, column_selection]. Leaving out the part before or after the comma selects all rows/columns. Be careful: forgetting the comma is a common source of errors in R.\n\ndat1 # complete dataset\ndat1[1,1] # first row, first column\ndat1[1,]  # first row, all columns\ndat1[,1]  # all rows, first column (equivalent to dat1$studs)\ndat1[,\"studs\"] # all rows, column named studs -&gt; note: \"\"\n\nIn these square brackets, you can also write conditions to make selections from dat1.\n\ndat1[dat1$studs &gt; 10000, ] # rows where studs is greater than 10000, all columns\ndat1[dat1$studs &gt; 10000 & dat1$profs &lt; 300, ] # & means AND\ndat1$profs[dat1$studs &gt; 10000] # Only see the number of professors: no comma\n\nRepetitive use of the dataset name in the [] makes the syntax quite long and somewhat tedious. Therefore, there is a better/more convenient solution. We use the {dplyr} package4.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#packages",
    "href": "02_intro.html#packages",
    "title": "2  Working with Datasets",
    "section": "2.4 Packages in R",
    "text": "2.4 Packages in R\nPackages are extensions for R that include additional functions, some might be familiar with Stata’s ado files. Packages need to be installed once and then loaded before use in a new session (i.e., after every restart of R/RStudio). install.packages() performs the installation, and library() loads the packages:\n\ninstall.packages(\"Package\") # only needed once on your PC\nlibrary(Package) # needed after every restart\n\nOften, when using install.packages(), not only the specified package is downloaded but also a number of other packages, the so-called “dependencies”. These are packages used in the background to enable the functions of the desired package. So don’t be surprised if the installation takes a bit longer.\nWith install.packages() we essentially screw in the light bulb in R, with library() we flip the switch so we can use the functions from the package. Each restart turns the light bulb off again, and we need to turn it back on with library(). The advantage is that we don’t have to turn on all the light bulbs at once when starting R.\n\n\n\n\n\nSource: Dianne Cook\n\n\n\n\n\n2.4.1 R packages on IAB Servers\n\n\n\n\n\n\nR Packages are typically installed from CRAN. However, this is not possible on the servers at IAB due to isolation from the internet. As a result, package installation is restricted on IAB servers to the collection maintained by DIM at N:/Ablagen/D01700-Allgemein/R/bin/windows/contrib/.\nA central challenge in installing from local zip files is handling dependencies: packages that the desired package relies on. When installing from the internet, dependencies are automatically installed, but with a local installation, this is not the case.\nAt IAB, some workarounds exist, and currently, I have a solution in progress at FDZ based on a .Rprofile file that provides the fdz_install() command, which behaves like the standard install.packages() command (or should, at least).\nThe most recent version of the .Rprofile file can be found under N:\\Ablagen\\D01700-Quickablage\\Filser\\2025-06_Rprofile.R. Place the .Rprofile file in C:\\Users\\*YOUR_USERNAME*\\Documents and restart R (CTRL + F10), you should then see a similar message in the console:\n\n----------------------------------------\nIAB-FDZ .Rprofile\nVersion 0.6\n----------------------------------------\n- Working directory:                   Z:/Eigene Dateien\n- Default package library:             Z:/R/4-4\n- HOME directory:                      C:\\Users\\FilserA001.IAB\\Documents\n- R_home directory:                    C:/PROGRA~1/R/R-4.4.0\n----------------------------------------\n\nTo make matters more comfortable, you can run this code once to copy the .Rprofile from my Quickablage into your Documents folder on the server you’re working on:\n\nfile.copy(from = \"N:/Ablagen/D01700-Quickablage/Filser/2025-06_Rprofile.R\",\n          to   = paste0(\n                    dir(path = \"C:/Users/\",\n                        pattern = Sys.getenv(\"USERNAME\"), # find correct User-Folder on C:\n                        full.names = T),\n                    \"/Documents/.Rprofile\"\n                    )\n          )\n\nHow to use Rproj to ensure reproducibilty\n\n\n\n\n\n\n\n\n\n\nLoading packages once\n\n\n\n\n\nIn addition to library(), you can also call functions from packages using :::\n\npackage::function()\n\nThis option is often used when only one function from a package is used or to clarify which package the function comes from. It can also help with issues if a command from another package has the same name—this will override the previous command (usually with a warning), which might look like:\n\nThe following objects are masked from ‘package:dplyr’:\n\n    between, first, last\n\nThe following object is masked from ‘package:purrr’:\n\n    transpose\n\nThis can be avoided by not fully loading certain packages but only calling the necessary functions with ::.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#tidyverse",
    "href": "02_intro.html#tidyverse",
    "title": "2  Working with Datasets",
    "section": "2.5 {tidyverse}",
    "text": "2.5 {tidyverse}\nIn this course, we will mainly work with packages from the {tidyverse}. The tidyverse is a collection of packages that share common syntax logic and thus harmonize particularly well and cover a broad range of use cases. With\n\ninstall.packages(\"tidyverse\")\nfdz_install(\"tidyverse\") # on IAB servers with .Rprofile\n\nthe following packages are installed:\nbroom, conflicted, cli, dbplyr, dplyr, dtplyr, forcats, ggplot2, googledrive, googlesheets4, haven, hms, httr, jsonlite, lubridate, magrittr, modelr, pillar, purrr, ragg, readr, readxl, reprex, rlang, rstudioapi, rvest, stringr, tibble, tidyr, xml2, tidyverse\nWe will get to know some of them during the course. The initially most important one is {dplyr}, which makes selecting cases and variables easier:\n\n\n\n\n\nIllustration based on the {dplyr} Cheatsheet\n\n\n\n\nBut installation is only the first step; we need to load the package with library():\n\nlibrary(tidyverse) # after once using install.packages(\"tidyverse\")\n\n\n2.5.1 Chaining Commands with %&gt;%\nIn R, dplyr and other {tidyverse} packages use %&gt;% (the pipe operator) to chain commands. This is a way to streamline commands and improve readability:\n\ndat1 %&gt;%\n  filter(studs &gt; 10000) %&gt;%\n  select(uni,studs)\n\n            uni studs\n1    Uni Bremen 19173\n2 Uni Oldenburg 15643\n\n\nHere, %&gt;% takes the output of one function and passes it as an input to the next function. This operator allows you to read and write code that closely resembles natural language. %&gt;%[^pipe] simply stands for “and then”.\n\nCall dat1 and then (%&gt;%)\nSelect only rows where studs &gt; 10000 and then (%&gt;%)\nKeep only the uni column\n\n\ndat1 %&gt;% filter(.,studs &gt; 10000) %&gt;% select(.,uni) # the dot represents the result of the previous step\n\nUsually it’s written just like this\n\ndat1 %&gt;% filter(studs &gt; 10000) %&gt;% select(uni)\n\n            uni\n1    Uni Bremen\n2 Uni Oldenburg\n\n\n\n\n\n\n\n\nThe shortcut for %&gt;% is STRG+SHIFT+m (cmd+shift+m on Mac)\n\n\n\nLet’s a have a closer look at filter() and select():\n\n\n2.5.2 Selecting Observations with filter()\nWith filter(), we can select rows from dat1 based on conditions:\n\ndat1 %&gt;% filter(uni == \"Uni Oldenburg\", studs &gt; 1000)\n\n  studs profs gegr stu_prof           uni\n1 15643   210 1973 74.49048 Uni Oldenburg\n\n\nThe selection does not change the original object dat1:\n\ndat1\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2  5333    67 1830 79.59701    Uni Vechta\n3 15643   210 1973 74.49048 Uni Oldenburg\n\n\nIf we want to keep the result of our selection with filter() for further steps, we can store it in a new data.frame object:\n\nover_10k &lt;- filter(dat1, studs &gt; 10000)\nover_10k\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2 15643   210 1973 74.49048 Uni Oldenburg\n\n\n\n\n\n\n\n\nfilter() helpers\n\n\n\n\n\n{dplyr} provides a number of helpers for filter():\n\ngreater/smaller than or equal to: &lt;= &gt;=\nor: |\none of: %in%\nwithin a given range: between()\n\n\nfilter(dat1, studs &gt;= 10000)\nfilter(dat1, studs &lt;= 10000)\nfilter(dat1,studs &gt; 10000 | profs &lt; 200) # more than 10.000 Students *or* less than 200 professors\nfilter(dat1, gegr %in% c(1971,1830)) # founded 1971 or 1830\nfilter(dat1, between(gegr,1971,1830)) # founded between 1971 and 1830 (including)\n\n\n\n\n\n\n2.5.3 Selecting variables with select()\nselect() allows us to select specific columns:\n\ndat1 %&gt;% select(uni,studs) # columns uni and studs\n\n            uni studs\n1    Uni Bremen 19173\n2    Uni Vechta  5333\n3 Uni Oldenburg 15643\n\n\n\ndat1 %&gt;% select(1:3) # column 1-3\n\n  studs profs gegr\n1 19173   322 1971\n2  5333    67 1830\n3 15643   210 1973\n\ndat1 %&gt;% select(-profs) # all but profs\n\n  studs gegr stu_prof           uni\n1 19173 1971 59.54348    Uni Bremen\n2  5333 1830 79.59701    Uni Vechta\n3 15643 1973 74.49048 Uni Oldenburg\n\n\n\n\n\n\n\n\nselect() helpers\n\n\n\n\n\n\ncontains(\"b\"): Variable name contains ...,\nmatches(): Variable selection using regular expressions\n\n\ndat1 %&gt;% select(contains(\"s\")) # all variables containing s\ndat1 %&gt;% select(matches(\"s$\")) # all variables ending on s\n\n\n\n\n\n\n2.5.4 Selecting Rows with slice()\nA first function from {tidyverse} is slice(), which allows us to select rows:\n\nslice(dat1,1) # first row\nslice(dat1,2:3) # rows 2-3\nslice(dat1,c(1,3)) # rows 1 and 3\n\n\n\n2.5.5 Sorting data with arrange()\nAnother common task in data analysis is sorting datasets. For this, we use arrange():\n\ndat1 %&gt;% arrange(studs)\n\n  studs profs gegr stu_prof           uni\n1  5333    67 1830 79.59701    Uni Vechta\n2 15643   210 1973 74.49048 Uni Oldenburg\n3 19173   322 1971 59.54348    Uni Bremen\n\n\nThis also works for string variables:\n\ndat1 %&gt;% arrange(uni)\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2 15643   210 1973 74.49048 Uni Oldenburg\n3  5333    67 1830 79.59701    Uni Vechta\n\n\nOf course, we can also sort by multiple variables; we just add more to arrange() and we can sort in descending order using desc():\n\ndat1 %&gt;% arrange(desc(gegr), studs)\n\n  studs profs gegr stu_prof           uni\n1 15643   210 1973 74.49048 Uni Oldenburg\n2 19173   322 1971 59.54348    Uni Bremen\n3  5333    67 1830 79.59701    Uni Vechta\n\n\n(This doesn’t make much sense in this example.)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#variable-type-factor",
    "href": "02_intro.html#variable-type-factor",
    "title": "2  Working with Datasets",
    "section": "2.6 Variable type factor",
    "text": "2.6 Variable type factor\nBut what if we want to assign a specific order that doesn’t follow numeric or alphabetical order? For example, if we want to order the universities as follows: 1) Uni Oldenburg, 2) Uni Bremen, and 3) Uni Vechta.\nThis is where a third variable type comes in: factor.\nWith the levels = argument, we can define an order:\n\nfactor(dat1$uni, levels = c(\"Uni Oldenburg\", \"Uni Bremen\", \"Uni Vechta\"))\n\n[1] Uni Bremen    Uni Vechta    Uni Oldenburg\nLevels: Uni Oldenburg Uni Bremen Uni Vechta\n\ndat1$uni_fct &lt;- factor(dat1$uni, \n                       levels = c(\"Uni Oldenburg\", \"Uni Bremen\", \"Uni Vechta\"))\n\nIf we now sort by uni_fct, the order of the levels is respected:\n\nclass(dat1$uni_fct)\n\n[1] \"factor\"\n\ndat1 %&gt;% arrange(uni_fct)\n\n  studs profs gegr stu_prof           uni       uni_fct\n1 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n2 19173   322 1971 59.54348    Uni Bremen    Uni Bremen\n3  5333    67 1830 79.59701    Uni Vechta    Uni Vechta\n\n\nThis may seem trivial at the moment but is very useful later for ordering variables in plots or setting the reference category in regression models.\nWe can use the levels = and labels = for a lazy recode:\n\ndat1$gegr_fct &lt;- factor(dat1$gegr,\n                       levels = c(1830,1971,1973) ,\n                       labels = c(\"early\",\"70s\",\"70s\")) # labels do not need to be unique\ndat1\n\n  studs profs gegr stu_prof           uni       uni_fct gegr_fct\n1 19173   322 1971 59.54348    Uni Bremen    Uni Bremen      70s\n2  5333    67 1830 79.59701    Uni Vechta    Uni Vechta    early\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg      70s\n\ndat1 %&gt;% arrange(desc(gegr_fct))\n\n  studs profs gegr stu_prof           uni       uni_fct gegr_fct\n1 19173   322 1971 59.54348    Uni Bremen    Uni Bremen      70s\n2 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg      70s\n3  5333    67 1830 79.59701    Uni Vechta    Uni Vechta    early\n\ndat1 %&gt;% arrange(desc(gegr_fct),gegr)\n\n  studs profs gegr stu_prof           uni       uni_fct gegr_fct\n1 19173   322 1971 59.54348    Uni Bremen    Uni Bremen      70s\n2 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg      70s\n3  5333    67 1830 79.59701    Uni Vechta    Uni Vechta    early\n\n\n\n2.6.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#rproj",
    "href": "02_intro.html#rproj",
    "title": "2  Working with Datasets",
    "section": "2.7 Setting up a project",
    "text": "2.7 Setting up a project\nIn general, it’s worth setting up projects in RStudio. Projects are .Rproj files  that automatically set the working directory to where they are saved. This simplifies collaborative work: no matter who is working on a project or on which device, the project file ensures all paths are always relative to the project directory. Furthermore, version control via git, e.g., github, and other functions can be set in the project file for all users. Also, the last open scripts remain open, making it easier to work on multiple projects.\n\n\n\n\n\n\n\n\n\nWith getwd(), we can check if it worked:\n\ngetwd()\n\n\n\n[1] \"D:/Courses/R-Course\"\n\n\n\n\n\n\n\n\n\n\n\nAlternatively, we could create an .Rproj project with the following command (here’s an example of calling a package with ::):\n\nrstudioapi::initializeProject(path = \"D:/Courses/R-Course\")\n\nWe can open the project with:\n\nrstudioapi::openProject(path = \"D:/Courses/R-Course\")\n\n\n2.7.1 💡 Using projects to ensure reproducibility\nR-Projects are a great way to organize your work and help to ensure reproducibility in conjunction with the FDZ .Rprofile:\nBy default, the .Rprofile stores all packages installed via fdz_install() in your personal Documents folder on Z:, as you can see in the startup message in the path displayed as Default package library:\n\n- Default package library:             Z:/R/4-4\n\nYou can check the directory where your library is kept using .libPaths() - R will install new packages in the first directory listed here.\nThis has the disadvantage that you might overwrite packages when working on different projects. In the worst case, you could break code from older projects when updating to a newer version of a package. You’ll have to track down the original package version when you’re trying to re-run code from the older project.\n⚠️ This can be extremely painful and make you question what life decisions brought you here.\nTherefore, I recommend setting up a project-specific .RProfile for projects that require reprodicibility:\n1️⃣ Copy the .Rprofile to your project root directory\n\nfile.copy(from = paste0(\n                    dir(path = \"C:/Users/\",\n                        pattern = Sys.getenv(\"USERNAME\"), # find correct User-Folder on C:\n                        full.names = T),\n                    \"/Documents/.Rprofile\"\n                    ),\n          to = \".\"\n          )\n\n2️⃣️ amend the first few lines so that packages are loaded and installed from within the project folder by modifying lines 11-19:\n\nlibdir &lt;- \n  paste0(\n    \"Z:/R/\",         # redirects library/fdz_install to Z:/R/\n    R.version$major, # major Version\n    \"-\",\n    sub(R.version$minor, pattern = \"\\\\..+\", replacement = \"\") # minor version\n  )\n\nFor instance, you could set a relative path to a subdirectory called “library” in your project:\n\nlibdir &lt;- \n  paste0(\n    \"./library/\",    # adjust path here\n    R.version$major, # major Version\n    \"-\",\n    sub(R.version$minor, pattern = \"\\\\..+\", replacement = \"\") # minor version\n  )\n\nThis will result in your packages being stored in path/to/your/project/library/RX-Y with X-Y being the R version. The downside of this approach is that you’ll need to (re-)install the packages you’re using for your project, and storing identical packages in multiple directories can be inefficient in terms of memory usage.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#import",
    "href": "02_intro.html#import",
    "title": "2  Working with Datasets",
    "section": "2.8 Importing datasets",
    "text": "2.8 Importing datasets\nIn most cases, we’ll use datasets that are already saved in a file and just need to be imported. There are countless ways to do this.\nIn this seminar, we’ll work with the Campus-File of PASS, whose parts are available as Stata files.\nTo import the dataset into R, we need to tell R the file path where the dataset is located. The file path depends on your device’s folder structure; in this case, it would be “D:/Courses/R-Course/”.\nOf course, the file path depends on where you saved the dataset:\n\n\n\n\n\n\n\n\n\nWe need to inform R of this file path.\n\n2.8.1 The import command\nNow we can use the actual import command read.table. For the path, we can just enter the quotation marks after file = and press the Tab key. Then we’ll see all subdirectories and tables in the project folder.5\n\nlibrary(haven)\npend &lt;- read_dta(\"./orig/PENDDAT_cf_W13.dta\") \n\nThe import process consists of two parts: first, we specify the object name as pend, under which R will store the dataset. After the &lt;- is the actual read_dta() command, which contains several options. First, we specify the exact dataset name, including the file extension.\n\n\n\n\n\n\nR has problems with Windows-style \\ in file paths\n\n\n\n\n\nUnfortunately, Windows systems use \\ in file paths, which causes problems in R. Therefore, file paths must always be specified with / or alternatively with \\\\. RStudio can help a bit with the CTRL + F/Search & Replace function.\n\n\n\nThe object created is a data.frame:\n\nclass(pend)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nTechnically, it’s a tibble—an enhanced version of data.frame in the tidyverse that includes labels and provides additional information in its display, such as variable classes in the first row.\nIf we were to simply type pend here, the entire dataset would be displayed. For an overview, we can use head:\n\nhead(pend)\n\n# A tibble: 6 × 123\n         pnr      hnr welle   pintjahr pintmon pintmod  zpsex   palter PD0400   \n       &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl+l&gt; &lt;dbl+lb&gt; &lt;dbl+l&gt; &lt;dbl+lb&gt; &lt;dbl+l&gt; &lt;dbl+&gt; &lt;dbl+lbl&gt;\n1 1000001901 10000019 1 [Wav… 2007     5 [May]  1 [CAP… 2 [Fem… 36       2 [Rat…\n2 1000001902 10000019 1 [Wav… 2007     5 [May] NA       1 [Mal… 39       2 [Rat…\n3 1000001901 10000019 3 [Wav… 2009     3 [Mar…  1 [CAP… 2 [Fem… 38      -9 [Ite…\n4 1000002001 10000020 1 [Wav… 2007     4 [Apr…  1 [CAP… 1 [Mal… 66     -10 [Ite…\n5 1000002002 10000020 1 [Wav… 2007     4 [Apr…  1 [CAP… 2 [Fem… 61       3 [Rat…\n6 1000002002 10000020 2 [Wav… 2008     5 [May]  1 [CAP… 2 [Fem… 62       3 [Rat…\n# ℹ 114 more variables: PA0100 &lt;dbl+lbl&gt;, PA0200 &lt;dbl+lbl&gt;, PA0300 &lt;dbl+lbl&gt;,\n#   PA0445 &lt;dbl+lbl&gt;, PA0800 &lt;dbl+lbl&gt;, PA0900 &lt;dbl+lbl&gt;, PA1000 &lt;dbl+lbl&gt;,\n#   PSM0100 &lt;dbl+lbl&gt;, PEO0100a &lt;dbl+lbl&gt;, PEO0100b &lt;dbl+lbl&gt;,\n#   PEO0100c &lt;dbl+lbl&gt;, PEO0100d &lt;dbl+lbl&gt;, PEO0100e &lt;dbl+lbl&gt;,\n#   PEO0200a &lt;dbl+lbl&gt;, PEO0200b &lt;dbl+lbl&gt;, PEO0200c &lt;dbl+lbl&gt;,\n#   PEO0200d &lt;dbl+lbl&gt;, PEO0300a &lt;dbl+lbl&gt;, PEO0300b &lt;dbl+lbl&gt;,\n#   PEO0300c &lt;dbl+lbl&gt;, PEO0300d &lt;dbl+lbl&gt;, PEO0300e &lt;dbl+lbl&gt;, …\n\n\nWith nrow and ncol, we can check if it worked. The dataset should have 28424 rows and 123 columns:\n\nnrow(pend)\n\n[1] 28424\n\nncol(pend)\n\n[1] 123\n\n\nOf course, we can also select rows and columns from this much larger dataset as we did before. For example, we can select the data from 2006 and store it under pend06:\n\npend06 &lt;- pend %&gt;% filter(pintjahr == 2006)\n\nNaturally, pend06 has significantly fewer rows than pend:\n\nnrow(pend06)\n\n[1] 168\n\n\nIf we want to see the exact ages of the respondents from pend06, we can call up the corresponding column with pend06$palter:\n\npend06$palter\n\n&lt;labelled&lt;double&gt;[168]&gt;: Age (W1: gen. from P1; W2 ff.: best info.), gen.\n  [1] 71 66 64 64 63 51 64 65 26 38 41 63 58 58 69 45 59 37 28 63 56 29 29 49 47\n [26] 66 34 22 21 37 36 58 56 80 44 65 61 66 40 53 34 70 69 54 65 62 58 54 51 57\n [51] 72 52 25 34 55 44 68 73 46 87 74 83 46 40 62 58 66 41 53 71 66 79 54 42 68\n [76] 68 81 92 70 66 68 77 44 66 66 67 62 43 35 35 52 54 20 48 48 20 41 24 22 33\n[101] 55 41 50 36 19 52 25 36 37 29 37 36 43 49 16 59 28 19 43 44 30 43 50 50 53\n[126] 52 71 43 58 58 58 38 49 30 27 50 58 26 36 44 28 19 42 44 23 20 33 24 31 32\n[151] 31 44 50 58 45 57 37 62 46 52 50 47 40 62 40 19 28 35\n\nLabels:\n value                                      label\n   -10 Item not surveyed in questionnaire version\n    -9                  Item not surveyed in wave\n    -8                          Implausible value\n    -4              Question mistakenly not asked\n    -3                    Not applicable (filter)\n    -2                            Details refused\n    -1                                 Don't know\n\n\nAs we’ve seen, there are many more variables in PASS than just palter, and not all have such meaningful names—like PD0400. To understand these variable names and the meaning of the values, we need the codebook.\nWe can also access a variable’s attributes()—more on labels later.\n\n\n2.8.2 Exercise",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#exporting-objects",
    "href": "02_intro.html#exporting-objects",
    "title": "2  Working with Datasets",
    "section": "2.9 Exporting objects",
    "text": "2.9 Exporting objects\n\n\n\n\n\n\nThe term save can sometimes lead to misunderstandings in R: does it mean\n\nsaving a dataset or other object to disk as .csv, .dta, .sav for access by other programs, or\nsimply storing the results internally in R under an object name?\n\nI avoid the word save and instead speak of exporting (Case 1: writing to a file) or storing (Case 2: storing results/values within R in an object).\n\n\n\nThe proprietary format in R for exporting data.frames and reloading afterwards is .RData (comparable to dta in Stata):\n\nsaveRDS(pend06, file = \"./data/pend06.RData\")\nrm(pend06) # delete pend06 from memory\n\npend06_neu &lt;- readRDS(file = \"./data/pend06.RData\")\nhead(pend06) # does not exist anymore -&gt; rm()\n\nError: Objekt 'pend06' nicht gefunden\n\nhead(pend06_neu,n=1)\n\n# A tibble: 1 × 123\n         pnr      hnr welle   pintjahr pintmon  pintmod zpsex   palter PD0400   \n       &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl+l&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+&gt; &lt;dbl+lbl&gt;\n1 1000402601 10004026 1 [Wav… 2006     12 [Dec… 0 [CAT… 1 [Mal… 71     -10 [Ite…\n# ℹ 114 more variables: PA0100 &lt;dbl+lbl&gt;, PA0200 &lt;dbl+lbl&gt;, PA0300 &lt;dbl+lbl&gt;,\n#   PA0445 &lt;dbl+lbl&gt;, PA0800 &lt;dbl+lbl&gt;, PA0900 &lt;dbl+lbl&gt;, PA1000 &lt;dbl+lbl&gt;,\n#   PSM0100 &lt;dbl+lbl&gt;, PEO0100a &lt;dbl+lbl&gt;, PEO0100b &lt;dbl+lbl&gt;,\n#   PEO0100c &lt;dbl+lbl&gt;, PEO0100d &lt;dbl+lbl&gt;, PEO0100e &lt;dbl+lbl&gt;,\n#   PEO0200a &lt;dbl+lbl&gt;, PEO0200b &lt;dbl+lbl&gt;, PEO0200c &lt;dbl+lbl&gt;,\n#   PEO0200d &lt;dbl+lbl&gt;, PEO0300a &lt;dbl+lbl&gt;, PEO0300b &lt;dbl+lbl&gt;,\n#   PEO0300c &lt;dbl+lbl&gt;, PEO0300d &lt;dbl+lbl&gt;, PEO0300e &lt;dbl+lbl&gt;, …\n\n\nWe can also export and restore other objects. However, we need to load() them, which will result in restoring the previous object name:\n\nsave(studs, file = \"./data/stud_vektor.RData\")\nrm(studs)\nstuds\nload(file = \"./data/stud_vektor.RData\") # studs is back with the same object name\nstuds\n\nThis also works for multiple Objects:\n\nsave(studs,profs, file = \"./data/meine_vektoren.RData\")\nrm(studs,profs)\nstuds\nprofs\nload(file = \"./data/meine_vektoren.RData\") # studs & profs restored with the same name\nstuds\nprofs\n\n\n2.9.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#overview-importing-and-exporting-data-sets",
    "href": "02_intro.html#overview-importing-and-exporting-data-sets",
    "title": "2  Working with Datasets",
    "section": "2.10 Overview: Importing and exporting data sets",
    "text": "2.10 Overview: Importing and exporting data sets\n\nImport optionsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\nfile type\nR function\nR package\nComment\n\n\n\n\n.csv\nread.table()\n-\nset delimiter with `sep = \";\"`\n\n\n.Rdata (R format)\nreadRDS\n-\n\n\n\ngroße .csv\nvroom()\n{vroom}\nset delimiter using `delim = \";\"`\n\n\n.dta (Stata)\nread_dta()\n{haven}\n\n\n\n.dta (Stata - große Dateien)\nread.dta13()\n{readstata13}\nuse convert.factors = F to import only numeric values\nalso imports files from newer Stata versions\n\n\n.dat (SPSS)\nread_spss()\n{haven}\n\n\n\n.xlsx (Excel)\nread_xlsx()\n{readxl}\nuse `sheet = 1`to specifiy which sheet you want\n\n\n\n\n\n\n\n\n\n\n# csv file\ndat1 &lt;- read.table(file = \"Dateiname.csv\",sep = \";\")\n\n# Rdata\ndat1 &lt;- readRDS(file = \"Dateiname.Rdata\")\n\n# large csv\nlibrary(vroom)\ndat1 &lt;- vroom(file = \"Dateiname.csv\",delim = \";\")\n\n# Stata dta\nlibrary(haven)\ndat1 &lt;- read_dta(file = \"Dateiname.dta\")\n\n# Stata large files\n# faster than read_dta(), but without labels\nlibrary(readstata13)\ndat1 &lt;- read.dta13(file = \"Dateiname.dta\",convert.factors = F) \n\n# SPSS sav\ndat1 &lt;- read_sav(file = \"Dateiname.sav\")\n\n# Excel\ndat1 &lt;- read_xlsx(path = \"Dateiname.xlsx\", sheet = \"1\")\ndat1 &lt;- read_xlsx(path = \"Dateiname.xlsx\", sheet = \"Tabellenblatt1\")\n\n\n\n\n\nExport optionsCode\n\n\n\n\n\n\n\nfile type\nR function\nR package\nComment\n\n\n\n\n.Rdata (R format)\nsaveRDS()\n-\nall variable properties remain\n\n\n.csv\nwrite.table()\n-\nuse `sep = \";\"` to set delimiter br&gt;use row.names= F to suppress row numbering\n\n\n.dta (Stata)\nwrite_dta()\n{haven}\n\n\n\n.dat (SPSS)\nwrite_spss()\n{haven}\n\n\n\n.xlsx (Excel)\nwrite.xlsx()\n{xlsx}\nuse `sheetName` to select excel sheet\n\n\n\n\n\n\n\n\n\n\n# Rdata\nsaveRDS(dat1,file = \"Dateiname.Rdata\")\n# csv\nwrite.table(dat1,file = \"Dateiname.csv\",sep = \";\",row.names = F)\n# dta\nlibrary(haven)\nwrite_dta(dat1,path = \"Dateiname.dta\")\n# sav\nlibrary(haven)\nwrite_sav(dat1,path = \"Dateiname.sav\")\n# xlsx\nlibrary(xlsx)\nwrite.xlsx(dat1,file = \"Dateiname.xlsx\", sheetName = \"Tabellenblatt 1\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#getting-help",
    "href": "02_intro.html#getting-help",
    "title": "2  Working with Datasets",
    "section": "2.11 Getting help",
    "text": "2.11 Getting help\nR packages (often) come with very detailed help pages, which can either be called up directly from RStudio:\n\n# help for packages\nvignette(\"dplyr\")\nvignette(package = \"dplyr\")\nvignette(\"rowwise\")\nhelp(\"dplyr\")\nhelp(package = \"dplyr\")\n\n\n# help for a specific function\n?select()\n\nAlternatively, googling the package and function mostly gives you what you need R dplyr select()\nOr refer to the CRAN site:\n\n\n\n\n\nCRAN-Seite für {dplyr}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#exercises",
    "href": "02_intro.html#exercises",
    "title": "2  Working with Datasets",
    "section": "2.12 Exercises",
    "text": "2.12 Exercises\n\n2.12.1 Exercise 1\n\nCreate a data.frame object called dat2:\n\n\ndat2 &lt;- data.frame(studs = c(14954,47269 ,23659,9415 ,38079), \n                   profs = c(250,553,438 ,150,636),\n                   prom_recht = c(FALSE,TRUE,TRUE,TRUE,FALSE),\n                   gegr  = c(1971,1870,1457,1818,1995))\n\n\nDo you see dat2 in your environment?\nPrint dat2 in the console.\nAdd the names of the universities as a new column to the dataset. The names are in this order:\n\n\nc(\"FH Aachen\",\"RWTH Aachen\",\"Uni Freiburg\",\"Uni Bonn\",\"FH Bonn-Rhein-Sieg\")\n\n[1] \"FH Aachen\"          \"RWTH Aachen\"        \"Uni Freiburg\"      \n[4] \"Uni Bonn\"           \"FH Bonn-Rhein-Sieg\"\n\n\n\nDisplay dat2 - either in the console or using View().\nCalculate the ratio of students per professor and store the results in a new variable. Check the result.\nDisplay only the third row of dat2.\nDisplay only the third column of dat2.\n\nWhat would you do to copy dat2 into an object called df_unis?\nBack to top\n\n\n\n2.12.2 Exercise 2\n\nCreate a .Rprofile for the package installation in C:\\Users\\*USERNAME*\\Documents.\nInstall the tidyverse packages using fdz_install(\"tidyverse\") after placing the .Rprofile file under C:\\Users\\*USERNAME*\\Documents.\nUse the data.frame dat2 from Exercise 1.\nUse filter to display only the universities with fewer than 10,000 students. (Remember to install and load {tidyverse} with library()).\nDisplay the founding years (gegr) column of universities with the right to award doctorates (prom_recht).\n\nBack to top\n\n\n\n2.12.3 Exercise 3\n\nContinue using the dataset from Exercises 1 & 2 (dat2)\nDisplay only the universities that were founded in 1971, 1457, or 1995, and for these cases, show only the name and founding year.\nSort the dataset according to the following order. (Create a factor variable that defines this order.)\n\n\nc(\"RWTH Aachen\", \"Uni Freiburg\", \"Uni Bonn\", \"FH Aachen\", \"FH Bonn-Rhein-Sieg\")\n\n[1] \"RWTH Aachen\"        \"Uni Freiburg\"       \"Uni Bonn\"          \n[4] \"FH Aachen\"          \"FH Bonn-Rhein-Sieg\"\n\n\nBack to top\n\n\n\n2.12.4 Exercise 4\n\nCreate an R project in your directory for this course.\nSave the personal data from the PASS-CampusFile (PENDDAT_cf_W13.dta) in your directory in the subfolder orig.\nRead the dataset PENDDAT_cf_W13.dta as shown above into R and assign it to the object name pend.\nUse head() and View() to get an overview of the dataset.\nHow many entries (rows) does the dataset contain?\nDisplay the variable names of pend using names()!\nHow old is the respondent with the pnr 1000908201 in welle 10 (in pintjahr 2016)?\nDisplay the wave (welle) and age (palter) of respondent with the pnr 1000908201?\nStore the resulting data.frame in an object, e.g. resp_1000908201.\n\nBack to top\n\n\n\n2.12.5 Exercise 5\n\nExport the data.frame resp_1000908201 created in the previous exercise as an .Rdata file.\nLoad the exported .Rdata file under a different name, e.g., resp_1000908201_new.\nDid everything work? Compare the newly loaded object with the original one: identical(resp_1000908201, resp_1000908201_new) - are both objects identical?\n\nBack to top",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#appendix",
    "href": "02_intro.html#appendix",
    "title": "2  Working with Datasets",
    "section": "2.13 Appendix",
    "text": "2.13 Appendix\n\n2.13.1 Alternatives to R Projects\nBesides setting up a project, you can also set the path using setwd() or directly specify it within read_dta() or other read...() commands. However, this approach is less portable to other machines. When someone else opens the .Rproj file, R automatically sets paths relative to the file’s location. This is also true if the directory is moved on your device—R will automatically adjust the working directory.\nTo set the working directory with setwd(), insert the folder path within the parentheses. Make sure to replace any \\ with /:\n\nsetwd(\"D:/Kurse/R_IAB\")\n\nYou can check if it worked with getwd():\n\ngetwd()\n\nThe path you set with setwd() should appear.\nAlternatively, you can provide the full path directly in read_dta():\n\npend &lt;- haven::read_dta(\"C:/Kurse/R_IAB/orig/PENDDAT_cf_W13.dta\")\n\n\n\n2.13.2 Selecting Rows & Columns Without {dplyr}\nBase R (without extensions like {dplyr}) can also filter datasets using square brackets []:\n\ndat1[1, 1] # first row, first column\n\n[1] 19173\n\ndat1[1, ]  # first row, all columns\n\n  studs profs gegr stu_prof        uni    uni_fct gegr_fct\n1 19173   322 1971 59.54348 Uni Bremen Uni Bremen      70s\n\ndat1[, 1]  # all rows, first column (equivalent to dat1$studs)\n\n[1] 19173  5333 15643\n\ndat1[, \"studs\"] # all rows, column named studs -&gt; note the \"\"\n\n[1] 19173  5333 15643\n\n\nYou can also select multiple rows or columns by using c():\n\ndat1[c(1, 2), ]  ## 1st & 2nd row, all columns\ndat1[, c(1, 3)]  ## all rows, 1st & 3rd column (equivalent to dat1$studs & dat1$stu_prof)\ndat1[, c(\"studs\", \"uni\")] ## all rows, columns named studs and uni\n\nYou can also write conditions in these square brackets to make selections from dat1.\n\ndat1 # full dataset\n\n  studs profs gegr stu_prof           uni       uni_fct gegr_fct\n1 19173   322 1971 59.54348    Uni Bremen    Uni Bremen      70s\n2  5333    67 1830 79.59701    Uni Vechta    Uni Vechta    early\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg      70s\n\ndat1[dat1$uni == \"Uni Oldenburg\", ] # Rows where uni equals \"Uni Oldenburg\", all columns\n\n  studs profs gegr stu_prof           uni       uni_fct gegr_fct\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg      70s\n\ndat1$studs[dat1$uni == \"Uni Oldenburg\"] # Just check the student count: no comma needed\n\n[1] 15643\n\n\nThis works as expected, and we can expand it:\n\ndat1[dat1$uni == \"Uni Oldenburg\" & dat1$studs &gt; 10000, ] # & means AND\n\n  studs profs gegr stu_prof           uni       uni_fct gegr_fct\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg      70s\n\n\nYou can also use the OR operator:\n\ndat1[dat1$uni == \"Uni Oldenburg\" | dat1$studs &gt; 10000, ]\n\n  studs profs gegr stu_prof           uni       uni_fct gegr_fct\n1 19173   322 1971 59.54348    Uni Bremen    Uni Bremen      70s\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg      70s\n\n\n\n\n2.13.3 select() vs $\nWhen you use select() to pick a specific variable, it preserves the data structure as a data.frame(), whereas dat1$variablename extracts the column as a vector (a series of values):\n\ndat1$studs\n\n[1] 19173  5333 15643\n\nclass(dat1$studs)\n\n[1] \"numeric\"\n\ndat1$studs / 20\n\n[1] 958.65 266.65 782.15\n\n\nselect() keeps the values as a column in a data.frame:\n\ndat1 %&gt;% select(studs)\n\n  studs\n1 19173\n2  5333\n3 15643\n\ndat1 %&gt;% select(studs) %&gt;% class()\n\n[1] \"data.frame\"\n\ndat1 %&gt;% select(studs) / 20\n\n   studs\n1 958.65\n2 266.65\n3 782.15",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "02_intro.html#footnotes",
    "href": "02_intro.html#footnotes",
    "title": "2  Working with Datasets",
    "section": "",
    "text": "In many other programming languages, these are called libraries.↩︎\nThere are more, and this enumeration ignores technical details—for an advanced introduction to vectors in R, click here.↩︎\nWe will see soon how packages can make working in R easier.↩︎\nIt has become common in the R community to write packages with {} to distinguish them more clearly from functions. I follow this convention in this script.↩︎\nSometimes the dataset is not in the project’s subfolder, in which case the entire path can be specified in read_dta(): pend &lt;- read_dta(file = \"D:/Courses/R-Course/data/PENDDAT_cf_W13.dta\")↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with Datasets</span>"
    ]
  },
  {
    "objectID": "03_desc.html",
    "href": "03_desc.html",
    "title": "3  Getting an Overview",
    "section": "",
    "text": "3.1 Frequency Counts\nWe have various commands available to create a frequency count:\nThe simplest command for counting frequencies is the table() command. For example, with the variable statakt representing the education status of respondents:\ntable(pend$statakt)\n\n\n -10   -9   -5    1    2    3 \n3765 3289  280 9470 6139 5481\nHere, we see the absolute frequencies displayed. The first row lists the different values, and the second row shows the frequencies.\nHowever, the labels are ignored in the output of table(). A look into the PASS data report or using attributes() reveals the value labels:\nattributes(pend$statakt)$labels\n\n    Item not surveyed in questionnaire version \n                                           -10 \n                     Item not surveyed in wave \n                                            -9 \n          Cannot be generated (missing values) \n                                            -5 \nIn occupation with earnings &gt;400 EUR per month \n                                             1 \n                        Unemployed, registered \n                                             2 \n                        Pupil/student (school) \n                                             3 \n                       Apprenticeship/Studying \n                                             4 \n                  Military or civilian service \n                                             5 \n                  Carrying out domestic duties \n                                             6 \n           Maternity protection/parental leave \n                                             7 \n                    Pensioner/early retirement \n                                             8 \n                                         Other \n                                             9 \n         Unemployed, not registered (since W4) \n                                            10 \n                Ill/unfit to work/unemployable \n                                            11 \n                   Self-employed/family worker \n                                            12\n9470 respondents are employed, 5481 respondents are inactive, etc. (More on labels and working with value labels in R later.)\nWith count() from {dplyr}, we get the labels displayed directly. Again, we use the pipe %&gt;%:\npend %&gt;% count(statakt)\n\n# A tibble: 6 × 2\n  statakt                                                  n\n  &lt;dbl+lbl&gt;                                            &lt;int&gt;\n1 -10 [Item not surveyed in questionnaire version]      3765\n2  -9 [Item not surveyed in wave]                       3289\n3  -5 [Cannot be generated (missing values)]             280\n4   1 [In occupation with earnings &gt;400 EUR per month]  9470\n5   2 [Unemployed, registered]                          6139\n6   3 [Pupil/student (school)]                          5481\nWe can also store tables under a freely chosen name and call them up later:\nt1 &lt;- table(pend$statakt)\nt2 &lt;- pend %&gt;% count(statakt)\nWe see here that the table with table() creates a new object form, a table. With count(), however, a data.frame is created.\nclass(t1)\n\n[1] \"table\"\n\nclass(t2)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#frequency-counts",
    "href": "03_desc.html#frequency-counts",
    "title": "3  Getting an Overview",
    "section": "",
    "text": "table()\ncount() from {dplyr}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#NA03",
    "href": "03_desc.html#NA03",
    "title": "3  Getting an Overview",
    "section": "3.2 Missing Values in R: NA",
    "text": "3.2 Missing Values in R: NA\nNegative values are a bit annoying.\nTo mark the values like -5 as missing data in R, we need to set them to NA in pend. To do this, we call pend$statakt and filter with [] only the values for statakt equal to -1. In the previous chapter, we learned how to call specific values this way:\n\npend$statakt[pend$statakt == -5] # only call statakt = -5\n\n&lt;labelled&lt;double&gt;[280]&gt;: Current main occupation, gen. (since W2)\n  [1] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n [26] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n [51] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n [76] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[101] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[126] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[151] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[176] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[201] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[226] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[251] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[276] -5 -5 -5 -5 -5\n\nLabels:\n value                                          label\n   -10     Item not surveyed in questionnaire version\n    -9                      Item not surveyed in wave\n    -5           Cannot be generated (missing values)\n     1 In occupation with earnings &gt;400 EUR per month\n     2                         Unemployed, registered\n     3                         Pupil/student (school)\n     4                        Apprenticeship/Studying\n     5                   Military or civilian service\n     6                   Carrying out domestic duties\n     7            Maternity protection/parental leave\n     8                     Pensioner/early retirement\n     9                                          Other\n    10          Unemployed, not registered (since W4)\n    11                 Ill/unfit to work/unemployable\n    12                    Self-employed/family worker\n\n\n(Here, we get the labels again, which is somewhat suboptimal for clarity.)\nIf we then assign a new value with &lt;-, the called values will be overwritten - here, we overwrite all values for statakt == -1 with NA:\n\npend$statakt[pend$statakt == -5]  &lt;- NA\n\nHowever, we have not yet overwritten all the negative values; -10 and -9 are still missing. Of course, it would be possible this way, but it’s a bit cumbersome:\n\npend$statakt[pend$statakt == -9 ]  &lt;- NA\npend$statakt[pend$statakt == -10]  &lt;- NA\n\nFor the PASS data, it’s shorter to use &lt; 0, because all missing codes are less than 0:1\n\npend$statakt[pend$statakt &lt; 0 ]  &lt;- NA\n\nIn count(), NA is also counted:\n\npend %&gt;% count(statakt)\n\n# A tibble: 4 × 2\n  statakt                                                 n\n  &lt;dbl+lbl&gt;                                           &lt;int&gt;\n1  1 [In occupation with earnings &gt;400 EUR per month]  9470\n2  2 [Unemployed, registered]                          6139\n3  3 [Pupil/student (school)]                          5481\n4 NA                                                   7334\n\n\nIf we want to avoid this, we use filter() again - with is.na(), we can identify NA. By prefixing with !, we can request that all non-NA values be retained with TRUE:\n\npend %&gt;% filter(!is.na(statakt)) %&gt;% count(statakt)\n\n# A tibble: 3 × 2\n  statakt                                                n\n  &lt;dbl+lbl&gt;                                          &lt;int&gt;\n1 1 [In occupation with earnings &gt;400 EUR per month]  9470\n2 2 [Unemployed, registered]                          6139\n3 3 [Pupil/student (school)]                          5481",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#other-table-values",
    "href": "03_desc.html#other-table-values",
    "title": "3  Getting an Overview",
    "section": "3.3 Other Table Values",
    "text": "3.3 Other Table Values\nWith the help of additional functions, we can customize the frequency table to match the Stata with tab statakt:\n\n\n   Current main occupation, gen. (since |\n                                    W2) |      Freq.     Percent        Cum.\n----------------------------------------+-----------------------------------\nIn occupation with earnings &gt;400 EUR pe |      9,470       44.90       44.90\n                 Unemployed, registered |      6,139       29.11       74.01\n                 Pupil/student (school) |      5,481       25.99      100.00\n----------------------------------------+-----------------------------------\n                                  Total |     21,090      100.00\n\n\n\ntab1 &lt;- pend %&gt;% filter(!is.na(statakt)) %&gt;% count(statakt)\n\n\nprop.table(): relative values/percentages\n\n\ntab1$pct &lt;- prop.table(tab1$n) \ntab1\n\n# A tibble: 3 × 3\n  statakt                                                n   pct\n  &lt;dbl+lbl&gt;                                          &lt;int&gt; &lt;dbl&gt;\n1 1 [In occupation with earnings &gt;400 EUR per month]  9470 0.449\n2 2 [Unemployed, registered]                          6139 0.291\n3 3 [Pupil/student (school)]                          5481 0.260\n\n\n29.109% of respondents are unemployed.\n\nprop.table() with cumsum(): cumulative relative frequencies\n\n\ntab1$cum &lt;- prop.table(tab1$n) %&gt;% cumsum()\ntab1\n\n# A tibble: 3 × 4\n  statakt                                                n   pct   cum\n  &lt;dbl+lbl&gt;                                          &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1 [In occupation with earnings &gt;400 EUR per month]  9470 0.449 0.449\n2 2 [Unemployed, registered]                          6139 0.291 0.740\n3 3 [Pupil/student (school)]                          5481 0.260 1    \n\n\n74.011% of respondents are employed or unemployed (and not inactive).\n\n3.3.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#contingency-tables",
    "href": "03_desc.html#contingency-tables",
    "title": "3  Getting an Overview",
    "section": "3.4 Contingency Tables",
    "text": "3.4 Contingency Tables\nContingency tables allow us to explore how frequently combinations of different variables occur together. Let’s look at two ways to create contingency tables in R.\nUsing count() from the {dplyr} package, we create a contingency table by inserting two variables. For instance, if we want to see the frequencies of employment status (statakt) by gender (zpsex), we can use the following command:\n\npend %&gt;% count(zpsex, statakt)\n\n# A tibble: 8 × 3\n  zpsex      statakt                                                 n\n  &lt;dbl+lbl&gt;  &lt;dbl+lbl&gt;                                           &lt;int&gt;\n1 1 [Male]    1 [In occupation with earnings &gt;400 EUR per month]  4685\n2 1 [Male]    2 [Unemployed, registered]                          3240\n3 1 [Male]    3 [Pupil/student (school)]                          2047\n4 1 [Male]   NA                                                   3555\n5 2 [Female]  1 [In occupation with earnings &gt;400 EUR per month]  4785\n6 2 [Female]  2 [Unemployed, registered]                          2899\n7 2 [Female]  3 [Pupil/student (school)]                          3434\n8 2 [Female] NA                                                   3779\n\ntab2 &lt;- pend %&gt;% count(zpsex, statakt)\ntab2$pct &lt;- prop.table(tab2$n)\ntab2\n\n# A tibble: 8 × 4\n  zpsex      statakt                                                 n    pct\n  &lt;dbl+lbl&gt;  &lt;dbl+lbl&gt;                                           &lt;int&gt;  &lt;dbl&gt;\n1 1 [Male]    1 [In occupation with earnings &gt;400 EUR per month]  4685 0.165 \n2 1 [Male]    2 [Unemployed, registered]                          3240 0.114 \n3 1 [Male]    3 [Pupil/student (school)]                          2047 0.0720\n4 1 [Male]   NA                                                   3555 0.125 \n5 2 [Female]  1 [In occupation with earnings &gt;400 EUR per month]  4785 0.168 \n6 2 [Female]  2 [Unemployed, registered]                          2899 0.102 \n7 2 [Female]  3 [Pupil/student (school)]                          3434 0.121 \n8 2 [Female] NA                                                   3779 0.133 \n\n\n\ntab2 %&gt;% mutate(pct_zpsex= prop.table(n), .by = zpsex)\n\n# A tibble: 8 × 5\n  zpsex      statakt                                          n    pct pct_zpsex\n  &lt;dbl+lbl&gt;  &lt;dbl+lbl&gt;                                    &lt;int&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n1 1 [Male]    1 [In occupation with earnings &gt;400 EUR pe…  4685 0.165      0.346\n2 1 [Male]    2 [Unemployed, registered]                   3240 0.114      0.240\n3 1 [Male]    3 [Pupil/student (school)]                   2047 0.0720     0.151\n4 1 [Male]   NA                                            3555 0.125      0.263\n5 2 [Female]  1 [In occupation with earnings &gt;400 EUR pe…  4785 0.168      0.321\n6 2 [Female]  2 [Unemployed, registered]                   2899 0.102      0.195\n7 2 [Female]  3 [Pupil/student (school)]                   3434 0.121      0.231\n8 2 [Female] NA                                            3779 0.133      0.254\n\n\n\n3.4.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#summary-statistics",
    "href": "03_desc.html#summary-statistics",
    "title": "3  Getting an Overview",
    "section": "3.5 Summary Statistics",
    "text": "3.5 Summary Statistics\nFor numerical variables, such as income (netges), we often compute summary statistics like the mean, median, or quantiles. To get a quick overview, use summary():\n\nsummary(pend$netges)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n    -5.0     -3.0     -3.0    567.9    990.0 111419.0 \n\npend$netges[pend$netges &lt; 0] &lt;- NA # Handling Missing Data\nsummary(pend$netges)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n      0     880    1320    1562    1890  111419   18056 \n\n\n\n3.5.1 Calculating Specific Statistics\nTo calculate specific statistics, we can use:\n\nMinimum: min()\nMaximum: max()\nMean: mean()\nMedian: median()\nQuantiles: quantile()\nVariance: var()\nStandard Deviation: sd()\n\nFor instance, the mean of income. Setting na.rm = TRUE forces R to ignore missing values:\n\nmean(pend$netges)\n\n[1] NA\n\nmean(pend$netges, na.rm = TRUE)\n\n[1] 1562.3\n\n\n\n\n3.5.2 Custom Summary with summarise()\nYou can use summarise() from {dplyr} to create custom summary tables:\n\npend %&gt;%\n  summarise(\n    Minimum = min(netges, na.rm = TRUE),\n    Median = median(netges, na.rm = TRUE),\n    Mean = mean(netges, na.rm = TRUE),\n    Maximum = max(netges, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 4\n  Minimum   Median  Mean Maximum  \n  &lt;dbl+lbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt;\n1 0           1320 1562. 111419   \n\n\n\n\n3.5.3 Comparing Across Groups\nTo compare statistics across groups, use .by in summarise():\n\npend %&gt;%\n  summarise(\n    Minimum = min(netges, na.rm = TRUE),\n    Median = median(netges, na.rm = TRUE),\n    Mean = mean(netges, na.rm = TRUE),\n    Maximum = max(netges, na.rm = TRUE),\n    .by = welle\n  ) %&gt;% arrange(welle)\n\n# A tibble: 13 × 5\n   welle                   Minimum   Median  Mean Maximum  \n   &lt;dbl+lbl&gt;               &lt;dbl+lbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt;\n 1  1 [Wave 1 (2006/2007)] 1          1200  1525. 111419   \n 2  2 [Wave 2 (2007/2008)] 0          1320  1529.   7200   \n 3  3 [Wave 3 (2008/2009)] 0          1298. 1498.  12000   \n 4  4 [Wave 4 (2010)]      0          1210  1447.  10800   \n 5  5 [Wave 5 (2011)]      0          1250  1494.  33363   \n 6  6 [Wave 6 (2012)]      0          1215  1459.  15950   \n 7  7 [Wave 7 (2013)]      0          1250  1539.  87835   \n 8  8 [Wave 8 (2014)]      0          1255  1456.   9000   \n 9  9 [Wave 9 (2015)]      0          1280  1613. 110451   \n10 10 [Wave 10 (2016)]     0          1375  1541.   6300   \n11 11 [Wave 11 (2017)]     0          1500  1748.  44440   \n12 12 [Wave 12 (2018)]     0          1500  1667.   7150   \n13 13 [Wave 13 (2019)]     0          1550  1816.  88453   \n\n\nGiven that the resulting ‘table’ is a data.frame, we can also filter for specific waves if needed:\n\npend %&gt;% \n  summarise(\n    Minimum = min(netges, na.rm = TRUE),\n    Median = median(netges, na.rm = TRUE),\n    Mean = mean(netges, na.rm = TRUE),\n    Maximum = max(netges, na.rm = TRUE),\n    .by = welle\n  ) %&gt;% \n  filter(welle %in% c(1, 10)) \n\n# A tibble: 2 × 5\n  welle                   Minimum   Median  Mean Maximum  \n  &lt;dbl+lbl&gt;               &lt;dbl+lbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt;\n1  1 [Wave 1 (2006/2007)] 1           1200 1525. 111419   \n2 10 [Wave 10 (2016)]     0           1375 1541.   6300   \n\n\nThese methods allow for thorough analysis of both categorical and numerical data in R.\n\n\n3.5.4 Exercise",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#exercises",
    "href": "03_desc.html#exercises",
    "title": "3  Getting an Overview",
    "section": "3.6 Exercises",
    "text": "3.6 Exercises\nUse the PASS CampusFile PENDDAT_cf_W13.dta for all exercises:\n\nlibrary(haven)\npend &lt;- read_dta(\"./orig/PENDDAT_cf_W13.dta\")\n\nAs a reminder: you can find an overview of the data import commands here\n\n3.6.1 Exercise 1\nWe are interested in the variable famstand, which contains the marital status of the respondents:\n\n\n\n\n\n\n\n\nMarital status, gen.\nMarital status, gen.\n\n\n\n\n-8\nImplausible value\n\n\n-4\nQuestion mistakenly not asked\n\n\n-3\nNot applicable (filter)\n\n\n-2\nNo answer\n\n\n1\nSingle\n\n\n2\nMarried/civil partnership, living together\n\n\n3\nMarried/civil partnership, not living together\n\n\n4\nDivorced\n\n\n5\nWidowed\n\n\n\n\n\n\n\n\nDisplay a table with absolute frequencies of famstand using both table() and count() (Remember to load {tidyverse} for count()).\nOverwrite missing codes with NA.\nDid the replacement of missing values with NA work? Create the table again.\nDisplay the relative frequencies (proportions). Use prop.table()\n\nBack to top\n\n\n3.6.2 Exercise 2\n\nCreate a contingency table for famstand and zpsex using count().\nWhat percentage of the respondents are divorced women? Use prop.table()\n\nBack to top\n\n\n3.6.3 Exercise 3\nDescribe the age of respondents (palter) using summary and create your own overview using summarise() to compare respondent age by marital status.\n\nFirst, overwrite missing values with NA:\n\n\npend$palter[pend$palter&lt;0] &lt;- NA\npend$famstand[pend$famstand&lt;0] &lt;- NA\n\n\nCreate an overview using summary().\nCreate an overview with the minimum, median, mean, variance, and maximum age values using summarise().\nExtend this overview to display the summary statistics for the different famstand categories.\n\nBack to top",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#notes",
    "href": "03_desc.html#notes",
    "title": "3  Getting an Overview",
    "section": "3.7 Notes",
    "text": "3.7 Notes\n\n3.7.1 Rounding with round()\nExplanation: You can round values to a certain number of digits using round(x , 3). The second number in the parentheses (after the comma) specifies how many decimal places you want:\n\nround(21.12121123,digits = 3)\n\n[1] 21.121\n\nround(21.12121123,digits = 5)\n\n[1] 21.12121\n\nround(21.12121123,digits = 0)\n\n[1] 21\n\n\nWe can round the relative frequencies to make the table above more readable:\n\nxtabs(~zpsex+statakt, data = pend) %&gt;% \n  prop.table(.,margin = 1) %&gt;% \n  round(.,3)\n\n     statakt\nzpsex     1     2     3\n    1 0.470 0.325 0.205\n    2 0.430 0.261 0.309",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "03_desc.html#footnotes",
    "href": "03_desc.html#footnotes",
    "title": "3  Getting an Overview",
    "section": "",
    "text": "For non-systematic values, we can use the %in% operator that we already learned about in connection with filter(): pend$var1[pend$var1 %in% c(-9,2,124) ]  &lt;- NA (this is just an example).↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Getting an Overview</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html",
    "href": "04_data_wrangle.html",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "",
    "text": "4.1 Creating Variables\nLet’s take a closer look at creating variables in R. There are two basic ways to add variables to a data.frame:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#var",
    "href": "04_data_wrangle.html#var",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "",
    "text": "Base R: ...$newvar &lt;-\n{dplyr}: mutate(new_var= )\n\n\n4.1.1 Base R: ...$newvar &lt;-\n\ndat3$studs_to_mean &lt;- dat3$studs - mean(dat3$studs)\ndat3\n\n  studs profs prom_recht gegr                uni studs_to_mean\n1 14954   250      FALSE 1971          FH Aachen      -11721.2\n2 47269   553       TRUE 1870        RWTH Aachen       20593.8\n3 23659   438       TRUE 1457       Uni Freiburg       -3016.2\n4  9415   150       TRUE 1818           Uni Bonn      -17260.2\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg       11403.8\n\n\nYou can also delete variables using &lt;- NULL:\n\ndat3$studs_to_mean &lt;- NULL\ndat3\n\n  studs profs prom_recht gegr                uni\n1 14954   250      FALSE 1971          FH Aachen\n2 47269   553       TRUE 1870        RWTH Aachen\n3 23659   438       TRUE 1457       Uni Freiburg\n4  9415   150       TRUE 1818           Uni Bonn\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg\n\n\n\n\n4.1.2 {dplyr}: mutate(new_var= )\nAn alternative way to create variables is using mutate(new_variable = ) from {dplyr} ({tidyverse}):\n\ndat3 %&gt;% mutate(studs_to_mean = studs - mean(studs))\n\n  studs profs prom_recht gegr                uni studs_to_mean\n1 14954   250      FALSE 1971          FH Aachen      -11721.2\n2 47269   553       TRUE 1870        RWTH Aachen       20593.8\n3 23659   438       TRUE 1457       Uni Freiburg       -3016.2\n4  9415   150       TRUE 1818           Uni Bonn      -17260.2\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg       11403.8\n\n\nYou can also create multiple variables within a single mutate() command:\n\ndat3 %&gt;% mutate(\n  studs_to_mean = studs - mean(studs),\n  profs_to_mean = profs - mean(profs)\n)\n\n  studs profs prom_recht gegr                uni studs_to_mean profs_to_mean\n1 14954   250      FALSE 1971          FH Aachen      -11721.2        -155.4\n2 47269   553       TRUE 1870        RWTH Aachen       20593.8         147.6\n3 23659   438       TRUE 1457       Uni Freiburg       -3016.2          32.6\n4  9415   150       TRUE 1818           Uni Bonn      -17260.2        -255.4\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg       11403.8         230.6\n\n\nOr variables can be reused within mutate():\n\ndat3 %&gt;% mutate(\n  rel_to_mean = studs - mean(studs),\n  above_mean = rel_to_mean &gt; 0\n)\n\n  studs profs prom_recht gegr                uni rel_to_mean above_mean\n1 14954   250      FALSE 1971          FH Aachen    -11721.2      FALSE\n2 47269   553       TRUE 1870        RWTH Aachen     20593.8       TRUE\n3 23659   438       TRUE 1457       Uni Freiburg     -3016.2      FALSE\n4  9415   150       TRUE 1818           Uni Bonn    -17260.2      FALSE\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg     11403.8       TRUE\n\n\nThe original dataset remains unchanged:\n\ndat3\n\n  studs profs prom_recht gegr                uni\n1 14954   250      FALSE 1971          FH Aachen\n2 47269   553       TRUE 1870        RWTH Aachen\n3 23659   438       TRUE 1457       Uni Freiburg\n4  9415   150       TRUE 1818           Uni Bonn\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg\n\n\nTo keep the results, store them in an object:\n\ndat4 &lt;- dat3 %&gt;% mutate(\n  rel_to_mean = studs - mean(studs),\n  above_mean = rel_to_mean &gt; 0\n)\n\ndat4\n\n  studs profs prom_recht gegr                uni rel_to_mean above_mean\n1 14954   250      FALSE 1971          FH Aachen    -11721.2      FALSE\n2 47269   553       TRUE 1870        RWTH Aachen     20593.8       TRUE\n3 23659   438       TRUE 1457       Uni Freiburg     -3016.2      FALSE\n4  9415   150       TRUE 1818           Uni Bonn    -17260.2      FALSE\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg     11403.8       TRUE\n\n\n\n\n\n\n\n\nCreating Dummy Variables with as.numeric()\n\n\n\n\n\nYou can convert logical variables into numeric dummy variables (0/1) using as.numeric():\n\ndat3 %&gt;% mutate(\n  prom_dummy = as.numeric(prom_recht),\n  over10k = as.numeric(studs &gt; 10000)\n)\n\n  studs profs prom_recht gegr                uni prom_dummy over10k\n1 14954   250      FALSE 1971          FH Aachen          0       1\n2 47269   553       TRUE 1870        RWTH Aachen          1       1\n3 23659   438       TRUE 1457       Uni Freiburg          1       1\n4  9415   150       TRUE 1818           Uni Bonn          1       0\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg          0       1",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#group_by",
    "href": "04_data_wrangle.html#group_by",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "4.2 Grouping with .by=",
    "text": "4.2 Grouping with .by=\nThe true power of mutate() becomes apparent when combined with other {dplyr} functions. A common task in data preparation involves grouped values.\nWe’ll make our example dataset a bit smaller:\n\ndat5 &lt;- dat3 %&gt;% \n  select(-uni,-gegr) # to ensure everything is visible\n\nSince {dplyr} version 1.1.1, we can specify a grouping directly in mutate() using the .by= argument. This .by= grouping is applied only to the immediate calculations within mutate():\n\ndat5 %&gt;%\n  mutate(m_studs = mean(studs),\n         m_profs = mean(profs)) %&gt;% \n  mutate(m_studs2 = mean(studs),\n         .by = prom_recht) %&gt;% \n  mutate(m_profs2 = mean(profs))\n\n  studs profs prom_recht m_studs m_profs m_studs2 m_profs2\n1 14954   250      FALSE 26675.2   405.4  26516.5    405.4\n2 47269   553       TRUE 26675.2   405.4  26781.0    405.4\n3 23659   438       TRUE 26675.2   405.4  26781.0    405.4\n4  9415   150       TRUE 26675.2   405.4  26781.0    405.4\n5 38079   636      FALSE 26675.2   405.4  26516.5    405.4\n\n\nUsing summarise() instead of mutate() provides an overview:\n\ndat5 %&gt;%\n  summarise(m_studs = mean(studs),.by = prom_recht)\n\n  prom_recht m_studs\n1      FALSE 26516.5\n2       TRUE 26781.0\n\n\n\n\n\n\n\n\ngroup_by()\n\n\n\n\n\nBefore {dplyr} 1.1.1, grouping a dataset relied on group_by(). After setting group_by() along the values of a variable, all subsequent mutate() calculations are performed only within those groups:\n\ndat5 %&gt;%\n  mutate(m_studs = mean(studs),\n         m_profs = mean(profs)) %&gt;% \n  group_by(prom_recht) %&gt;%\n  mutate(m_studs2 = mean(studs),\n         m_profs2 = mean(profs))\n\n# A tibble: 5 × 7\n# Groups:   prom_recht [2]\n  studs profs prom_recht m_studs m_profs m_studs2 m_profs2\n  &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;        &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 14954   250 FALSE       26675.    405.   26516.     443 \n2 47269   553 TRUE        26675.    405.   26781      380.\n3 23659   438 TRUE        26675.    405.   26781      380.\n4  9415   150 TRUE        26675.    405.   26781      380.\n5 38079   636 FALSE       26675.    405.   26516.     443 \n\n\nAfter using group_by(), it’s good practice to remove the grouping with ungroup() once it’s no longer needed:\n\ndat5 %&gt;%\n  mutate(m_studs = mean(studs),\n         m_profs = mean(profs)) %&gt;% \n  group_by(prom_recht) %&gt;%\n  mutate(m_studs2 = mean(studs)) %&gt;% \n  ungroup() %&gt;% \n  mutate(m_profs2 = mean(profs))\n\n# A tibble: 5 × 7\n  studs profs prom_recht m_studs m_profs m_studs2 m_profs2\n  &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;        &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 14954   250 FALSE       26675.    405.   26516.     405.\n2 47269   553 TRUE        26675.    405.   26781      405.\n3 23659   438 TRUE        26675.    405.   26781      405.\n4  9415   150 TRUE        26675.    405.   26781      405.\n5 38079   636 FALSE       26675.    405.   26516.     405.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#across",
    "href": "04_data_wrangle.html#across",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "4.3 across(): Processing Multiple Variables",
    "text": "4.3 across(): Processing Multiple Variables\nA highly versatile addition to mutate() and summarise() is across(). This allows us to apply a function to multiple columns simultaneously, without repeating code:\n\ndat3 %&gt;%\n  summarise(studs = mean(studs),\n            profs = mean(profs))\n\n    studs profs\n1 26675.2 405.4\n\n\nHere, across() offers a much shorter syntax for variable selection, and we can use ?select_helpers like matches():\n\ndat3 %&gt;%\n  summarise(across(.cols = matches(\"studs|profs\"),.fns = ~mean(.x)))\n\n    studs profs\n1 26675.2 405.4\n\n\nThis is also compatible with .by=:\n\ndat3 %&gt;%\n  summarise(across(matches(\"studs|profs\"), ~mean(.x)), .by= prom_recht)\n\n  prom_recht   studs    profs\n1      FALSE 26516.5 443.0000\n2       TRUE 26781.0 380.3333\n\n\nFor more examples on how apply multiple functions, include renaming etc. see below\n\n4.3.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#custom-functions",
    "href": "04_data_wrangle.html#custom-functions",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "4.4 Custom Functions",
    "text": "4.4 Custom Functions\nSo far, we only used functions written by others. We can also use own functions to avoid repetition:\nTo do so, let’s examine three satisfaction variables for respondents in rows 12-16:\n\n\n\n\n\n\n\n\nvariable\nImportant regarding job\n\n\n\n\nPEO0300a\nTo earn a lot of money\n\n\nPEO0300b\nA job, that is fun\n\n\nPEO0300c\nGood career opportunities\n\n\nPEO0300d\nJob security\n\n\nPEO0300e\nJob where you can show off your abilities\n\n\n\n\n\n\n\n\n\n\n\n\n\n-10 bis -1\n1\n2\n3\n4\n\n\n\n\nt.n.z./k.A.\nVery important\nRather important\nRather not important\nNot important at all\n\n\n\n\n\n\n\n\npend &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\")\n\nsat_small &lt;- \n  pend %&gt;% \n    filter(welle == 1) %&gt;% \n    select(matches(\"PEO0300(a|b|c)\")) %&gt;% \n    slice(12:16) %&gt;% \n    haven::zap_labels() %&gt;% haven::zap_label() # remove labels\nsat_small\n\n# A tibble: 5 × 3\n  PEO0300a PEO0300b PEO0300c\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1        2        3        2\n2        1        1        3\n3        1        1        3\n4        2        1        1\n5        1        1        2\n\n\n\nsat_small &lt;- sat_small %&gt;% mutate(across(everything(),~as.numeric(.x)))\n\nSometimes we want to process multiple variables in the same way. Above, we saw how to handle this with across() for existing functions. But what if we want to perform a calculation that isn’t as simple as applying mean(), sd(), etc.?\n\nsat_small %&gt;% \n  mutate(dmean_PEO0300a = PEO0300a - mean(PEO0300a,na.rm = T),\n         dmean_PEO0300c = PEO0300c - mean(PEO0300c,na.rm = T))\n\n# A tibble: 5 × 5\n  PEO0300a PEO0300b PEO0300c dmean_PEO0300a dmean_PEO0300c\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n1        2        3        2            0.6         -0.200\n2        1        1        3           -0.4          0.8  \n3        1        1        3           -0.4          0.8  \n4        2        1        1            0.6         -1.2  \n5        1        1        2           -0.4         -0.200\n\n\n…and now what about F1450_06? Typing this out three times would violate the “DRY” principle1, especially considering the PASS CampusFile contains 5 columns of similar satisfaction variables. Copying and pasting is not a practical option.\nCustom functions allow us to adhere to the DRY principle in R. We’ll make our calculation steps part of a function() and apply it to the desired variables. A function takes an input, defined as a placeholder within the (). This placeholder is used within the function, and we return the result with return(). Only one output can be returned:\n\ndtomean &lt;- function(x){\n  d_x &lt;- x - mean(x,na.rm = T)\n  return(d_x)\n}\n\nHow can we now apply our function dtomean() to the variables from our sat_small?\nIn principle, we saw at the beginning that a data.frame is simply a combined collection of vectors (the variables).\nAccordingly, we can now apply our dtomean() to a variable (a vector) by calling it with data.frame$variablename:\n\ndtomean(sat_small$PEO0300a)\n\n[1]  0.6 -0.4 -0.4  0.6 -0.4\n\n\nTo apply our function to each variable of a data.frame, we can use lapply() - the output will then be a list, with elements named after the variable names:\n\nlapply(sat_small,FUN = dtomean)\n\n$PEO0300a\n[1]  0.6 -0.4 -0.4  0.6 -0.4\n\n$PEO0300b\n[1]  1.6 -0.4 -0.4 -0.4 -0.4\n\n$PEO0300c\n[1] -0.2  0.8  0.8 -1.2 -0.2\n\nres &lt;- lapply(sat_small,FUN = dtomean)\nclass(res)\n\n[1] \"list\"\n\n\nmap() from {purrr} is an alternative to lapply:\n\nsat_small %&gt;% map(~dtomean(.x))\n\n$PEO0300a\n[1]  0.6 -0.4 -0.4  0.6 -0.4\n\n$PEO0300b\n[1]  1.6 -0.4 -0.4 -0.4 -0.4\n\n$PEO0300c\n[1] -0.2  0.8  0.8 -1.2 -0.2\n\n\nThis formula syntax can also be found in across() - additionally, with .names = we have the option to modify the variable names for the results:\n\nsat_small %&gt;% \n  mutate(across(matches(\"PEO0300\"),~dtomean(.x)) )\n\n# A tibble: 5 × 3\n  PEO0300a PEO0300b PEO0300c\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1      0.6      1.6   -0.200\n2     -0.4     -0.4    0.8  \n3     -0.4     -0.4    0.8  \n4      0.6     -0.4   -1.2  \n5     -0.4     -0.4   -0.200\n\n\n\n4.4.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#exercises",
    "href": "04_data_wrangle.html#exercises",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "4.5 Exercises",
    "text": "4.5 Exercises\n\n4.5.1 Exercise\n\n\n\n\nUse the pend_small dataset:\n\n\npend_small &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                               col_select = c(\"welle\",\"zpsex\",\"PEO0400a\",\"PEO0400b\",\"PEO0400c\",\"PEO0400d\")\n                               ) %&gt;% \n  haven::zap_labels() %&gt;% # drop labels to have a clean data.frame\n  filter(welle == 2) %&gt;% \n  slice(1:10)\n\n\nCalculate the mean for the variables PEO0400a by gender (zpsex):\nCalculate the mean for the variables PEO0400a, PEO0400b, PEO0400c, and PEO0400d by gender (zpsex):\nUse across() to calculate the means for all four variables.\n\n\n\n\n\n\n\n\n\nvar\nlab\n\n\n\n\nPEO0400a\nFamily/job: Woman should be willing to reduce her working hours for family\n\n\nPEO0400b\nFamily/job: What women really want is a home and children\n\n\nPEO0400c\nFamily/job: Working mother can have an equally warm relationship with her childr\n\n\nPEO0400d\nFamily/job: Responsibility of husband: To earn money; responsibility of wife: Ho\n\n\n\n\n\n\n\n   welle zpsex PEO0400a PEO0400b PEO0400c PEO0400d\n1      2     2        1        1        4        1\n2      2     1        2        1        3        2\n3      2     2        1        3        1        4\n4      2     2        1        1        4        1\n5      2     2        1        1        1        1\n6      2     1        1        1        1        1\n7      2     1        1        2        1        4\n8      2     1        3        2        3        2\n9      2     2        3        3        3        3\n10     2     1        2        3        2        2\n\n\n\nStandardize the variables PEO0400a - PEO0400d from pend_small using the following pattern:\n\n\npend_small %&gt;% \n  mutate(std_PEO0400b = (PEO0400b - mean(PEO0400b,na.rm = T))/sd(PEO0400b,na.rm = T))\n\n\nUse a function so that you don’t have to repeatedly enter the same steps.\nAdditionally, use across() to apply the function to the desired variables.\nCalculate the standardization separately by gender (zpsex) using .by =.\n\nBack to top\nBack to top\n\n\n4.5.2 Exercise\nContinue using pend_small:\n\npend_small\n\n\n\n   welle zpsex PEO0400a PEO0400b PEO0400c PEO0400d\n1      2     2        1        1        4        1\n2      2     1        2        1        3        2\n3      2     2        1        3        1        4\n4      2     2        1        1        4        1\n5      2     2        1        1        1        1\n6      2     1        1        1        1        1\n7      2     1        1        2        1        4\n8      2     1        3        2        3        2\n9      2     2        3        3        3        3\n10     2     1        2        3        2        2\n\n\n\nStandardize the variables PEO0400a - PEO0400d from pend_small using the following pattern:\n\n\npend_small %&gt;% \n  mutate(std_PEO0400b = (PEO0400b - mean(PEO0400b,na.rm = T))/sd(PEO0400b,na.rm = T))\n\n\nUse a function so that you don’t have to repeatedly enter the same steps.\nAdditionally, use across() to apply the function to the desired variables.\n\nBack to top",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#appendix",
    "href": "04_data_wrangle.html#appendix",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "4.6 Appendix",
    "text": "4.6 Appendix\n\n4.6.1 across(): Processing Multiple Variables\nA highly versatile addition to mutate() and summarise() is across(). This allows us to apply a function to multiple columns simultaneously, without repeating code:\n\ndat3 %&gt;%\n  summarise(studs = mean(studs),\n            profs = mean(profs))\n\n    studs profs\n1 26675.2 405.4\n\n\nHere, across() offers a much shorter syntax for variable selection, and we can use ?select_helpers like matches():\n\ndat3 %&gt;%\n  summarise(across(.cols = matches(\"studs|profs\"),.fns = ~mean(.x)))\n\n    studs profs\n1 26675.2 405.4\n\n\nThis is also compatible with .by=:\n\ndat3 %&gt;%\n  summarise(across(matches(\"studs|profs\"), ~mean(.x)), .by= prom_recht)\n\n  prom_recht   studs    profs\n1      FALSE 26516.5 443.0000\n2       TRUE 26781.0 380.3333\n\n\nWe can apply multiple functions by placing them in a list():\n\ndat3 %&gt;%\n  summarise(across(matches(\"studs|profs\"), list(mean = ~mean(.x), sd = ~sd(.x))), .by= prom_recht)\n\n  prom_recht studs_mean studs_sd profs_mean profs_sd\n1      FALSE    26516.5 16351.84   443.0000 272.9432\n2       TRUE    26781.0 19119.14   380.3333 207.5966\n\n\nYou can define this list() in advance and use it later:\n\nwert_liste &lt;- list(MEAN = ~mean(.x), SD = ~sd(.x))\n\ndat3 %&gt;%\n  summarise(across(matches(\"studs|profs\"), wert_liste), .by= prom_recht)\n\n  prom_recht studs_MEAN studs_SD profs_MEAN profs_SD\n1      FALSE    26516.5 16351.84   443.0000 272.9432\n2       TRUE    26781.0 19119.14   380.3333 207.5966\n\n\nThe .names() argument allows us to control the naming of columns. {.fn} stands for the function being applied, and {.col} represents the name of the variable being processed.\n\ndat3 %&gt;%\n  summarise(across(matches(\"studs|profs\"), \n                   wert_liste,\n                   .names = \"{.fn}_{.col}\"),\n            .by= prom_recht)\n\n  prom_recht MEAN_studs SD_studs MEAN_profs SD_profs\n1      FALSE    26516.5 16351.84   443.0000 272.9432\n2       TRUE    26781.0 19119.14   380.3333 207.5966\n\n\nAll these functions also work with mutate():\n\ndat3 %&gt;%\n  mutate(across(matches(\"studs|profs\"),\n                wert_liste, \n                .names = \"{.col}XX{.fn}\"))\n\n  studs profs prom_recht gegr                uni studsXXMEAN studsXXSD\n1 14954   250      FALSE 1971          FH Aachen     26675.2  15799.92\n2 47269   553       TRUE 1870        RWTH Aachen     26675.2  15799.92\n3 23659   438       TRUE 1457       Uni Freiburg     26675.2  15799.92\n4  9415   150       TRUE 1818           Uni Bonn     26675.2  15799.92\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg     26675.2  15799.92\n  profsXXMEAN profsXXSD\n1       405.4   203.349\n2       405.4   203.349\n3       405.4   203.349\n4       405.4   203.349\n5       405.4   203.349\n\n\nMore examples in the across() documentation\n\n4.6.1.1 Exercise\n\n\n\n4.6.2 Helper functions\n\n4.6.2.1 ifelse()\nifelse() is a great help for all recoding tasks: we formulate a condition and if it is met, the first value is used; if not, the second value is used. Here we check whether studs-mean(studs) is greater than 0 - if so, above is used, otherwise below:\n\ndat3 %&gt;% mutate(rel_to_mean = studs-mean(studs),\n                ab_mean_lab = ifelse(rel_to_mean &gt; 0,\"above\",\"below\"))\n\n  studs profs prom_recht gegr                uni rel_to_mean ab_mean_lab\n1 14954   250      FALSE 1971          FH Aachen    -11721.2       below\n2 47269   553       TRUE 1870        RWTH Aachen     20593.8       above\n3 23659   438       TRUE 1457       Uni Freiburg     -3016.2       below\n4  9415   150       TRUE 1818           Uni Bonn    -17260.2       below\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg     11403.8       above\n\n\nThis can be helpful to replace negative values with NA, for example in the PASS data:\n\npend_small2 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                               col_select = c(\"palter\",\"PEO0400a\",\"PEO0400b\",\"PEO0400c\",\"statakt\"))  %&gt;% \n  slice(5624:5640)\n\nThe basic idea is to use ifelse() to replace negative values in a variable with NA:\n\npend_small2 %&gt;% mutate(PEO0400a = ifelse(PEO0400a&lt;0,NA,PEO0400a))\n\nacross() allows us to apply this ifelse()-function to replace NA in PEO0400a,PEO0400b, PEO0400c and statakt:\n\npend_small2 %&gt;% mutate(across(c(\"PEO0400a\",\"PEO0400b\",\"PEO0400c\",\"statakt\"), ~ifelse(.x&lt;0,NA,.x)))  \n\n# A tibble: 17 × 5\n   palter    PEO0400a PEO0400b PEO0400c statakt\n   &lt;dbl+lbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1 77               1        3        3      NA\n 2 78              NA       NA       NA      NA\n 3 51               2        4        1      NA\n 4 23               3        3        2      NA\n 5 17               3        2        1      NA\n 6 47               3        2        2      NA\n 7 24               3        4        1       1\n 8 52               2        3        1       1\n 9 19               2        3        2       3\n10 48               2        3        1       1\n11 49              NA       NA       NA      NA\n12 47               2        3        1      NA\n13 48               2        3        1       1\n14 49              NA       NA       NA       1\n15 39               4        3        1      NA\n16 37               3        4        1      NA\n17 38               3        3        1       1\n\npend_small2 %&gt;% mutate(across(matches(\"PEO0400|statakt\"), ~ifelse(.x&lt;0,NA,.x)))  # even shorter: matches()\n\n# A tibble: 17 × 5\n   palter    PEO0400a PEO0400b PEO0400c statakt\n   &lt;dbl+lbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1 77               1        3        3      NA\n 2 78              NA       NA       NA      NA\n 3 51               2        4        1      NA\n 4 23               3        3        2      NA\n 5 17               3        2        1      NA\n 6 47               3        2        2      NA\n 7 24               3        4        1       1\n 8 52               2        3        1       1\n 9 19               2        3        2       3\n10 48               2        3        1       1\n11 49              NA       NA       NA      NA\n12 47               2        3        1      NA\n13 48               2        3        1       1\n14 49              NA       NA       NA       1\n15 39               4        3        1      NA\n16 37               3        4        1      NA\n17 38               3        3        1       1\n\n\n\n\n4.6.2.2 case_when()\ncase_when() ({dplyr}) extends the principle ifelse(), allowing us to specify more than two options.\nThe syntax is slightly different: first, we specify the condition, then after a ~ the values to be used:\n\ndat3 %&gt;% mutate(age = case_when(gegr &lt; 1500 ~ \"very old\",\n                                gegr &lt; 1900 ~ \"old\"))\n\n  studs profs prom_recht gegr                uni      age\n1 14954   250      FALSE 1971          FH Aachen     &lt;NA&gt;\n2 47269   553       TRUE 1870        RWTH Aachen      old\n3 23659   438       TRUE 1457       Uni Freiburg very old\n4  9415   150       TRUE 1818           Uni Bonn      old\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg     &lt;NA&gt;\n\n\nWith TRUE, we can address all cases that have not met any conditions so far:\n\ndat3 %&gt;% mutate(age = case_when(gegr &lt; 1500 ~ \"very old\",\n                                gegr &lt; 1900 ~ \"old\",\n                                TRUE ~ \"relatively new\"))\n\n  studs profs prom_recht gegr                uni            age\n1 14954   250      FALSE 1971          FH Aachen relatively new\n2 47269   553       TRUE 1870        RWTH Aachen            old\n3 23659   438       TRUE 1457       Uni Freiburg       very old\n4  9415   150       TRUE 1818           Uni Bonn            old\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg relatively new\n\n\nThis doesn’t have to be limited to one variable:\n\ndat3 %&gt;% mutate(age = case_when(gegr &lt; 1500 & prom_recht  == T ~ \"very old university\",\n                                gegr &lt; 1900 & prom_recht  == T ~ \"old university\",\n                                gegr &gt; 1900 & prom_recht  == T ~ \"young university\",\n                                gegr &lt; 1900 & prom_recht  == F ~ \"old college\",\n                                gegr &gt; 1900 & prom_recht  == F ~ \"young college\"))\n\n  studs profs prom_recht gegr                uni                 age\n1 14954   250      FALSE 1971          FH Aachen       young college\n2 47269   553       TRUE 1870        RWTH Aachen      old university\n3 23659   438       TRUE 1457       Uni Freiburg very old university\n4  9415   150       TRUE 1818           Uni Bonn      old university\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg       young college\n\n\n\n\n4.6.2.3 cut(): creating classes\n\ndat3\n\n  studs profs prom_recht gegr                uni\n1 14954   250      FALSE 1971          FH Aachen\n2 47269   553       TRUE 1870        RWTH Aachen\n3 23659   438       TRUE 1457       Uni Freiburg\n4  9415   150       TRUE 1818           Uni Bonn\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg\n\n\nA common task in data preparation is classifying a continuous variable, such as the number of professors. We want to group profs in steps of 150. To create these classes, we use cut() and specify the class boundaries with breaks. We can use seq() to generate the breakpoints. In seq(), we specify the lower and upper limits along with the step size.\n\ncut(dat3$profs,breaks = c(50, 200, 350, 500, 650))\n\n[1] (200,350] (500,650] (350,500] (50,200]  (500,650]\nLevels: (50,200] (200,350] (350,500] (500,650]\n\ncut(dat3$profs,breaks = seq(50,650,150))\n\n[1] (200,350] (500,650] (350,500] (50,200]  (500,650]\nLevels: (50,200] (200,350] (350,500] (500,650]\n\n\nWe store these values in a new variable in the dat3 dataset:\n\ndat3$prof_class &lt;- cut(dat3$profs,breaks = seq(50,650,150))\ndat3\n\n  studs profs prom_recht gegr                uni prof_class\n1 14954   250      FALSE 1971          FH Aachen  (200,350]\n2 47269   553       TRUE 1870        RWTH Aachen  (500,650]\n3 23659   438       TRUE 1457       Uni Freiburg  (350,500]\n4  9415   150       TRUE 1818           Uni Bonn   (50,200]\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg  (500,650]\n\n\nFor this new variable, we can request a frequency table using count():\n\ndat3 %&gt;% count(prof_class)\n\n  prof_class n\n1   (50,200] 1\n2  (200,350] 1\n3  (350,500] 1\n4  (500,650] 2\n\n\nThe parentheses ( indicate exclusion, while the brackets ] indicate inclusion. There are 1 universities in the dataset that have more than 200 and up to 350 professors.\nFor the following examples, we delete the prof_class variable again:\n\ndat3$prof_class &lt;- NULL\n\nSome useful options for cut() in the appendix\n\nbsp &lt;- c(1990,1998,2001,2009)\nbsp\n\n[1] 1990 1998 2001 2009\n\ncut(bsp,breaks = c(1990,2000,2010)) \n\n[1] &lt;NA&gt;             (1.99e+03,2e+03] (2e+03,2.01e+03] (2e+03,2.01e+03]\nLevels: (1.99e+03,2e+03] (2e+03,2.01e+03]\n\n# Specify the number of digits in the labels\ncut(bsp,breaks = c(1990,2000,2010),dig.lab = 4) \n\n[1] &lt;NA&gt;        (1990,2000] (2000,2010] (2000,2010]\nLevels: (1990,2000] (2000,2010]\n\n# Include the lower boundary\ncut(bsp,breaks = c(1990,2000,2010),dig.lab = 4,include.lowest = T) \n\n[1] [1990,2000] [1990,2000] (2000,2010] (2000,2010]\nLevels: [1990,2000] (2000,2010]\n\n# Number the categories instead of labels:\ncut(bsp,breaks = c(1990,2000,2010),labels = FALSE)\n\n[1] NA  1  2  2\n\n# Specify your own labels:\ncut(bsp,breaks = c(1990,2000,2010),labels = c(\"90s\",\"00s\"))\n\n[1] &lt;NA&gt; 90s  00s  00s \nLevels: 90s 00s\n\n\n\n\n\n4.6.3 Renaming variables\nTo rename variables, use rename(new_name = old_name)\n\nsat_small %&gt;% rename(newname = PEO0300a)\n\n# A tibble: 5 × 3\n  newname PEO0300b PEO0300c\n    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1       2        3        2\n2       1        1        3\n3       1        1        3\n4       2        1        1\n5       1        1        2\n\n\nFor advanced transformations, it’s worth looking into rename_with(). This allows us to use Regular Expressions, for example from {stringr}. Here’s just an example:\n\nsat_small %&gt;% rename_with(~tolower(.))\n\n# A tibble: 5 × 3\n  peo0300a peo0300b peo0300c\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1        2        3        2\n2        1        1        3\n3        1        1        3\n4        2        1        1\n5        1        1        2\n\nsat_small %&gt;% rename_with(~str_remove(.x,\"PEO0300\"))\n\n# A tibble: 5 × 3\n      a     b     c\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     2     3     2\n2     1     1     3\n3     1     1     3\n4     2     1     1\n5     1     1     2\n\nsat_small %&gt;% rename_with(~str_replace(.x,\"PEO0300\",\"Occupation_\"))\n\n# A tibble: 5 × 3\n  Occupation_a Occupation_b Occupation_c\n         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1            2            3            2\n2            1            1            3\n3            1            1            3\n4            2            1            1\n5            1            1            2\n\n\n\n\n4.6.4 String Functions for regex\n{stringr} provides a series of very useful string functions with regular expressions. You can get an overview from this cheatsheet.\n\ndat3 %&gt;% mutate(uni_fh = str_detect(uni,\"Uni\"))\n\n  studs profs prom_recht gegr                uni uni_fh\n1 14954   250      FALSE 1971          FH Aachen  FALSE\n2 47269   553       TRUE 1870        RWTH Aachen  FALSE\n3 23659   438       TRUE 1457       Uni Freiburg   TRUE\n4  9415   150       TRUE 1818           Uni Bonn   TRUE\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg  FALSE\n\ndat3 %&gt;% mutate(bula = case_when(str_detect(uni,\"Bremen\")~ \"HB\",\n                                 str_detect(uni,\"Oldenb|Vechta\")~ \"NDS\",\n                                 str_detect(uni,\"Bonn|Aachen\")~ \"NRW\",\n                                 str_detect(uni,\"Freiburg\")~ \"BW\"\n                                 ))\n\n  studs profs prom_recht gegr                uni bula\n1 14954   250      FALSE 1971          FH Aachen  NRW\n2 47269   553       TRUE 1870        RWTH Aachen  NRW\n3 23659   438       TRUE 1457       Uni Freiburg   BW\n4  9415   150       TRUE 1818           Uni Bonn  NRW\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg  NRW\n\ndat3 %&gt;% mutate(ort = str_remove(uni,\"Uni |FH |RWTH \"))\n\n  studs profs prom_recht gegr                uni             ort\n1 14954   250      FALSE 1971          FH Aachen          Aachen\n2 47269   553       TRUE 1870        RWTH Aachen          Aachen\n3 23659   438       TRUE 1457       Uni Freiburg        Freiburg\n4  9415   150       TRUE 1818           Uni Bonn            Bonn\n5 38079   636      FALSE 1995 FH Bonn-Rhein-Sieg Bonn-Rhein-Sieg",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "04_data_wrangle.html#footnotes",
    "href": "04_data_wrangle.html#footnotes",
    "title": "4  Data Wrangling I: Creating Variables",
    "section": "",
    "text": "Do not repeat yourself, see Wickham et al: “You should consider writing a function whenever you’ve copied and pasted a block of code more than twice (i.e. you now have three copies of the same code).”↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Wrangling I: Creating Variables</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html",
    "href": "07_viz_translated.html",
    "title": "5  Visualization with {ggplot2}",
    "section": "",
    "text": "5.1 ggplot2 and the Grammar of Graphics\nggplot2 is the implementation of the concept of “layered grammar of graphics” in R. The idea of this visualization system is to break down data visualization into parameters: the underlying dataset, the variables to be displayed, the choice of display shapes, the coordinate system, scales, and statistical transformations. A standard command in ggplot2 looks something like this:\nggplot(data = dataset, aes(x = var1, y = var2, color = var3)) +\n  geom_point() +\n  labs(title= \"Title\", subtitle = \"Subtitle\") +\n  theme_minimal()\nSo we first call up a plot with ggplot(). Further arguments then define additional aspects:\nNow we will work through the individual layers of the graphic:",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html#ggplot2-and-the-grammar-of-graphics",
    "href": "07_viz_translated.html#ggplot2-and-the-grammar-of-graphics",
    "title": "5  Visualization with {ggplot2}",
    "section": "",
    "text": "With data =, we specify the data.frame we want to visualize.\nThe aesthetics aes() specify which variables are to be displayed: here var1 on the x-axis, var2 on the y-axis, and var3 for coloring.\nThe layers geom_.. specify the type of display, e.g., geom_point() for point plots and geom_bar() for bar charts.\nWith labs, we can add labels, such as a title or axis labels.\nThe themes theme_... set the design of the graphic, e.g., black and white axes and background colors with theme_bw().\n\n\n\n5.1.1 data =\nIn data =, we specify the data.frame that contains the information to be visualized. We start our ggplot with:\n\nggplot(data = pend_small)\n\n\n\n\n\n\n\n\n\n\n5.1.2 aes\nWe want to visualize these values in a scatterplot, with age on the x-axis and weekly working hours on the y-axis:\n\nggplot(data = pend_small, aes(x = palter, y = azges1))\n\n\n\n\n\n\n\n\n\n\n5.1.3 geom\nIf we only provide these details, we will get an empty coordinate system—why? Because we haven’t yet specified what form of display we want. For this, we must specify a geom_, such as geom_col() for bar charts, which we attach to the ggplot command with +:\n\nggplot(data = pend_small, aes(x = palter, y = azges1)) + geom_point()\n\n\n\n\n\n\n\n\nWith color =, we can also change the color of the points:\n\nggplot(data = pend_small, aes(x = palter, y = azges1)) + geom_point(color = \"orange\")\n\n\n\n\n\n\n\n\nHere is an overview of all color names that are recognized, though there are many more colors—see Appendix.\n\n\n5.1.4 aes() Part II\nThis already looks pretty good, but the points are not yet separated by gender. To do this, we need to include the gender information (zpsex) in aes(). In addition to the axes, aes() also specifies the variables for the appearance of the geom_s—this can include not only color but also shape, size, or transparency. Here’s an overview.\nGender should determine the color of the points, which we can specify in aes with color:\n\n# results in an error due to labels:\nggplot(data = pend_small, aes(x = palter, y = azges1, color = zpsex )) + \n  geom_point()\n\nError in UseMethod(\"rescale\"): nicht anwendbare Methode für 'rescale' auf Objekt der Klasse \"c('haven_labelled', 'vctrs_vctr', 'double')\" angewendet\n\n\nA numeric variable for color = results in a color gradient, while a factor/character variable results in a discrete color scale:\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.numeric(zpsex))) + \n  geom_point()\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.factor(zpsex))) + \n  geom_point()\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.character(zpsex))) + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also specify custom colors with scale_color_manual1, and a list of possible colors can be found here.\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.factor(zpsex))) + \n  geom_point() + \n  scale_color_manual(values = c(\"lightskyblue4\",\"navy\"))\n\n\n\n\n\n\n\n\n\n\n5.1.5 Labels\nWith the breaks and labels options, we can also edit the legend labels. To do this, we first specify the levels of the gender variable in breaks and then the corresponding labels in the same order:\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.factor(zpsex))) + \n  geom_point() + \n  scale_color_manual(values = c(\"lightskyblue4\",\"navy\"),\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") )\n\n\n\n\n\n\n\n\nFinally, we adjust the labels with labs, where we have the following options:\n\ntitle: Title for the graphic\nsubtitle: Subtitle for the title\ncaption: Annotation below the graphic\nx: x-axis label\ny: y-axis label\nfill: Legend label when fill is specified in aes()\ncolor: Legend label when color is specified in aes()\nlinetype: Legend label when linetype is specified in aes()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html#combination-of-all-options",
    "href": "07_viz_translated.html#combination-of-all-options",
    "title": "5  Visualization with {ggplot2}",
    "section": "5.2 Combination of all options",
    "text": "5.2 Combination of all options\n\nggplot(data = pend_small, aes(x = palter, y = azges1, \n                               shape = as.factor(zpsex),\n                               color = as.factor(zpsex))) + \n  geom_point(size = 4) + \n  scale_color_manual(values = c(\"lightskyblue4\",\"orange\"),\n                     breaks = c(1,2), labels = c(\"Men\", \"Women\")\n                     ) +\n  scale_shape_manual(values = c(18,20),\n                     breaks = c(1,2), labels = c(\"Men\", \"Women\")\n                     ) +\n  labs(color = \"Gender\", \n       shape = \"Gender\",\n       y = \"Hours/Week\",\n       x = \"Age\",\n       title = \"Working hours and age\",\n       subtitle = \"By Gender\",\n       caption = \"Soruce: PASS CF 0619\"\n       ) \n\n\n\n\n\n\n\n\nÜbersicht zu shapes\n\n5.2.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html#visualizing-distributions",
    "href": "07_viz_translated.html#visualizing-distributions",
    "title": "5  Visualization with {ggplot2}",
    "section": "5.3 Visualizing distributions",
    "text": "5.3 Visualizing distributions\nWith the following syntax we can create a boxplot using ggplot2. Since we are only considering one variable, we only need to specify y = or x = depending on whether the box should be oriented vertically or horizontally.\nggplot(data = pend_small, aes(y = azges1)) + geom_boxplot()\nggplot(data = pend_small, aes(x = azges1)) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also create separate boxplots for men and women by specifying a variable for the other axis:\n\nggplot(data = pend_small, aes(y = azges1, x = factor(zpsex))) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n5.3.1 Histogram\nWe can also describe distributions using a histogram using the geom_histogram() function. If we want to change the color, fill = is the correct option instead of color =:\nggplot(data = pend_small, aes(x = azges1)) + \n  geom_histogram()  \nggplot(data = pend_small, aes(x = azges1)) + \n  geom_histogram(fill = \"sienna1\")  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo split the histogram by gender, we can again specify fill as an aesthetic. With position = position_dodge(), we can place the bars side by side:\nggplot(data = pend_small, aes(x = azges1, fill = factor(zpsex))) + \n  geom_histogram() \nggplot(data = pend_small, aes(x = azges1, fill = factor(zpsex))) + \n  geom_histogram(position = position_dodge()) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe scale_...manual commands still work here, but as scale_fill_manual instead of scale_color_manual:\n\nggplot(data = pend_small, aes(x = azges1, fill = factor(zpsex))) + \n  geom_histogram(position = position_dodge()) +\n  scale_fill_manual(values = c(\"sienna1\",\"dodgerblue4\"),\n                    breaks = 1:2, labels = c(\"Männer\",\"Frauen\")) +\n  labs(fill = \"Geschlecht\")\n\n\n\n\n\n\n\n\n\n\n5.3.2 Exercise",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html#categorical-variables",
    "href": "07_viz_translated.html#categorical-variables",
    "title": "5  Visualization with {ggplot2}",
    "section": "5.4 Categorical variables",
    "text": "5.4 Categorical variables\nNext, we’ll look at a way to visualize the contingency table from Chapter 2:\n\npend_small$PD0400[pend_small$PD0400&lt;0] &lt;- NA # exclude missings\npend_small %&gt;% \n  count(zpsex, PD0400) %&gt;% \n  filter(!is.na(PD0400))\n\n# A tibble: 8 × 3\n  zpsex      PD0400                       n\n  &lt;dbl+lbl&gt;  &lt;dbl+lbl&gt;                &lt;int&gt;\n1 1 [Male]   1 [Not at all religious]     9\n2 1 [Male]   2 [Rather not religious]     6\n3 1 [Male]   3 [Rather religious]         9\n4 1 [Male]   4 [Very religious]           5\n5 2 [Female] 1 [Not at all religious]     8\n6 2 [Female] 2 [Rather not religious]     2\n7 2 [Female] 3 [Rather religious]         5\n8 2 [Female] 4 [Very religious]           3\n\n\nWith geom_bar(), we can create bars by setting the height as the count of observations with ..count.. for y:\n\npend_small %&gt;% \n  count(zpsex, PD0400) %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  ggplot(data = ., aes(x = as_factor(PD0400), fill = factor(zpsex),\n                       y = n)) +\n  geom_col(position = position_dodge()) \n\n\n\n\n\n\n\n\nHow do we get relative frequencies? We add mutate(pct = prop.table(n), .by = zpsex) to our pipe. With scale_y_continuous(labels = scales::label_percent(accuracy = 1)), we can also display percentages on the y-axis. To create a bar chart instead of a column chart, simply swap x and y and adjust the percentage labels using scale_x_continuous:\npend_small %&gt;% \n  count(zpsex, PD0400) %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  mutate(pct = prop.table(n), .by = zpsex) %&gt;% \n  ggplot(data = ., aes(x = as_factor(PD0400), fill = factor(zpsex),\n                       y = pct )) +\n  geom_col(position = position_dodge()) +\n  scale_y_continuous(labels = scales::label_percent(accuracy = 1)) \n# horizontal -&gt; swap x and y axis\npend_small %&gt;% \n  count(zpsex, PD0400) %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  mutate(pct = prop.table(n), .by = zpsex) %&gt;% \n  ggplot(data = ., aes(y = as_factor(PD0400), fill = factor(zpsex),\n                       x = pct )) +\n  geom_col(position = position_dodge()) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThese charts can also be customized with scale_... and labeled in detail using labs()—all options are consistent across different types of visualizations. Additionally, we can label the categories ourselves with breaks = and labels = if we don’t like the default labels:\n\npend_small %&gt;% \n  count(zpsex, PD0400) %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  mutate(pct = prop.table(n), .by = zpsex) %&gt;% \n  ggplot(data = ., aes(y = as_factor(PD0400), \n                       fill = factor(zpsex),\n                       x = pct )) +\n  geom_col(position = position_dodge()) +\n  scale_fill_manual(values = c(\"deepskyblue3\",\"deepskyblue4\"),\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\")) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) +\n  labs(title = \"Religiösität nach Geschlecht\",\n       subtitle = \"Relative Häufigkeiten\",\n       caption = \"Quelle: PASS-CF 0619\",\n       y = \"Religiösität\",\n       x = \"Relative Häufigkeit\",\n       fill = \"Geschlecht\" ) \n\n\n\n\n\n\n\n\n\n5.4.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html#exercises",
    "href": "07_viz_translated.html#exercises",
    "title": "5  Visualization with {ggplot2}",
    "section": "5.5 Exercises",
    "text": "5.5 Exercises\nTo keep the data simple, you can use the following command:\n\npend &lt;- \n  haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\", \n    col_select = c(\"zpsex\", \"welle\", \"bilzeit\", \"PA0445\", \"PG1270\", \"PEO0400c\")\n  )\n\n\n5.5.1 Exercise 1\nUse this data set:\n\npend_u41 &lt;- \n  pend %&gt;% \n  filter(welle == 13, bilzeit &gt; 0, PA0445 &gt; 0) %&gt;% \n  mutate(zpsex = factor(zpsex))\n\n\nCreate a scatter plot for the variables “Duration of total unemployment experience in months” (PA0445, y-axis) and “Duration of education” (bilzeit, x-axis).\nSet the color to differentiate between men and women (zpsex).\nChange the colors to goldenrod1 and dodgerblue4 (or any other from this list).\nLabel the axes and legend!\n\nBack to top\n\n\n5.5.2 Exercise 2\nUse this data set:\n\npend_u42 &lt;- \n  pend %&gt;% \n  filter(welle == 9, PG1270 &gt; 0) \n\n\nCreate a boxplot or histogram for the distribution of the number of cigarettes and cigarillos smoked per day (in the last week) (PG1270).\nCustomize this graphic so that the distributions for men and women are shown separately.\nHow can you also set the colors based on gender? (Remember color = and fill =).\nChange the bar colors using scale_color_manual, scale_color_brewer, or scale_color_viridis (see the sections Colors, ColorBrewer, and viridis under “other options”).\n\nBack to top\n\n\n5.5.3 Exercise 3\nUse this data set:\n\npend_u43 &lt;- \n  pend %&gt;% \n  filter(welle == 11, PEO0400c &gt; 0) \n\n\nCreate a bar chart for the responses to the question, “A working mother can have just as close a relationship with her children as a mother who is not employed.” (PEO0400c).\nCreate a bar chart for PEO0400c separated by the migration variable, so set the bar colors based on migration. The migration variable captures whether the respondents have a migration background:\n\n\n\nVariablevaluelabel`PEO0400c`1Completely agree2Rather agree3Rather not agree4Do not agree at all`migration`1No migration background2Person is immigrated3At least one parent is immigrated4At least one grand-parent is immigrated, parents born in GER\n\n\nBack to top",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html#more-options-for-ggplot2",
    "href": "07_viz_translated.html#more-options-for-ggplot2",
    "title": "5  Visualization with {ggplot2}",
    "section": "5.6 More options for {ggplot2}",
    "text": "5.6 More options for {ggplot2}\n\n5.6.1 Aesthetics\n\n\n\n\n\n\n\n\n\n\n\n5.6.2 themes\nWith so-called themes, we can change the layout of the graphic. Other themes include theme_light(), theme_classic(), or theme_void(). A full list can be found here. Additionally, the {ggthemes} package (install.packages('ggthemes')) offers a wide selection.\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = factor(zpsex))) + \n  geom_point(size = 2) + \n  theme_minimal()\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = factor(zpsex))) + \n  geom_point(size = 2) +\n  theme_dark()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.6.3 Colors\n\np1 &lt;- ggplot(data = pend_small, aes(x = palter, y = azges1, color = factor(zpsex))) + \n  geom_point(size = 3) \n\nIn addition to the colors used in the example for fill, countless other colors can be used with scale_fill_manual and scale_color_manual:\n\nHere you can find an overview of all color names that are recognized.\nAlternatively, HEX codes can also be specified, which can be created using tools like the Adobe Color Wheel or Color Hex.\n\np1 +  scale_color_manual(values = c(\"dodgerblue4\",\"sienna1\"),\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") )\np1 +  scale_color_manual(values = c(\"#005b96\",\"#6497b1\"),\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.6.3.1 ColorBrewer\nAs an alternative to manually selecting colors with scale_fill_manual and scale_color_manual, you can use predefined color palettes from colorbrewer with scale_fill_brewer(). Simply use scale_fill_brewer() instead of scale_fill_manual and specify one of the palettes instead of values—an overview can be found here. ColorBrewer palettes are integrated into ggplot2.\n\np1 +\n  scale_color_brewer(palette = \"RdYlBu\",\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") ) \n\n\n\n\n\n\n\n\n\n\n5.6.3.2 viridis\nSimilarly, there are {viridis} palettes, which are “colorblind-safe” and are also integrated into {ggplot2}. However, note that for color selections based on a categorical variable, scale_color_viridis_d() should be used. For determining color along a numerical/metric variable, scale_color_viridis_c() should be used. Additionally, you can adjust the width of the color scale with begin and end:\np1 +\n  scale_color_viridis_d(option=\"magma\",\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") ) \np1 +\n  scale_color_viridis_d(option=\"magma\",begin = .65,end = .85,\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.6.3.3 Additional Color Palettes\nIn addition, there are countless packages that also offer scale_color_ and scale_fill_ functions: Here are two examples with {scico} and {MetBrewer}, which contains colors from images in the Metropolitan Museum of Art:\n\ninstall.packages('scico')\ninstall.packages(\"MetBrewer\")\n\n{scico} color palettes\n\n\n\n\n\n\n\n\n\n{MetBrewer} color palettes\n\n\n\n\n\n\n\n\n\nlibrary(scico)\np1 +\n  scale_color_scico_d(palette = \"oslo\",begin = .5,end = .8,\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") ) \nlibrary(MetBrewer)\np1 +\n  scale_color_met_d(name = \"Kandinsky\",\n                    breaks = c(1,2), labels = c(\"Men\", \"Women\") ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparable packages also exist for:\n\n{DutchMasters} - Color palettes from paintings by Dutch masters.\n{wesanderson} - Color palettes based on various Wes Anderson films (e.g., The Grand Budapest Hotel).\n{ochRe} - Color palettes “inspired by Australian art, landscapes, and wildlife.”\n{paletteer} offers a vast selection of various color palettes.\n\nCheck out the interactive color picker here\n\n\n\n5.6.4 Shapes\n\n\n\n\n\n\n\n\n\nZusätzlicher Überblick\n\n\n5.6.5 Linetypes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\n\n\nShapes und Linetypes at a glance in the R Cookbook",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html#useful-links",
    "href": "07_viz_translated.html#useful-links",
    "title": "5  Visualization with {ggplot2}",
    "section": "5.7 Useful links",
    "text": "5.7 Useful links\n\nThe Graphs chapter of the R Cookbook is an excellent resource for various options and a basic overview—for example, on adjusting the legend, line and point types, or the axes.\nAdjusting font size and color: This guide provides a good overview of how to modify font size and color in {ggplot2}.\nFrom Data to Viz offers a decision tree for various relationships and descriptions with example syntax.\n\n\n\n\n\n\n\n\n\n\n\nThe R Graph Gallery is even more extensive and offers additional visualization ideas.\nFor those who want to learn more about effective (and beautiful) data visualizations with {ggplot2}, Cédric Scherer’s tutorial is an excellent introduction. This workshop is great for further exploration.\nThis workshop offers additional insights on how to make data visualizations more appealing with {ggplot2}.\nA list of extensions for ggplot2.\nThe book on {ggplot2}.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "07_viz_translated.html#footnotes",
    "href": "07_viz_translated.html#footnotes",
    "title": "5  Visualization with {ggplot2}",
    "section": "",
    "text": "If we had specified color in aes, the corresponding command would be scale_color_manual.↩︎",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Visualization with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "09_reg.html",
    "href": "09_reg.html",
    "title": "6  Regression models",
    "section": "",
    "text": "6.1 Regression Models with lm()\nRegression models in R can be created with lm(). Here, we specify the variable for the y-axis (the dependent variable) and, after a ~, the variable for the x-axis (the independent variable). We will discuss the interpretation of the results in the coming weeks.\nlm(var2 ~ var1, data = dat1)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1)\n\nCoefficients:\n(Intercept)         var1  \n     -2.340        1.839\nThe value under var1 indicates how much the line changes up/down per “step to the right”. Thus, the line increases by 1.8389662 for each unit of var1. We can store the results under m1:\nm1 &lt;- lm(var2 ~ var1, data = dat1)\nWith summary(), we get a regression table:\nsummary(m1)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.372 -3.613  0.162  2.234 10.789 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  -2.3400     4.3454  -0.538   0.6096  \nvar1          1.8390     0.7727   2.380   0.0548 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.127 on 6 degrees of freedom\nMultiple R-squared:  0.4856,    Adjusted R-squared:  0.3999 \nF-statistic: 5.664 on 1 and 6 DF,  p-value: 0.05477\nm1 contains all the information about the model, and $coefficients is particularly helpful:\nm1$coefficients\n\n(Intercept)        var1 \n  -2.339960    1.838966 \n\nsummary(m1)$coefficients\n\n             Estimate Std. Error    t value   Pr(&gt;|t|)\n(Intercept) -2.339960  4.3453801 -0.5384938 0.60961706\nvar1         1.838966  0.7727028  2.3799139 0.05477457\nWe can view the individual values with View(m1):\nFor example, fitted.values contains the predicted values for each case.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg.html#lm1",
    "href": "09_reg.html#lm1",
    "title": "6  Regression models",
    "section": "",
    "text": "6.1.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg.html#calculating-models-for-specific-cases",
    "href": "09_reg.html#calculating-models-for-specific-cases",
    "title": "6  Regression models",
    "section": "6.2 Calculating Models for Specific Cases",
    "text": "6.2 Calculating Models for Specific Cases\nIf we want to recalculate the model, we have two options:\n\n6.2.1 Create a New Data Frame\nWe can keep multiple data.frame objects in memory in R. Thus, we can easily create a new data.frame containing only observations with var2 &lt; 20 and use this for our lm() command:\n\ndat1_u20 &lt;- dat1 %&gt;% filter(var2 &lt; 20)\nm2a &lt;- lm(var2 ~ var1, data = dat1_u20)\nsummary(m2a)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1_u20)\n\nResiduals:\n      1       2       3       4       5       6       7 \n-0.4737  0.1941 -1.4737  4.5230  1.1875 -2.4803 -1.4770 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   1.1382     1.9217   0.592    0.579\nvar1          0.6678     0.3877   1.722    0.146\n\nResidual standard error: 2.555 on 5 degrees of freedom\nMultiple R-squared:  0.3724,    Adjusted R-squared:  0.2469 \nF-statistic: 2.967 on 1 and 5 DF,  p-value: 0.1456\n\n\n\n\n6.2.2 Filter Directly in lm()\nWe can also incorporate the filter() command directly into the data= argument of lm():\n\nm2b &lt;- lm(var2 ~ var1, data = dat1 %&gt;% filter(var2 &lt; 20))\nsummary(m2b)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1 %&gt;% filter(var2 &lt; 20))\n\nResiduals:\n      1       2       3       4       5       6       7 \n-0.4737  0.1941 -1.4737  4.5230  1.1875 -2.4803 -1.4770 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   1.1382     1.9217   0.592    0.579\nvar1          0.6678     0.3877   1.722    0.146\n\nResidual standard error: 2.555 on 5 degrees of freedom\nMultiple R-squared:  0.3724,    Adjusted R-squared:  0.2469 \nF-statistic: 2.967 on 1 and 5 DF,  p-value: 0.1456",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg.html#regression-tables",
    "href": "09_reg.html#regression-tables",
    "title": "6  Regression models",
    "section": "6.3 Regression tables",
    "text": "6.3 Regression tables\nIf we want to compare these different models, a table is a good option.\nThere are numerous alternatives for creating regression tables, and my personal favorite is modelsummary() from the eponymous package {modelsummary}. It handles (almost) all types of models and offers a wide range of features, including Word output (more on this later) and coefficient plots (which we will also cover). Additionally, the documentation is excellent.\n\nfdz_install(\"modelsummary\")\n\n\nlibrary(modelsummary)\nmodelsummary(list(m1,m2a,m2b))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n                (3)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  -2.340\n                  1.138\n                  1.138\n                \n                \n                  \n                  (4.345)\n                  (1.922)\n                  (1.922)\n                \n                \n                  var1\n                  1.839\n                  0.668\n                  0.668\n                \n                \n                  \n                  (0.773)\n                  (0.388)\n                  (0.388)\n                \n                \n                  Num.Obs.\n                  8\n                  7\n                  7\n                \n                \n                  R2\n                  0.486\n                  0.372\n                  0.372\n                \n                \n                  R2 Adj.\n                  0.400\n                  0.247\n                  0.247\n                \n                \n                  AIC\n                  55.4\n                  36.6\n                  36.6\n                \n                \n                  BIC\n                  55.6\n                  36.5\n                  36.5\n                \n                \n                  Log.Lik.\n                  -24.702\n                  -15.321\n                  -15.321\n                \n                \n                  F\n                  5.664\n                  2.967\n                  2.967\n                \n                \n                  RMSE\n                  5.31\n                  2.16\n                  2.16\n                \n        \n      \n    \n\n\n\nWe will delve a bit more into the customization options for {modelsummary} later, but here are two key options for now:\n\nBy using stars = T, we can display the significance levels with the common star codes (*: p &lt; .05, etc.)\nBy using gof_omit = \"IC|RM|Log\", we can hide the goodness of fit statistics that have IC, RM, or Log in their names (such as AIC, BIC, RMSE, and LogLikelihood)\nBy using \"Name\" = in list(), we can specify names:\n\n\nmodelsummary(list(\"m1\"=m1,\"m2a\"=m2a,\"m2b\"=m2b),stars = T,gof_omit = \"IC|RM|Log\")\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                m1\n                m2a\n                m2b\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n        \n                \n                  (Intercept)\n                  -2.340\n                  1.138\n                  1.138\n                \n                \n                  \n                  (4.345)\n                  (1.922)\n                  (1.922)\n                \n                \n                  var1\n                  1.839+\n                  0.668\n                  0.668\n                \n                \n                  \n                  (0.773)\n                  (0.388)\n                  (0.388)\n                \n                \n                  Num.Obs.\n                  8\n                  7\n                  7\n                \n                \n                  R2\n                  0.486\n                  0.372\n                  0.372\n                \n                \n                  R2 Adj.\n                  0.400\n                  0.247\n                  0.247\n                \n                \n                  F\n                  5.664\n                  2.967\n                  2.967\n                \n        \n      \n    \n\n\n\nThe output = option allows us to export the modelsummary as .docx-file:\n\nmodelsummary(list(\"m1\"=m1,\"m2a\"=m2a,\"m2b\"=m2b),stars = T,gof_omit = \"IC|RM|Log\",output = \"./results/Regression_table.docx\")\n\n\n6.3.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg.html#categorical-independent-variables",
    "href": "09_reg.html#categorical-independent-variables",
    "title": "6  Regression models",
    "section": "6.4 Categorical Independent Variables",
    "text": "6.4 Categorical Independent Variables\nOf course, we can also include categorical independent variables in our model. However, we need to define the relevant variables as factors to inform R that the numeric values should not be interpreted numerically.\nFor instance, in our small example, educ represents education levels where 1 stands for basic education, 2 for intermediate, and 3 for high education.\n\ndat1\n\n  id var1 var2 educ gend  x\n1  1    2    2    3    2  2\n2  2    1    2    1    1  1\n3  3    2    1    2    1  2\n4  4    5    9    2    2  4\n5  5    7    7    1    1  1\n6  6    8    4    3    2 NA\n7  7    9   25    2    1 NA\n8  8    5    3   -1    2 NA\n\nm3 &lt;- lm(var2 ~ factor(educ), dat1)\nsummary(m3)\n\n\nCall:\nlm(formula = var2 ~ factor(educ), data = dat1)\n\nResiduals:\n         1          2          3          4          5          6          7 \n-1.000e+00 -2.500e+00 -1.067e+01 -2.667e+00  2.500e+00  1.000e+00  1.333e+01 \n         8 \n-1.277e-15 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)    3.000e+00  8.848e+00   0.339    0.752\nfactor(educ)1  1.500e+00  1.084e+01   0.138    0.897\nfactor(educ)2  8.667e+00  1.022e+01   0.848    0.444\nfactor(educ)3 -1.088e-15  1.084e+01   0.000    1.000\n\nResidual standard error: 8.848 on 4 degrees of freedom\nMultiple R-squared:  0.2848,    Adjusted R-squared:  -0.2516 \nF-statistic: 0.531 on 3 and 4 DF,  p-value: 0.685\n\n\nIt’s even better if we label educ beforehand:\n\ndat1$ed_fct &lt;- factor(dat1$educ, levels = 1:3,\n                        labels = c(\"basic\", \"medium\", \"high\"))\ndat1\n\n  id var1 var2 educ gend  x ed_fct\n1  1    2    2    3    2  2   high\n2  2    1    2    1    1  1  basic\n3  3    2    1    2    1  2 medium\n4  4    5    9    2    2  4 medium\n5  5    7    7    1    1  1  basic\n6  6    8    4    3    2 NA   high\n7  7    9   25    2    1 NA medium\n8  8    5    3   -1    2 NA   &lt;NA&gt;\n\n\nThen use the factor in the regression command:\n\nm3 &lt;- lm(var2 ~ ed_fct, dat1)\nsummary(m3)\n\n\nCall:\nlm(formula = var2 ~ ed_fct, data = dat1)\n\nResiduals:\n      1       2       3       4       5       6       7 \n -1.000  -2.500 -10.667  -2.667   2.500   1.000  13.333 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)     4.500      6.257   0.719    0.512\ned_fctmedium    7.167      8.077   0.887    0.425\ned_fcthigh     -1.500      8.848  -0.170    0.874\n\nResidual standard error: 8.848 on 4 degrees of freedom\n  (1 Beobachtung als fehlend gelöscht)\nMultiple R-squared:  0.2594,    Adjusted R-squared:  -0.1109 \nF-statistic: 0.7005 on 2 and 4 DF,  p-value: 0.5485\n\n\n\nCompared to educ = basic, the predicted value for var2 when educ = medium is 7.17 higher.\nCompared to educ = basic, the predicted value for var2 when educ = high is -1.5 higher.\n\nWe can also change the reference category:\n\ndat1$ed_fct &lt;- relevel(dat1$ed_fct, ref = \"medium\")\nm3b &lt;- lm(var2 ~ ed_fct, dat1)\nsummary(m3b)\n\n\nCall:\nlm(formula = var2 ~ ed_fct, data = dat1)\n\nResiduals:\n      1       2       3       4       5       6       7 \n -1.000  -2.500 -10.667  -2.667   2.500   1.000  13.333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)   11.667      5.109   2.284   0.0844 .\ned_fctbasic   -7.167      8.077  -0.887   0.4251  \ned_fcthigh    -8.667      8.077  -1.073   0.3437  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.848 on 4 degrees of freedom\n  (1 Beobachtung als fehlend gelöscht)\nMultiple R-squared:  0.2594,    Adjusted R-squared:  -0.1109 \nF-statistic: 0.7005 on 2 and 4 DF,  p-value: 0.5485\n\n\n\nCompared to educ = medium, the predicted value for var2 when educ = basic is 7.17 lower.\nCompared to educ = medium, the predicted value for var2 when educ = high is 8.67 lower.\n\n\n6.4.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg.html#multiple-independent-variables",
    "href": "09_reg.html#multiple-independent-variables",
    "title": "6  Regression models",
    "section": "6.5 Multiple Independent Variables",
    "text": "6.5 Multiple Independent Variables\nTo include multiple independent variables in our regression models, we specify them using +:\n\nm4 &lt;- lm(var2 ~ ed_fct + var1, dat1)\nsummary(m4)\n\n\nCall:\nlm(formula = var2 ~ ed_fct + var1, data = dat1)\n\nResiduals:\n     1      2      3      4      5      6      7 \n 4.258  2.758 -4.824 -2.082 -2.758 -4.258  6.907 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   2.3187     5.8227   0.398    0.717\ned_fctbasic  -4.8297     6.0381  -0.800    0.482\ned_fcthigh   -8.0824     5.9411  -1.360    0.267\nvar1          1.7527     0.8347   2.100    0.127\n\nResidual standard error: 6.501 on 3 degrees of freedom\n  (1 Beobachtung als fehlend gelöscht)\nMultiple R-squared:  0.7002,    Adjusted R-squared:  0.4003 \nF-statistic: 2.335 on 3 and 3 DF,  p-value: 0.2521",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg.html#modelplot",
    "href": "09_reg.html#modelplot",
    "title": "6  Regression models",
    "section": "6.6 Coefficient Plots",
    "text": "6.6 Coefficient Plots\nIn addition to regression tables, {modelsummary} provides the modelplot() function, which makes it easy to create coefficient plots from one or more models:\n\nmodelplot(m4)\n\n\n\n\n\n\n\n\nFor model comparison, simply provide the models in a named list, and you can further customize the plot with the usual {ggplot2} commands:\n\nmodelplot(list(\"Model 1\" = m1,\n               \"Model 4\" = m4))\n\n\n\n\n\n\n\n\nWith coef_map, you can assign labels to the coefficients (note that (Intercept) does not get a name and is therefore omitted):\n\nmodelplot(list(\"Model 1\" = m1,\n               \"Model 4\" = m4),\n          coef_map = c(\"var1\" = \"Name for var1\",\n                       \"ed_fcthigh\" = \"Higher Education\",\n                       \"ed_fctbasic\" = \"Basic Education\"\n                          ))\n\n\n\n\n\n\n\n\nYou can also further customize the plot with the usual {ggplot2} commands:\n\nmodelplot(list(\"Model 1\" = m1,\n               \"Model 4\" = m4),\n          coef_map = c(\"var1\" = \"Name for var1\",\n                       \"ed_fcthigh\" = \"Higher Education\",\n                       \"ed_fctbasic\" = \"Basic\\nEducation\")) + # \\n inserts a line break\n  geom_vline(aes(xintercept = 0), linetype = \"dashed\", color = \"grey40\") +  # Add a 0 line\n  scale_color_manual(values = c(\"orange\", \"navy\")) +\n  theme_minimal(base_size = 15, base_family = \"serif\") \n\n\n\n\n\n\n\n\nWith {broom}, you can also create a data.frame from the regression results and create the ggplot entirely yourself - see appendix.\n\n\n\n\n\n\nmargins: {marginaleffects}\n\n\n\nAlternative visual summaries of regression results rely on marginal effects, contrasts, elasticities, or predictions. For all of these metric, see the {marginaleffects} package. There’s a special chapter for replicating Stata’s margins\n\n\n\n6.6.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg.html#exercises",
    "href": "09_reg.html#exercises",
    "title": "6  Regression models",
    "section": "6.7 Exercises",
    "text": "6.7 Exercises\nUse the following subset of the PASS CampusFile:\n\npend_ue08 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\") %&gt;% \n  filter(welle == 13, netges &gt; 0, azges1 &gt; 0, schul2 &gt; 1, palter &gt; 0)\n\n\n6.7.1 Regression model\n\nCreate an object mod1 with a linear regression model (lm) where netges (monthly net income in EUR) is the dependent variable and azges1 (working hours) is the independent variable! (see here)\nExamine the results of mod1 - what can you infer about the relationship between netges and azges1?\n\n\n\n6.7.2 Categorical Independent Variables\n\nCreate a regression model with the income of respondents (netges) as the dependent variable and the education level of the respondents schul as the independent variable:\n\n\n\n\n\n\n\n\n\nvalue\nlabel\n\n\n\n\n2\nFinished school without degree\n\n\n3\nSchool incorporating physically or mentally disabled children (Sonderschulabschluss)\n\n\n4\nLower secondary school (Hauptschulabschluss)\n\n\n5\nIntermediate secondary school (Realschulabschluss, Mittlere Reife)\n\n\n6\nUpper secondary Fachoberschule, Fachhochschulreife)\n\n\n7\nGeneral/subject-specific upper secondary school (Hochschulreife)\n\n\n\n\n\n\n\n\nEnsure that schul2 is defined as a factor. Assign the labels “No degree”, “Special education School”, “Secondary School”, “Intermediate Diploma”, “Vocational School”, “Abitur” to levels 2-7 and save the factor as a variable schul2_fct in your data.frame - see the code help below:\n\n\npend_ue08$schul2_fct &lt;-  \n  factor(pend_ue08$schul2, \n         levels = 2:7, \n         labels = c(\"No degree\", \"Special education School\", \"Secondary School\",\n                    \"Intermediate secondary school\", \n                    \"Upper secondary\", \"Abitur\"))\n\n\nCreate the regression model using this new factor variable for schul2_fct as the independent variable.\nChange the reference category to Intermediate secondary school (schul2 = 5) and estimate the model again.\n\n\n\n6.7.3 Multiple Independent Variables & Coefficient Plot\n\nAdjust the lm() model mod1 (with all cases from pend_u08) to include the education level (schul2) as an additional independent variable.\nAlso create a graphical comparison of the two models with and without the education level.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg.html#appendix",
    "href": "09_reg.html#appendix",
    "title": "6  Regression models",
    "section": "6.8 Appendix",
    "text": "6.8 Appendix\n\n6.8.1 Visualizing Regression Lines and Data\nWith geom_smooth(method = \"lm\"), we can also represent regression lines in {ggplot2}:\nWe can visualize our model with var1 and var2 as follows:\n\nlibrary(ggplot2)\nggplot(dat1, aes(x = var1, y = var2)) + \n  geom_point(size = 2) + \n  geom_smooth(method = \"lm\")  \n\n\n\n\n\n\n\n\nHere, it appears we have an outlier. In our small dataset, it is easy to find. In larger datasets, geom_text() can help us:\n\nggplot(dat1, aes(x = var1, y = var2)) + \n  geom_point(size = 2) + \n  geom_smooth(method = \"lm\")  +\n  geom_text(data = . %&gt;% filter(var2 &gt; 20), aes(y = var2 + 3, label = id), color = \"sienna1\")\n\n\n\n\n\n\n\n\nWe can also specify geom_ for just a subset by reassigning data = (not using the selection from the main ggplot() command) and applying a filter(). Additionally, we shift the label slightly above the point with var2 + 3.\n\ndat1 &lt;- dat1 %&gt;% select(-matches(\"compl\"))\n\n\n\n6.8.2 Predicted Values\nThe predicted values from lm() can be found under $fitted.values:\n\nm1$fitted.values\n\n        1         2         3         4         5         6         7         8 \n 1.337972 -0.500994  1.337972  6.854871 10.532803 12.371769 14.210736  6.854871 \n\n\nThese predicted values are simply the sum of the value under Intercept and the value under var1 multiplied by the respective value for var1.\n\nm1\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1)\n\nCoefficients:\n(Intercept)         var1  \n     -2.340        1.839  \n\n\nFor the first row of dat1, the predicted value from m1 is: 2.1351 + 0.5811 * 1 =2.7162\nThe values under fitted.values follow the order in the dataset, so we can simply add them as a new column in dat1:\n\ndat1$lm_predictions &lt;- m1$fitted.values\ndat1\n\n  id var1 var2 educ gend  x ed_fct lm_predictions\n1  1    2    2    3    2  2   high       1.337972\n2  2    1    2    1    1  1  basic      -0.500994\n3  3    2    1    2    1  2 medium       1.337972\n4  4    5    9    2    2  4 medium       6.854871\n5  5    7    7    1    1  1  basic      10.532803\n6  6    8    4    3    2 NA   high      12.371769\n7  7    9   25    2    1 NA medium      14.210736\n8  8    5    3   -1    2 NA   &lt;NA&gt;       6.854871\n\n\nThe plot shows how predictions based on m1 look: They correspond to the values on the blue line (the so-called regression line) at the respective points for var1.\n\n\nCode\nggplot(dat1, aes(x = var1, y = var2)) +\n  geom_point(size = 3) +      \n  geom_smooth(method = \"lm\", color = \"darkblue\", se = FALSE, size = .65) +\n  geom_point(aes(x = var1, y = lm_predictions), color = \"dodgerblue3\", size = 3) +\n  expand_limits(x = c(0,8), y = c(0,8))\n\n\n\n\n\n\n\n\n\n\n\n6.8.3 Residuals\nThe light blue points (i.e., the predictions from m1) are close to the actual points. However, even the light blue points do not perfectly overlap with the actual values. These deviations between the predicted and actual values are called residuals: \\[Residual = observed\\, value \\; - \\; predicted\\, value\\] \\[\\varepsilon_{\\text{i}} = \\text{y}_{i} - \\hat{y}_{i}\\] We can calculate these manually as the difference between the actual and predicted value or simply call them using m1$residuals:\n\nm1$residuals\n\n         1          2          3          4          5          6          7 \n 0.6620278  2.5009940 -0.3379722  2.1451292 -3.5328032 -8.3717694 10.7892644 \n         8 \n-3.8548708 \n\n\nWe can also store the residuals for lm in dat1:\n\ndat1$lm_residuals &lt;- m1$residuals\ndat1\n\n  id var1 var2 educ gend  x ed_fct lm_predictions lm_residuals\n1  1    2    2    3    2  2   high       1.337972    0.6620278\n2  2    1    2    1    1  1  basic      -0.500994    2.5009940\n3  3    2    1    2    1  2 medium       1.337972   -0.3379722\n4  4    5    9    2    2  4 medium       6.854871    2.1451292\n5  5    7    7    1    1  1  basic      10.532803   -3.5328032\n6  6    8    4    3    2 NA   high      12.371769   -8.3717694\n7  7    9   25    2    1 NA medium      14.210736   10.7892644\n8  8    5    3   -1    2 NA   &lt;NA&gt;       6.854871   -3.8548708\n\n\nHere are the residuals for lm shown in light blue:\n\n\nCode\nggplot(dat1, aes(x = var1, y = var2)) + \n  geom_smooth(method = \"lm\", color = \"darkblue\", se = FALSE, size = .65) +\n  geom_segment(aes(x = var1, xend = var1, y = var2, yend = lm_predictions), color = \"dodgerblue3\", size = .65, linetype = 1) +\n  geom_point(size = 3) +\n  geom_point(aes(x = var1, y = lm_predictions), color = \"dodgerblue3\", size = 3) +\n  expand_limits(x = c(0,8), y = c(0,8))\n\n\n\n\n\n\n\n\n\n\n\n6.8.4 Checking Assumptions\nModel Dashboard\n\ninstall.packages(\"performance\")\n\n\nlibrary(performance)\n\nmodel_test &lt;- check_model(m4)\nplot(model_test)\n\n\n\n\n\n\n\n\n\n\n6.8.5 Test for Normal Distribution of Residuals\nGraphical check: Q-Q plot\n\nlibrary(ggfortify)\nautoplot(m1, which = 2)\n\n\n\n\n\n\n\n\n\n\nYou can check the normality assumption with the Shapiro-Wilk test & shapiro.test(). This tests the null hypothesis \\(H_0\\): “The residuals are normally distributed” against the alternative hypothesis \\(H_A\\): “The residuals significantly deviate from normal distribution.”\n\nshapiro.test(m1$residuals) \n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.95346, p-value = 0.746\n\n\n\n\n6.8.6 Test for Homoscedasticity\nHomoscedasticity is present when the predicted values are approximately equally distant from the actual values (m1\\$fitted.values) across the entire range of values. There is both a graphical method for checking this and a formal test. For the graphical check, the predicted values and the residuals are plotted as a scatterplot. The autoplot() function can be helpful here:\n\nautoplot(m1, which = 1)\n\n\n\n\n\n\n\n\n\n\nThe associated test is the Breusch-Pagan test. This test evaluates the null hypothesis (\\(H_0\\)) of “homoscedasticity” against the alternative hypothesis (\\(H_A\\)) of “heteroscedasticity.” The p-value indicates the probability with which we must reject the homoscedasticity assumption. In R, you can use bptest from the lmtest package for this:\n\ninstall.packages(\"lmtest\")\n\n\nlibrary(lmtest)\nbptest(m3)\n\n\n    studentized Breusch-Pagan test\n\ndata:  m3\nBP = 3.6069, df = 2, p-value = 0.1647\n\n\n\n\n6.8.7 Test for Multicollinearity\n\ninstall.packages(\"car\")\n\n\n# library(car)\npendx &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",n_max = 300)  %&gt;% filter(netges &gt;0, palter &gt;0 )\nmox &lt;- lm(netges ~ palter + azges1, data=pendx)\ncar::vif(mox)\n\n  palter   azges1 \n1.000133 1.000133 \n\n\n\nA common threshold for the Variance Inflation Factor (VIF) is 10. Values of VIF above 10 indicate a serious multicollinearity problem, and often measures are recommended starting from a stricter threshold of about 5.00. In this specific example, all independent variables are within acceptable limits according to both thresholds.\nIf multicollinearity is present, there are several ways to address it: We can exclude one or more independent variables from the model. This is ultimately a substantive question and cannot be resolved with a standard recipe. Alternatively, we can combine the collinear independent variables into index variables. For example, we could create a common index, such as the average of the respective independent variables.\n\n\n\n6.8.8 Comparing Regression Models\nWith the {performance} package, we can also perform a comprehensive model comparison:\n\ninstall.packages(\"performance\")\n\n\nlibrary(performance)\ncompare_performance(m1, m4, metrics = c(\"R2\", \"R2_adj\"))\n\nWhen comparing models, please note that probably not all models were fit\n  from same data.\n\n\n# Comparison of Model Performance Indices\n\nName | Model |    R2 | R2 (adj.)\n--------------------------------\nm1   |    lm | 0.486 |     0.400\nm4   |    lm | 0.700 |     0.400\n\n\n\n\n6.8.9 Individual Coefficient Plots with {broom}\nmodelplot() offers a quick way to create coefficient plots, but I often use {broom}. Using broom::tidy(..., conf.int = TRUE), we get a data.frame with the results of the regression model, which we can then process further in {ggplot2}—if the standard solution from modelplot() doesn’t meet our needs or preferences:\n\nlibrary(broom) ## already loaded as part of the tidyverse\ntidy(m3, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term         estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)      4.5       6.26     0.719   0.512    -12.9      21.9\n2 ed_fctmedium     7.17      8.08     0.887   0.425    -15.3      29.6\n3 ed_fcthigh      -1.5       8.85    -0.170   0.874    -26.1      23.1\n\ntidy(m3, conf.int = TRUE) %&gt;% \n  mutate(term = str_replace(term, \"ed_fct\", \"Education: \")) %&gt;% \n  ggplot(aes(y = term, x = estimate)) +\n  geom_vline(aes(xintercept = 0), linetype = \"dashed\", color = \"navy\") +\n  geom_errorbarh(aes(xmin = conf.low, xmax  = conf.high), height = .1) + \n  geom_point(color = \"orange\", shape = 18, size = 7) +\n  theme_minimal(base_size = 16)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regression models</span>"
    ]
  },
  {
    "objectID": "09_reg2.html",
    "href": "09_reg2.html",
    "title": "7  Regression Models: Extensions",
    "section": "",
    "text": "7.1 Keeping Only Complete Rows\nWhen we compare models m1 and m3, we see different sample sizes:\nm1 &lt;- lm(var2 ~ var1, data = dat1)  \nm4 &lt;- lm(var2 ~ ed_fct + var1, data = dat1)\nmodelsummary(list(\"m1\"=m1,\"m4\"=m4), gof_omit = \"IC|RM|Log|F\")\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                m1\n                m4\n              \n        \n        \n        \n                \n                  (Intercept)\n                  -2.340\n                  -2.511\n                \n                \n                  \n                  (4.345)\n                  (5.681)\n                \n                \n                  var1\n                  1.839\n                  1.753\n                \n                \n                  \n                  (0.773)\n                  (0.835)\n                \n                \n                  ed_fctmedium\n                  \n                  4.830\n                \n                \n                  \n                  \n                  (6.038)\n                \n                \n                  ed_fcthigh\n                  \n                  -3.253\n                \n                \n                  \n                  \n                  (6.554)\n                \n                \n                  Num.Obs.\n                  8\n                  7\n                \n                \n                  R2\n                  0.486\n                  0.700\n                \n                \n                  R2 Adj.\n                  0.400\n                  0.400\nIt appears that in model m4, one case is lost with ed_fct. Why is that? It’s worth taking a look at the data:\ndat1\n\n  id var1 var2 educ gend  x ed_fct\n1  1    2    2    3    2  2   high\n2  2    1    2    1    1  1  basic\n3  3    2    1    2    1  2 medium\n4  4    5    9    2    2  4 medium\n5  5    7    7    1    1  1  basic\n6  6    8    4    3    2 NA   high\n7  7    9   25    2    1 NA medium\n8  8    5    3   -1    2 NA   &lt;NA&gt;\nThe value for ed_fct is missing for id = 8.\nTo compare the models, we should use only the rows where ed_fct values are available. We can manually select these rows (excluding id=8), but this can be cumbersome with larger datasets.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Regression Models: Extensions</span>"
    ]
  },
  {
    "objectID": "09_reg2.html#complcses",
    "href": "09_reg2.html#complcses",
    "title": "7  Regression Models: Extensions",
    "section": "",
    "text": "7.1.1 complete.cases()\nHere, complete.cases() is helpful. This function creates a logical variable that is TRUE for all complete cases (i.e., without NA). Incomplete cases are marked as FALSE. We specify which variables to consider for this check and add the variable to the dataset as a new column. For model 1, a case is considered complete if both var2 and var1 are present. So, we select the relevant variables with select() and apply complete.cases to this selection:\n\ndat1 %&gt;% select(var1, var2) %&gt;% complete.cases(.) \n\n[1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\ndat1$compl_m1 &lt;- dat1 %&gt;% select(var1, var2) %&gt;% complete.cases(.) \ndat1\n\n  id var1 var2 educ gend  x ed_fct compl_m1\n1  1    2    2    3    2  2   high     TRUE\n2  2    1    2    1    1  1  basic     TRUE\n3  3    2    1    2    1  2 medium     TRUE\n4  4    5    9    2    2  4 medium     TRUE\n5  5    7    7    1    1  1  basic     TRUE\n6  6    8    4    3    2 NA   high     TRUE\n7  7    9   25    2    1 NA medium     TRUE\n8  8    5    3   -1    2 NA   &lt;NA&gt;     TRUE\n\n\n\n\n\n\n\n\ncomplete.cases() alone searches for NA in all variables\n\n\n\n\n\nNote: if we do not specify variables, NA will be considered from all variables, including x, which we are not interested in here:\n\ndat1 %&gt;% complete.cases(.) \n\n[1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE\n\ndat1$compl &lt;- dat1 %&gt;% complete.cases(.) \ndat1\n\n  id var1 var2 educ gend  x ed_fct compl_m1 compl\n1  1    2    2    3    2  2   high     TRUE  TRUE\n2  2    1    2    1    1  1  basic     TRUE  TRUE\n3  3    2    1    2    1  2 medium     TRUE  TRUE\n4  4    5    9    2    2  4 medium     TRUE  TRUE\n5  5    7    7    1    1  1  basic     TRUE  TRUE\n6  6    8    4    3    2 NA   high     TRUE FALSE\n7  7    9   25    2    1 NA medium     TRUE FALSE\n8  8    5    3   -1    2 NA   &lt;NA&gt;     TRUE FALSE\n\n\n\n\n\nWe do the same for model m4, which includes ed_fct in addition to var2 and var1:\n\ndat1$compl_m4 &lt;- dat1 %&gt;% select(var1, var2, ed_fct) %&gt;% complete.cases(.)\n\nHere’s how it looks in the dataset:\n\ndat1\n\n  id var1 var2 educ gend  x ed_fct compl_m1 compl_m4\n1  1    2    2    3    2  2   high     TRUE     TRUE\n2  2    1    2    1    1  1  basic     TRUE     TRUE\n3  3    2    1    2    1  2 medium     TRUE     TRUE\n4  4    5    9    2    2  4 medium     TRUE     TRUE\n5  5    7    7    1    1  1  basic     TRUE     TRUE\n6  6    8    4    3    2 NA   high     TRUE     TRUE\n7  7    9   25    2    1 NA medium     TRUE     TRUE\n8  8    5    3   -1    2 NA   &lt;NA&gt;     TRUE    FALSE\n\n\n\n\n7.1.2 Finding Cases with Missing Values\nNow, we can filter by these variables and examine these cases more closely. We filter for cases that are included in m1 (i.e., compl_m1 = TRUE) but not in m4 (compl_m4 = FALSE):\n\ndat1 %&gt;% filter(compl_m1 == T & compl_m4 == F) \n\n  id var1 var2 educ gend  x ed_fct compl_m1 compl_m4\n1  8    5    3   -1    2 NA   &lt;NA&gt;     TRUE    FALSE\n\n\n\n\n7.1.3 Calculating Models with Only Complete Cases\nWe can now create model m1 to include only cases that are also considered in model m4:\n\nm1_m4vars &lt;- lm(var2 ~ var1, data = filter(dat1, compl_m4 == T))\nmodelsummary(list(\"m1\"=m1,\"m1 with m4vars\"=m1_m4vars,\"m4\"=m4), gof_omit = \"IC|RM|Log|F\")\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                m1\n                m1 with m4vars\n                m4\n              \n        \n        \n        \n                \n                  (Intercept)\n                  -2.340\n                  -1.832\n                  -2.511\n                \n                \n                  \n                  (4.345)\n                  (4.646)\n                  (5.681)\n                \n                \n                  var1\n                  1.839\n                  1.848\n                  1.753\n                \n                \n                  \n                  (0.773)\n                  (0.814)\n                  (0.835)\n                \n                \n                  ed_fctmedium\n                  \n                  \n                  4.830\n                \n                \n                  \n                  \n                  \n                  (6.038)\n                \n                \n                  ed_fcthigh\n                  \n                  \n                  -3.253\n                \n                \n                  \n                  \n                  \n                  (6.554)\n                \n                \n                  Num.Obs.\n                  8\n                  7\n                  7\n                \n                \n                  R2\n                  0.486\n                  0.508\n                  0.700\n                \n                \n                  R2 Adj.\n                  0.400\n                  0.409\n                  0.400\n                \n        \n      \n    \n\n\n\nNow, both m1 with m4vars and m4 have the same number of cases, allowing for a direct comparison of the results.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Regression Models: Extensions</span>"
    ]
  },
  {
    "objectID": "09_reg2.html#inter",
    "href": "09_reg2.html#inter",
    "title": "7  Regression Models: Extensions",
    "section": "7.2 Interactions",
    "text": "7.2 Interactions\nInteractions between two variables can be calculated using *:\n\ndat1$g_fct &lt;- factor(dat1$gend, levels = 1:2,\n                     labels = c(\"women\",\"men\"))\nm5 &lt;- lm(var2 ~ var1 * g_fct, data = dat1)\nsummary(m5)\n\n\nCall:\nlm(formula = var2 ~ var1 * g_fct, data = dat1)\n\nResiduals:\n      1       2       3       4       5       6       7       8 \n-1.5000  2.6145 -0.8827  4.5000 -7.3687 -1.5000  5.6369 -1.5000 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)    -3.1117     4.7702  -0.652   0.5498  \nvar1            2.4972     0.8211   3.041   0.0384 *\ng_fctmen        5.9451     8.4973   0.700   0.5227  \nvar1:g_fctmen  -2.1639     1.5331  -1.411   0.2310  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.493 on 4 degrees of freedom\nMultiple R-squared:  0.7244,    Adjusted R-squared:  0.5177 \nF-statistic: 3.504 on 3 and 4 DF,  p-value: 0.1286\n\n\navg_slopes() from {marginaleffects} helps to calculate the marginal effects/slopes of a one-unit increase in var1 for each subgroup of g_fct:\n\navg_slopes(m5,\n           variables = \"var1\",\n           by = \"g_fct\")\n\n\n g_fct Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 % 97.5 %\n women    2.497      0.821 3.041  0.00236 8.7  0.888   4.11\n men      0.333      1.295 0.257  0.79684 0.3 -2.204   2.87\n\nTerm: var1\nType:  response \nComparison: dY/dX\n\n\nInteractions should always be visualized. plot_predictions() from {marginaleffects} is a very helpful function to plot the predicted values :\n\nplot_predictions(m5, condition = c(\"var1\", \"g_fct\"))\n\n\n\n\n\n\n\n\nWe can modify this plot using familiar {ggplot2} commands:\n\nplot_predictions(m5, condition = c(\"var1\", \"g_fct\")) + \n  scale_color_manual(values = c(\"orange\",\"lightskyblue3\"), breaks = c(\"women\",\"men\"), labels=c(\"Women\",\"Men\")) +\n  scale_fill_manual(values = c(\"orange\",\"lightskyblue3\"), breaks = c(\"women\",\"men\"), labels=c(\"Women\",\"Men\")) +\n  labs(title = \"Predicted Values for var2\",\n       color = \"Gender\", fill = \"Gender\",\n       x = \"Values for var1\",\n       y = \"Predicted Values for var1\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nAlternatively, we can create the “marginsplot” step by step ourselves",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Regression Models: Extensions</span>"
    ]
  },
  {
    "objectID": "09_reg2.html#quad",
    "href": "09_reg2.html#quad",
    "title": "7  Regression Models: Extensions",
    "section": "7.3 Quadratic Terms & Polynomials",
    "text": "7.3 Quadratic Terms & Polynomials\n\nm6 &lt;- lm(var2 ~ var1 + I(var1^2), data = dat1 %&gt;% filter(id != 7))\nsummary(m6)\n\n\nCall:\nlm(formula = var2 ~ var1 + I(var1^2), data = dat1 %&gt;% filter(id != \n    7))\n\nResiduals:\n      1       2       3       4       5       6       7 \n-0.5443  1.4334 -1.5443  3.2043  1.2713 -1.0248 -2.7957 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  -1.8580     3.4066  -0.545    0.614\nvar1          2.6481     1.9083   1.388    0.238\nI(var1^2)    -0.2235     0.2110  -1.059    0.349\n\nResidual standard error: 2.524 on 4 degrees of freedom\nMultiple R-squared:  0.5099,    Adjusted R-squared:  0.2648 \nF-statistic: 2.081 on 2 and 4 DF,  p-value: 0.2402\n\n\nAgain, {marginaleffects} provides a helpful function to visualize the shape of predicted values:\n\nplot_predictions(m6, condition = \"var1\") # conditional adjusted predictions \n\n\n\n\n\n\n\nplot_slopes(m6, variables = \"var1\", condition = \"var1\") # conditional marginal effects",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Regression Models: Extensions</span>"
    ]
  },
  {
    "objectID": "09_reg2.html#logistic-regression-model",
    "href": "09_reg2.html#logistic-regression-model",
    "title": "7  Regression Models: Extensions",
    "section": "7.4 Logistic regression model",
    "text": "7.4 Logistic regression model\nFor binary dependent variables, logistic regression models are a widely used tool. We can fit logistic regression models in R using glm() - for an example, we turn to PSM0100 (Usage of social networks yes = 1, no = 2) :\n\\[\\begin{equation*}\n\\widehat{Logit(soc\\_med=1)} = \\widehat{ln\\left(\\frac{P(soc\\_med=1)}{1-P(soc\\_med=1)}\\right)} = \\hat\\beta0 + \\hat{\\beta1}\\times \\texttt{palter}\n\\end{equation*}\\]\n\npend10 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                          col_select = c(\"palter\",\"PSM0100\")) %&gt;% \n  filter(PSM0100&gt;0) %&gt;% \n  mutate(soc_med = 2- PSM0100)  # convert into 0/1 dummy variable\n\npend10 %&gt;% count(soc_med,PSM0100) # check: soc_med = 1 -&gt; yes, soc_med = 0 -&gt; no\n\n# A tibble: 2 × 3\n  soc_med PSM0100       n\n    &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;int&gt;\n1       0 2 [No]     2873\n2       1 1 [Yes]    2589\n\n\n\nm2 &lt;- glm(soc_med ~ palter, family = \"binomial\", data = pend10)\nsummary(m2)\n\n\nCall:\nglm(formula = soc_med ~ palter, family = \"binomial\", data = pend10)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  3.194321   0.107660   29.67   &lt;2e-16 ***\npalter      -0.073518   0.002315  -31.75   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 7557.2  on 5461  degrees of freedom\nResidual deviance: 6217.5  on 5460  degrees of freedom\nAIC: 6221.5\n\nNumber of Fisher Scoring iterations: 3\n\n\nThe interpretation of the \\(\\beta\\) coefficients from a logistic regression model pertains to the logits (the logarithms of the odds): There is a statistically significant relationship at the 0.001 level between age and the probability of using social media. With each additional year of age, there is a decrease of 0.073518 in the logits* of the respondents using social media.*\n\n7.4.1 average marginal effects\nLogits are quite cumbersome—so how does the probability of \\(\\texttt{soc\\_med} = 1\\) change with palter? Here, we face the challenge that the derivative of the “inverse function” is not as straightforward as in the case of OLS. If we modify the regression equation from above1 with exp() and \\(p=\\frac{Odds}{1+Odds}\\), we get:\n\\[\\begin{equation*}\n\\widehat{P(soc\\_med=1)} = \\frac{e^{\\hat\\beta0+\\hat\\beta1 \\times \\texttt{palter}}}{1+e^{\\hat\\beta0+\\hat{\\beta1}\\times \\texttt{palter}}}\n\\end{equation*}\\]\nWe would need to differentiate this expression with respect to palter to determine how the predicted probability of \\(\\texttt{soc\\_med} = 1\\) changes with each additional year of respondent age. Given that palter appears in both the exponent of the e function and both the numerator and denominator (“top and bottom”), the differentiation becomes significantly more complex than in the previous lm() models.\nFor our purposes, it is crucial to note that to compute changes in the predicted probabilities, we need the so-called marginal effects from the {marginaleffects} package. This package includes the avg_slopes() function, which allows us to calculate a \\(\\beta\\) representing the change in the probability of \\(\\texttt{soc\\_med} = 1\\) in relation to palter. This is known as the average marginal effect, as it provides the average marginal change in the dependent variable for a one-unit increase in the independent variable.\n\nfdz_install(\"marginaleffects\") # nur einmal nötig\nlibrary(marginaleffects)\n\n\navg_slopes(m2)\n\n\n Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 %  97.5 %\n  -0.0142   0.000266 -53.4   &lt;0.001 Inf -0.0147 -0.0137\n\nTerm: palter\nType:  response \nComparison: dY/dX\n\n\nWith each additional year of age, there is on average a decrease of 0.01419 (1.419 percentage points) in the probability of using social media.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Regression Models: Extensions</span>"
    ]
  },
  {
    "objectID": "09_reg2.html#gew",
    "href": "09_reg2.html#gew",
    "title": "7  Regression Models: Extensions",
    "section": "7.5 Weighted Regression Model",
    "text": "7.5 Weighted Regression Model\nThe {survey} package allows including weights when fitting regression model:\n\nfdz_install(\"survey\")\n\n\nlibrary(survey)\npend &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\") %&gt;% filter(netges &gt; 0 , palter &gt; 0, azges1 &gt; 0) %&gt;% \n  mutate(zpsex_fct = factor(zpsex, levels = 1:2, labels = c(\"M\",\"W\")))\nwgt_df &lt;- haven::read_dta(\"./orig/pweights_cf_W13.dta\")\npend_wgt &lt;- pend %&gt;% left_join(wgt_df, by = join_by(pnr,welle))\n\nmodx &lt;- lm(netges ~ palter + I(palter^2),data=pend) # conventional lm() model\n\n# create new data.frame including weights using svydesign() from survey-package\npend_weighted &lt;- svydesign(id      = ~pnr, # id variable\n                           weights = ~wqp, # weight variable\n                           data    = pend_wgt) # original unweighted data \n\n# family = gaussian() provides a linear regression model, like lm() - but respecting weights\nsurvey_modx &lt;- svyglm(netges ~ palter + I(palter^2), \n                    family = gaussian(), data = etb18,design = pend_weighted)\n\nmodelsummary(list(\"lm()\"=modx,\"svyglm()\"= survey_modx),gof_omit = \"RM|IC|Log\")\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                lm()\n                svyglm()\n              \n        \n        \n        \n                \n                  (Intercept)\n                  811.753\n                  463.721\n                \n                \n                  \n                  (354.363)\n                  (504.015)\n                \n                \n                  palter\n                  24.640\n                  53.580\n                \n                \n                  \n                  (17.071)\n                  (26.471)\n                \n                \n                  I(palter^2)\n                  -0.147\n                  -0.489\n                \n                \n                  \n                  (0.197)\n                  (0.314)\n                \n                \n                  Num.Obs.\n                  7996\n                  7996\n                \n                \n                  R2\n                  0.004\n                  0.007\n                \n                \n                  R2 Adj.\n                  0.004\n                  -2.252\n                \n                \n                  F\n                  15.525\n                  8.495",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Regression Models: Extensions</span>"
    ]
  },
  {
    "objectID": "09_reg2.html#rbst",
    "href": "09_reg2.html#rbst",
    "title": "7  Regression Models: Extensions",
    "section": "7.6 “Robust” Standard Errors",
    "text": "7.6 “Robust” Standard Errors\nOften, standard errors need to be adjusted for violations of general assumptions (homoscedasticity, etc.).\nThe good news is that R offers several ways to correct standard errors, including with {sandwich} or {estimatr}.\nA very simple option is the correction of standard errors in {modelsummary}, which we will look at in more detail:\nWe can request heteroskedasticity-consistent (HC) “robust” standard errors with the vcov option HC in modelsummary(). The help page for {modelsummary} provides a list of all options.\nOne option is also stata, to replicate results from Stata’s , robust. More here about the background and differences.\nWe can estimate the following model:\n\nmod1 &lt;- lm(netges ~ palter + I(palter^2),data=pend)\n\nIn the modelsummary(), we can now display the same model with different adjustments for the standard errors:\n\nlibrary(modelsummary)\nmodelsummary(list(mod1,mod1,mod1,mod1),vcov = c(\"classical\",\"HC\",\"HC2\",\"stata\"),gof_omit = \"RM|IC|Log\")\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n                (3)\n                (4)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  811.753\n                  811.753\n                  811.753\n                  811.753\n                \n                \n                  \n                  (354.363)\n                  (171.599)\n                  (171.543)\n                  (171.520)\n                \n                \n                  palter\n                  24.640\n                  24.640\n                  24.640\n                  24.640\n                \n                \n                  \n                  (17.071)\n                  (8.923)\n                  (8.920)\n                  (8.919)\n                \n                \n                  I(palter^2)\n                  -0.147\n                  -0.147\n                  -0.147\n                  -0.147\n                \n                \n                  \n                  (0.197)\n                  (0.112)\n                  (0.112)\n                  (0.112)\n                \n                \n                  Num.Obs.\n                  7996\n                  7996\n                  7996\n                  7996\n                \n                \n                  R2\n                  0.004\n                  0.004\n                  0.004\n                  0.004\n                \n                \n                  R2 Adj.\n                  0.004\n                  0.004\n                  0.004\n                  0.004\n                \n                \n                  F\n                  15.525\n                  23.449\n                  23.441\n                  23.440\n                \n                \n                  Std.Errors\n                  IID\n                  HC\n                  HC2\n                  HC1\n                \n        \n      \n    \n\n\n\nFor clustered SEs, we specify ~clustervariable:\n\nmodelsummary(mod1, vcov = c(\"classical\",~pnr), stars = T,gof_omit = \"RM|IC|Log|F\")\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n        \n                \n                  (Intercept)\n                  811.753*\n                  811.753**\n                \n                \n                  \n                  (354.363)\n                  (274.972)\n                \n                \n                  palter\n                  24.640\n                  24.640+\n                \n                \n                  \n                  (17.071)\n                  (14.475)\n                \n                \n                  I(palter^2)\n                  -0.147\n                  -0.147\n                \n                \n                  \n                  (0.197)\n                  (0.185)\n                \n                \n                  Num.Obs.\n                  7996\n                  7996\n                \n                \n                  R2\n                  0.004\n                  0.004\n                \n                \n                  R2 Adj.\n                  0.004\n                  0.004\n                \n                \n                  Std.Errors\n                  IID\n                  by: pnr",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Regression Models: Extensions</span>"
    ]
  },
  {
    "objectID": "09_reg2.html#fe",
    "href": "09_reg2.html#fe",
    "title": "7  Regression Models: Extensions",
    "section": "7.7 Fixed Effects Models with {fixest}",
    "text": "7.7 Fixed Effects Models with {fixest}\n\nfdz_install(\"fixest\")\n\n{fixest}) offers a wide range of options: logistic FE models, multi-dimensional fixed effects, multiway clustering, etc. And it is very fast, e.g., faster than Stata’s reghdfe. For more details, the vignette is recommended.\nThe central function for estimating linear FE regression models is feols() - it works very similarly to lm(). We provide a formula following the pattern dependent variable ~ independent variable(s). We simply add the variable that specifies the FEs with |:\n\nlibrary(fixest)\nfe_mod1 &lt;- feols(netges ~ palter + I(palter^2) | pnr, data = pend)\nfe_mod1\n\nOLS estimation, Dep. Var.: netges\nObservations: 7,996\nFixed-effects: pnr: 2,444\nStandard-errors: Clustered (pnr) \n              Estimate Std. Error  t value   Pr(&gt;|t|)    \npalter      133.811281  14.558248  9.19144  &lt; 2.2e-16 ***\nI(palter^2)  -0.848429   0.154417 -5.49441 4.3261e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 1,222.2     Adj. R2: 0.513287\n                Within R2: 0.009765\n\n\n{fixest} automatically clusters the standard errors along the FE variable (here pnr). If we don’t want that, we can request unclustered SEs with the se option = \"standard\":\n\nsummary(fe_mod1, se = 'standard')\n\nOLS estimation, Dep. Var.: netges\nObservations: 7,996\nFixed-effects: pnr: 2,444\nStandard-errors: IID \n              Estimate Std. Error  t value   Pr(&gt;|t|)    \npalter      133.811281  39.896986  3.35392 0.00080209 ***\nI(palter^2)  -0.848429   0.429629 -1.97479 0.04834109 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 1,222.2     Adj. R2: 0.513287\n                Within R2: 0.009765\n\nsummary(fe_mod1, cluster = ~pnr)\n\nOLS estimation, Dep. Var.: netges\nObservations: 7,996\nFixed-effects: pnr: 2,444\nStandard-errors: Clustered (pnr) \n              Estimate Std. Error  t value   Pr(&gt;|t|)    \npalter      133.811281  14.558248  9.19144  &lt; 2.2e-16 ***\nI(palter^2)  -0.848429   0.154417 -5.49441 4.3261e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 1,222.2     Adj. R2: 0.513287\n                Within R2: 0.009765\n\n\n{modelsummary} shows the clustered SEs:\n\nmodelsummary(fe_mod1,gof_omit = \"R|IC|Log|F\",stars = T)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n        \n                \n                  palter\n                  133.811***\n                \n                \n                  \n                  (14.558)\n                \n                \n                  I(palter^2)\n                  -0.848***\n                \n                \n                  \n                  (0.154)\n                \n                \n                  Num.Obs.\n                  7996\n                \n                \n                  Std.Errors\n                  by: pnr",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Regression Models: Extensions</span>"
    ]
  },
  {
    "objectID": "09_reg2.html#mlvl",
    "href": "09_reg2.html#mlvl",
    "title": "7  Regression Models: Extensions",
    "section": "7.8 Multilevel Models with {lme4}",
    "text": "7.8 Multilevel Models with {lme4}\nWith lmer(), we can estimate a random intercept model by specifying ( 1 | pnr), which indicates that a separate random intercept should be calculated for each pnr:\n\nlibrary(lme4)\nml_m3 &lt;- lmer(netges ~ palter + I(palter^2) + ( 1 | pnr), data=pend)\n\nmodelsummary(list(ml_m3),gof_omit = \"R|IC|Log|F\")\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  754.388\n                \n                \n                  \n                  (392.459)\n                \n                \n                  palter\n                  18.523\n                \n                \n                  \n                  (19.083)\n                \n                \n                  I(palter^2)\n                  -0.020\n                \n                \n                  \n                  (0.222)\n                \n                \n                  SD (Intercept pnr)\n                  1327.674\n                \n                \n                  SD (Observations)\n                  1414.455\n                \n                \n                  Num.Obs.\n                  7996\n                \n        \n      \n    \n\n\n\nMore about multilevel models and {lme4} in blog posts by Rense Nieuwenhuis and Tristan Mahr.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Regression Models: Extensions</span>"
    ]
  },
  {
    "objectID": "09_reg2.html#links",
    "href": "09_reg2.html#links",
    "title": "7  Regression Models: Extensions",
    "section": "7.9 Links",
    "text": "7.9 Links\nHow to interpret statistical models in R using {marginaleffects} - deep dive into the background of marginal effects, predictions, adjusted predictions, elasticities, … and how you can fit them using R. Fans of Stata’s margins should take a look at a special chapter comparing margins to marginaleffects",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Regression Models: Extensions</span>"
    ]
  },
  {
    "objectID": "09_reg2.html#footnotes",
    "href": "09_reg2.html#footnotes",
    "title": "7  Regression Models: Extensions",
    "section": "",
    "text": "\\(\\widehat{Logit(soc\\_med=1)} = \\widehat{ln\\left(\\frac{P(soc\\_med=1)}{1-P(soc\\_med=1)}\\right)} = \\hat\\beta0 + \\hat{\\beta1}\\times \\texttt{palter}\\)↩︎",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Regression Models: Extensions</span>"
    ]
  },
  {
    "objectID": "10_raw_to_table.html",
    "href": "10_raw_to_table.html",
    "title": "8  From data to table & graph",
    "section": "",
    "text": "8.1 Exploring the variables\nFirst, we explore the variables available in the data set based on their variable labels (attributes(...)$label)\npass_df &lt;- read_dta(\"./orig/PENDDAT_cf_W13.dta\", n_max = 1) # load the first row only\nThis gives us one variable label:\nattributes(pass_df$pnr)$label\n\n[1] \"Constant person number\"\n\nattributes(pass_df$welle)$label\n\n[1] \"Survey wave indicator\"\nGet all variable label, we loop over all variables using map() and store the result in var_lab:\nvar_lab &lt;- \n  pass_df %&gt;% # call data.frame\n    map(~attributes(.x)$label) %&gt;%  # apply attributes to all variables (take the entire input)\n    unlist() %&gt;% # turn list into vector\n    enframe() # turn the vector into a data.frame\nhead(var_lab)\n\n# A tibble: 6 × 2\n  name     value                                    \n  &lt;chr&gt;    &lt;chr&gt;                                    \n1 pnr      Constant person number                   \n2 hnr      Household number (current)               \n3 welle    Survey wave indicator                    \n4 pintjahr Date of person interview: Year, gen.     \n5 pintmon  Date of person interview: Month, gen.    \n6 pintmod  System variable: Mode of person interview\nWe’re looking for variables for income, education, age, gender, and hours worked. Do find the corresponding variables, we can filter through the var_lab data.frame using grepl(\"pattern\", variable):\nvar_lab %&gt;% filter(grepl(\"income\",value))\n\n# A tibble: 3 × 2\n  name     value                                                                \n  &lt;chr&gt;    &lt;chr&gt;                                                                \n1 PAS1400b Acceptable disadvantage: Low income                                  \n2 netges   Current net total income, without mini-job, incl. categorized data, …\n3 brges    Current gross total income, without mini-job, incl. categorized data…\n\nvar_lab %&gt;% filter(grepl(\"time\",value))\n\n# A tibble: 5 × 2\n  name     value                                                                \n  &lt;chr&gt;    &lt;chr&gt;                                                                \n1 PEO0900a Attitude towards fulltime childcare outside house: From what age onw…\n2 PEO0900b Attitude towards fulltime childcare outside house: From what age onw…\n3 PQB0600a Opportunities/pressures at work: Often great time pressure           \n4 PAS1400a Acceptable disadvantage: Long commuting time                         \n5 azges1   Current contract working time,total, without mini-job, gen.\nTo search for multiple variables, we can use grepl(\"pattern\", variable) in combiation with the | (or) operator:\n# var_lab %&gt;% filter(grepl(\"income|school| Age | age |gender|working time\",value)) # basic syntax\nvar_lab %&gt;% filter(grepl(\"income|school|[A,a]ge |gender|working time\",value)) # using regex \n\n# A tibble: 18 × 2\n   name     value                                                               \n   &lt;chr&gt;    &lt;chr&gt;                                                               \n 1 palter   Age (W1: gen. from P1; W2 ff.: best info.), gen.                    \n 2 PSM0100  Usage of social networks                                            \n 3 PEO0800a Attitude towards childcare outside house: From what age onwards (mo…\n 4 PEO0800b Attitude towards childcare outside house: From what age onwards (ye…\n 5 PEO0900a Attitude towards fulltime childcare outside house: From what age on…\n 6 PEO0900b Attitude towards fulltime childcare outside house: From what age on…\n 7 PEO1000a Attitude: Mother take up employment(&gt;15h): From what age onwards (m…\n 8 PEO1000b Attitude: Mother take up employment(&gt;15h): From what age onwards (y…\n 9 PEO1100a Attitude: Mother take up employment(&gt;30h): From what age onwards (m…\n10 PEO1100b Attitude: Mother take up employment(&gt;30h): From what age onwards (y…\n11 PQB0600j Opportunities/pressures at work: Salary or wage is appropriate      \n12 PAS1400b Acceptable disadvantage: Low income                                 \n13 PG1270   Average number of cigarettes smoked per day (last week)             \n14 epartner Control variable: Marriage partner or registered partner in HH      \n15 schul2   Highest school qualification, incl. foreign, +open                  \n16 netges   Current net total income, without mini-job, incl. categorized data,…\n17 brges    Current gross total income, without mini-job, incl. categorized dat…\n18 azges1   Current contract working time,total, without mini-job, gen.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>From data to table & graph</span>"
    ]
  },
  {
    "objectID": "10_raw_to_table.html#loading-data",
    "href": "10_raw_to_table.html#loading-data",
    "title": "8  From data to table & graph",
    "section": "8.2 Loading data",
    "text": "8.2 Loading data\nThe we load the PASS data, apply a filter right away to drop missing values and keep wave 13 only. In second step, we keep only necessary variables:\n\npass_df &lt;- read_dta(\"./orig/PENDDAT_cf_W13.dta\") %&gt;% \n  filter(netges &gt; 0,palter &gt; 0, schul2 &gt; 0,azges1&gt;0, welle == 12) %&gt;% \n  select(netges, palter, schul2, azges1, welle, zpsex)\n\nNext, we explore the categorial schul2 variable:\n\npass_df %&gt;% count(schul2)\n\n# A tibble: 6 × 2\n  schul2                                                                       n\n  &lt;dbl+lbl&gt;                                                                &lt;int&gt;\n1 2 [Finished school without degree]                                          18\n2 3 [School incorporating physically or mentally disabled children (Sonde…     4\n3 4 [Lower secondary school (Hauptschulabschluss)]                           117\n4 5 [Intermediate secondary school (Realschulabschluss, Mittlere Reife)]     259\n5 6 [Upper secondary Fachoberschule, Fachhochschulreife)]                     56\n6 7 [General/subject-specific upper secondary school (Hochschulreife)]       226\n\npass_df %&gt;% count(zpsex)\n\n# A tibble: 2 × 2\n  zpsex          n\n  &lt;dbl+lbl&gt;  &lt;int&gt;\n1 1 [Male]     348\n2 2 [Female]   332",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>From data to table & graph</span>"
    ]
  },
  {
    "objectID": "10_raw_to_table.html#preparing-variables",
    "href": "10_raw_to_table.html#preparing-variables",
    "title": "8  From data to table & graph",
    "section": "8.3 Preparing variables",
    "text": "8.3 Preparing variables\nTo have nice short and informative labels, we define both variables as factors. We combine 6 [Upper secondary Fachoberschule, Fachhochschulreife)] and 7 [General/subject-specific upper secondary school (Hochschulreife)] into “Upper Secondary”:\n\npass_df &lt;- \n  pass_df %&gt;% \n    mutate( \n      gender = factor(zpsex,  levels = 1:2, labels = c(\"Male\",\"Female\")) ,\n      educ   = factor(schul2, levels = 2:7, \n                      labels = c(\"No degree\",\"Special education\",\"Lower secondary\",\n                                 \"Intermediate secondary\", \"Upper secondary\",\n                                 \"Upper secondary\") )\n      )\n\nChecking the recodes relies using count():\n\npass_df %&gt;% count(gender,zpsex)\n\n# A tibble: 2 × 3\n  gender zpsex          n\n  &lt;fct&gt;  &lt;dbl+lbl&gt;  &lt;int&gt;\n1 Male   1 [Male]     348\n2 Female 2 [Female]   332\n\npass_df %&gt;% count(educ,schul2)\n\n# A tibble: 6 × 3\n  educ                   schul2                                                n\n  &lt;fct&gt;                  &lt;dbl+lbl&gt;                                         &lt;int&gt;\n1 No degree              2 [Finished school without degree]                   18\n2 Special education      3 [School incorporating physically or mentally d…     4\n3 Lower secondary        4 [Lower secondary school (Hauptschulabschluss)]    117\n4 Intermediate secondary 5 [Intermediate secondary school (Realschulabsch…   259\n5 Upper secondary        6 [Upper secondary Fachoberschule, Fachhochschul…    56\n6 Upper secondary        7 [General/subject-specific upper secondary scho…   226",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>From data to table & graph</span>"
    ]
  },
  {
    "objectID": "10_raw_to_table.html#create-descriptions",
    "href": "10_raw_to_table.html#create-descriptions",
    "title": "8  From data to table & graph",
    "section": "8.4 Create descriptions",
    "text": "8.4 Create descriptions\nTo create descriptions for our variables.\n\n8.4.1 Description of income variable\nA histogram for\n\nlibrary(wesanderson) # for colors from Wes Anderson movies\n\nError in library(wesanderson): es gibt kein Paket namens 'wesanderson'\n\nwesanderson::wes_palettes$Darjeeling2[1:2] # the package contains hex-codes lists - we'll go for Darjeeling2\n\nError in loadNamespace(x): es gibt kein Paket namens 'wesanderson'\n\n# save it as an object\ninc_hist &lt;- \n  pass_df %&gt;% \n  ggplot(aes(netges, fill = gender)) +\n  geom_histogram(position = position_dodge(),bins = 50, color = \"grey30\", size = .1) +\n  scale_fill_manual(values = wesanderson::wes_palettes$Darjeeling2[1:2])  +\n  facet_grid(gender~.) + # split panel by gender\n  labs(x = \"Current net total income\", y = \"Count\",\n       fill = \"\", color = \"\",\n       title = \"Distribution of earnings by gender\") +\n  theme_minimal()+\n  guides(fill = \"none\", color = \"none\") +\n  theme(strip.text.y = element_text(angle = 0,size = rel(1.5)))\n\nError in loadNamespace(x): es gibt kein Paket namens 'wesanderson'\n\ninc_hist\n\nError: Objekt 'inc_hist' nicht gefunden\n\n# export plot\nggsave(plot = inc_hist,filename = \"./results/Fig01_Histogramm.png\")\n\nError: Objekt 'inc_hist' nicht gefunden\n\n\n\n\n8.4.2 Continuous independent variables\nFor the continuous independent variables, we create a summary table.\nTo have it all in one table, pivot_longer() is helpful:\n\n## just to illustrate what pivot_longer does here:\npass_df %&gt;% \n  select(palter, azges1,gender) %&gt;% # retain only variables palter, azges1, gender\n  pivot_longer(cols = -gender) %&gt;%  # reshape variables except gender to long shape\n  head(n=2) # only show lines 1-2\n\n# A tibble: 2 × 3\n  gender name   value    \n  &lt;fct&gt;  &lt;chr&gt;  &lt;dbl+lbl&gt;\n1 Female palter 34       \n2 Female azges1 24       \n\n# store for later:\ncont_desctab &lt;- \npass_df %&gt;% \n  select(palter, azges1,gender) %&gt;% \n  pivot_longer(cols = -gender) %&gt;% \n  summarise(MEAN = mean(value), \n            SD =   sd(value),\n            MIN =  min(value),\n            MAX =  max(value),\n            .by = c(\"gender\",\"name\"))\n\ncont_desctab # quick look\n\n# A tibble: 4 × 6\n  gender name    MEAN    SD MIN       MAX      \n  &lt;fct&gt;  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt;\n1 Female palter  44.9 11.2  20        65       \n2 Female azges1  30.3 10.3   3        74       \n3 Male   palter  42.6 11.1  19        65       \n4 Male   azges1  37.5  7.98  2        64       \n\n\nAnd then we create a frequency table for educ. We store it for later formatting:\n\ndesc_tab &lt;- \n  pass_df %&gt;% \n    select(educ,gender) %&gt;% \n    count(educ,gender) %&gt;% \n    mutate(pct = prop.table(n)*100, # to have it as percent\n           pct = sprintf(\"%.2f\",pct), # format number -&gt; 2 digits\n           pct = paste0(pct,\"%\"),\n           .by = gender)\n\ndesc_tab # check\n\n# A tibble: 9 × 4\n  educ                   gender     n pct   \n  &lt;fct&gt;                  &lt;fct&gt;  &lt;int&gt; &lt;chr&gt; \n1 No degree              Male      14 4.02% \n2 No degree              Female     4 1.20% \n3 Special education      Male       4 1.15% \n4 Lower secondary        Male      64 18.39%\n5 Lower secondary        Female    53 15.96%\n6 Intermediate secondary Male     113 32.47%\n7 Intermediate secondary Female   146 43.98%\n8 Upper secondary        Male     153 43.97%\n9 Upper secondary        Female   129 38.86%",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>From data to table & graph</span>"
    ]
  },
  {
    "objectID": "10_raw_to_table.html#fit-regression-models",
    "href": "10_raw_to_table.html#fit-regression-models",
    "title": "8  From data to table & graph",
    "section": "8.5 Fit regression models",
    "text": "8.5 Fit regression models\nWe fit two regression models:\n\nmod1 &lt;- lm(netges~ gender*azges1+ I(azges1^2), data = pass_df) \nsummary(mod1)\n\n\nCall:\nlm(formula = netges ~ gender * azges1 + I(azges1^2), data = pass_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1820.0  -519.7  -120.2   293.1  5139.3 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          517.3962   303.3108   1.706  0.08850 .  \ngenderFemale        -835.1715   255.2593  -3.272  0.00112 ** \nazges1                59.8497    14.9688   3.998 7.08e-05 ***\nI(azges1^2)           -0.5025     0.2070  -2.427  0.01547 *  \ngenderFemale:azges1   14.0308     7.0818   1.981  0.04797 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 819.7 on 675 degrees of freedom\nMultiple R-squared:  0.2422,    Adjusted R-squared:  0.2377 \nF-statistic: 53.94 on 4 and 675 DF,  p-value: &lt; 2.2e-16\n\nmod2 &lt;- lm(netges~ palter + I(palter^2) + educ + gender*azges1 + I(azges1^2), data = pass_df) \nsummary(mod2)\n\n\nCall:\nlm(formula = netges ~ palter + I(palter^2) + educ + gender * \n    azges1 + I(azges1^2), data = pass_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1930.1  -470.7   -87.7   344.2  4433.9 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                -877.63869  533.77509  -1.644  0.10060    \npalter                       15.16374   20.71663   0.732  0.46445    \nI(palter^2)                   0.01347    0.23751   0.057  0.95478    \neducSpecial education       245.59507  437.68450   0.561  0.57490    \neducLower secondary         403.80108  193.80535   2.084  0.03758 *  \neducIntermediate secondary  580.82538  187.81755   3.092  0.00207 ** \neducUpper secondary        1032.23670  187.05171   5.518 4.89e-08 ***\ngenderFemale               -972.95869  247.57879  -3.930 9.38e-05 ***\nazges1                       63.21451   14.50979   4.357 1.53e-05 ***\nI(azges1^2)                  -0.58616    0.19693  -2.976  0.00302 ** \ngenderFemale:azges1          16.84689    6.79861   2.478  0.01346 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 762.3 on 669 degrees of freedom\nMultiple R-squared:  0.3505,    Adjusted R-squared:  0.3408 \nF-statistic:  36.1 on 10 and 669 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>From data to table & graph</span>"
    ]
  },
  {
    "objectID": "10_raw_to_table.html#regression-summaries",
    "href": "10_raw_to_table.html#regression-summaries",
    "title": "8  From data to table & graph",
    "section": "8.6 Regression summaries",
    "text": "8.6 Regression summaries\n\n8.6.1 Regression table\nWe use the {modelsummary} package to create a regression table. We save the regression table as flextable object using output = \"flextable\" for additional formatting using the {flextable} package later.\n\nlibrary(flextable)\nlibrary(modelsummary)\n# set flextable defaults\nset_flextable_defaults(font.family = \"Times New Roman\",font.color = \"grey25\",border.color = \"grey25\",\n                       font.size = 8,padding = .5)\n\n# create a data.frame with reference categories\nref_rows &lt;- tribble( ~ term, ~ \"Simple Model\",  ~ \"Full Model\",\n                      \"Men\",           'ref.',   'ref.',\n                      \"No degree\",         '',   'ref.'\n                     )\nattr(ref_rows, 'position') &lt;- c(3,16) # attach rows for ref cats\n\nreg_flextab &lt;- \nmodelsummary(list(\"Simple Model\" = mod1,\n                  \"Full Model\" = mod2), \n             coef_rename = c(\"(Intercept)\"=\"Intercept\",\n                                           \"azges1\" = \"Working hours (h)\",\n                                           \"I(azges1^2)\" = \"Working hours² (h)\",\n                                           \"genderFemale\" = \"Female\", # \"×\"\n                                           \"palter\" = \"Age\",\n                                           \"I(palter^2)\" = \"Age²\",\n                                           \"educSpecial education\"      = \"Special education\",\n                                           \"educLower secondary\"        = \"Lower secondary\",\n                                           \"educIntermediate secondary\" = \"Intermediate secondary\",\n                                           \"educUpper secondary\"        =  \"Upper secondary\"\n                             ),\n            add_rows = ref_rows,\n            stars = T, gof_omit = \"IC|Log|RMSE\",\n            output = \"flextable\") %&gt;% autofit()\n\nreg_flextab # check\n\n Simple ModelFull ModelIntercept517.396+-877.639(303.311)(533.775)Menref.ref.Female-835.172**-972.959***(255.259)(247.579)Working hours (h)59.850***63.215***(14.969)(14.510)Working hours² (h)-0.502*-0.586**(0.207)(0.197)Female:Working hours (h)14.031*16.847*(7.082)(6.799)Age15.164(20.717)Age²0.013(0.238)No degreeref.Special education245.595(437.684)Lower secondary403.801*(193.805)Intermediate secondary580.825**(187.818)Upper secondary1032.237***(187.052)Num.Obs.680680R20.2420.350R2 Adj.0.2380.341F53.94536.096+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n8.6.2 Visualize the interaction term\nNext, we use the {marginaleffects} package to calculate adjusted predictions and then visualize them using {ggplot2}:\n\nlibrary(marginaleffects)\npred_df &lt;- \n      predictions(mod2,\n                  newdata = datagrid(azges1 = 1:40, grid_type = \"counterfactual\"),\n                  by = c(\"azges1\",\"gender\"))\n\n\nfig02_pred &lt;- \n  pred_df %&gt;% \n  data.frame() %&gt;% \n  ggplot(aes(x=azges1, y = estimate, fill = gender, color = gender,\n             ymin = conf.low,\n             ymax = conf.high)) + \n    geom_point() + # point estimates\n    geom_line(aes(group = gender)) +\n    geom_ribbon(alpha= .2, color = NA) +\n  scale_fill_manual(values = wesanderson::wes_palettes$Darjeeling2[1:2] ) +\n  scale_color_manual(values = wesanderson::wes_palettes$Darjeeling2[1:2] ) +\n  theme_minimal()+ \n  labs(y = \"Adjusted prediction of net income\", x = \"Working hours\",\n       fill = \"\", color = \"\")\n\nError in loadNamespace(x): es gibt kein Paket namens 'wesanderson'\n\nfig02_pred \n\nError: Objekt 'fig02_pred' nicht gefunden\n\n\nExport it as a png file:\n\nggsave(plot = fig02_pred,filename = \"./results/Fig02_Adjusted_Predictions.png\")\n\nSaving 7 x 5 in image\n\n\nError: Objekt 'fig02_pred' nicht gefunden",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>From data to table & graph</span>"
    ]
  },
  {
    "objectID": "10_raw_to_table.html#exporting-everything-into-a-word-file",
    "href": "10_raw_to_table.html#exporting-everything-into-a-word-file",
    "title": "8  From data to table & graph",
    "section": "8.7 Exporting everything into a Word file",
    "text": "8.7 Exporting everything into a Word file\nFinally, we can use the flextable package to do some formatting of the modelsummary and descriptive tables we’ created earlier.\n\n8.7.1 Formating using flextable\n\nlibrary(flextable) # install it if necessary\nlibrary(officer)   # install it if necessary\n\n# set flextable defaults\nset_flextable_defaults(font.family = \"Times New Roman\",font.color = \"grey25\",border.color = \"grey25\",\n                       font.size = 8,padding = .5)\n\n\n8.7.1.1 Descriptive tables\n\ncont_descflextab &lt;- \n  cont_desctab %&gt;% \n    mutate(name = \n             case_when(name == \"palter\" ~ \"Age\",\n                       name == \"azges1\" ~ \"Working hours\"\n                            )) %&gt;% \n    relocate(name) %&gt;%         # put name in first column\n    arrange(name, gender) %&gt;%  # sort by variable, then gender\n        flextable() %&gt;%        # turn data.frame into flextable\n        border_remove() %&gt;%    # remove everything to start from scratch\n        hline_bottom() %&gt;%     # bottom line\n        hline_top() %&gt;%        # top  line\n        border( i = ~name != lead(name),\n                border.bottom = fp_border(color = \"grey25\", width = .1 )) %&gt;%  # put a border whenever name is different from following line\n        set_header_labels(      # label header relabel\n        gender = \"Gender\",\n        name = \"Variable\") %&gt;%  \n        merge_v(j = 1) %&gt;%      # put variable levels in column 1 into a joint cell\n        fix_border_issues() %&gt;% \n        autofit() \n\ncont_descflextab\n\nVariableGenderMEANSDAge (W1: gen. from P1; W2 ff.: best info.), gen.Age (W1: gen. from P1; W2 ff.: best info.), gen.AgeMale42.6120711.0923071965Female44.9337311.2045722065Working hoursMale37.474147.981385 264Female30.2741010.275959 374\n\n\n\ndes_flextab &lt;- \n    desc_tab %&gt;% \n      flextable() %&gt;%      # turn data.frame into flextable\n      border_remove() %&gt;%  # remove everything to start from scratch\n      hline_bottom() %&gt;%   # top line\n      hline_top() %&gt;%      # bottom line\n      border( i = ~educ != lead(educ),\n              border.bottom = fp_border(color = \"grey25\", width = .1 )) %&gt;%  # put a border whenever education is different from following line\n      set_header_labels(   # label header\n      educ = \"Education\",\n      gender = \"Gender\", \n      n = \"Frequency\",\n      pct = \"Percent\") %&gt;%  \n      merge_v(j = 1) %&gt;%   # put education levels in column 1 into a joint cell\n      fix_border_issues() %&gt;% \n      autofit() %&gt;% \n      padding(j = 3,padding.right = 6,part = \"all\")  # adjust width of column 3\ndes_flextab\n\nEducationGenderFrequencyPercentNo degreeMale144.02%Female41.20%Special educationMale41.15%Lower secondaryMale6418.39%Female5315.96%Intermediate secondaryMale11332.47%Female14643.98%Upper secondaryMale15343.97%Female12938.86%\n\n\n\n\n8.7.1.2 Regression (flex)table from modelsummary\n\nreg_flextab_final &lt;- \n  reg_flextab %&gt;% \n    border_remove() %&gt;%  # drop all borders\n    hline_bottom() %&gt;%   # bottom line\n    hline_top() %&gt;%      # top line\n    border( i = ~ ` `== \"Num.Obs.\",\n              border.top = fp_border(color = \"grey25\", width = .1 )) %&gt;%  # line above Num.Obs.\n    italic(.,j=-1,i =  ~`Full Model` == \"ref.\") %&gt;%  # set ref. to italic\n    autofit()\n\nreg_flextab_final\n\n Simple ModelFull ModelIntercept517.396+-877.639(303.311)(533.775)Menref.ref.Female-835.172**-972.959***(255.259)(247.579)Working hours (h)59.850***63.215***(14.969)(14.510)Working hours² (h)-0.502*-0.586**(0.207)(0.197)Female:Working hours (h)14.031*16.847*(7.082)(6.799)Age15.164(20.717)Age²0.013(0.238)No degreeref.Special education245.595(437.684)Lower secondary403.801*(193.805)Intermediate secondary580.825**(187.818)Upper secondary1032.237***(187.052)Num.Obs.680680R20.2420.350R2 Adj.0.2380.341F53.94536.096+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n8.7.2 Put it in one word file\nThe officer package allows to create a Word file from a template file. More here\n\nread_docx(\"Vorlage_times_hochformat.docx\") %&gt;% # load template\n  body_add_par(value = \"Descriptives\",style = \"heading 1\") %&gt;% # create heading\n  body_add_par(value = \" \") %&gt;%  # add empty row\n  body_add_flextable(., value = des_flextab) %&gt;%\n  body_add_par(value = \" \") %&gt;% # add empty row\n  body_add_flextable(., value = cont_descflextab) %&gt;%\n  body_add_par(value = \"Regression results\",style = \"heading 1\") %&gt;% # create heading\n  body_add_par(value = \" \") %&gt;% \n  body_add_flextable(., value = reg_flextab_final) %&gt;%\n  print(target = \"./results/My_Tables.docx\") # export using print with file name as target\n#",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>From data to table & graph</span>"
    ]
  },
  {
    "objectID": "05_merge_pivot.html",
    "href": "05_merge_pivot.html",
    "title": "9  Data Wrangling II: Merging & reshaping",
    "section": "",
    "text": "9.1 Joining/merging data sets\nA mutating join allows you to combine variables from two data.frames. It first matches observations by their keys, then copies across variables from one table to the other.\nR for Data Science: Mutating joins\nA quick illustration:1\nThere are also right_join() and anti_join(). For a more in-depth introduction, the chapter on Relational Data in R for Data Science is highly recommended.\nA very helpful option in the ..._join() functions is the ability to join different variables. For example, here we have some cases from ids_df, for which the (fictional) unemployment figures from alo_bula should be used. However, in ids_df, the variable Bula contains the state information, while in alo_bula, it is the variable bundesland:\nCode\nids_df &lt;-  data.frame(pnr = sample(1:9,4),\n                       Bula = c(2,1,14,15))\n\nset.seed(90459)\nalo_bula &lt;- data.frame(bundesland = seq(1:8),\n                       Werte = sample(letters,size = 8) # mit sample() kann eine zufällige Auswahl getroffen werden \n                       )\nids_df\n\n#&gt;   pnr Bula\n#&gt; 1   8    2\n#&gt; 2   3    1\n#&gt; 3   2   14\n#&gt; 4   6   15\n\nalo_bula\n\n#&gt;   bundesland Werte\n#&gt; 1          1     g\n#&gt; 2          2     m\n#&gt; 3          3     n\n#&gt; 4          4     z\n#&gt; 5          5     w\n#&gt; 6          6     r\n#&gt; 7          7     t\n#&gt; 8          8     h\n\nids_df %&gt;% left_join(alo_bula,by = c(\"Bula\"=\"bundesland\"))\n\n#&gt;   pnr Bula Werte\n#&gt; 1   8    2     m\n#&gt; 2   3    1     g\n#&gt; 3   2   14  &lt;NA&gt;\n#&gt; 4   6   15  &lt;NA&gt;\nA quick check for the matching cases can be done using:\ntable(ids_df$Bula %in% alo_bula$bundesland)\n\n#&gt; \n#&gt; FALSE  TRUE \n#&gt;     2     2\nanti_join() allows for checking which key variables are not present in the other data.frame:\nids_df %&gt;% anti_join(alo_bula,by = c(\"Bula\"=\"bundesland\"))\n\n#&gt;   pnr Bula\n#&gt; 1   2   14\n#&gt; 2   6   15\n\nalo_bula %&gt;% anti_join(ids_df,by = c(\"bundesland\"=\"Bula\"))\n\n#&gt;   bundesland Werte\n#&gt; 1          3     n\n#&gt; 2          4     z\n#&gt; 3          5     w\n#&gt; 4          6     r\n#&gt; 5          7     t\n#&gt; 6          8     h",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Data Wrangling II: Merging & reshaping</span>"
    ]
  },
  {
    "objectID": "05_merge_pivot.html#join",
    "href": "05_merge_pivot.html#join",
    "title": "9  Data Wrangling II: Merging & reshaping",
    "section": "",
    "text": "inner_join\n\n\n\n\n\n\n\nleft_join\n\n\n\n\n\n\n\nfull_join\n\n\n\n\n\n\n\n\n\n\n\nFigure 9.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.1.1 Exercise",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Data Wrangling II: Merging & reshaping</span>"
    ]
  },
  {
    "objectID": "05_merge_pivot.html#reshaping-data-pivot_longer-pivot_wider",
    "href": "05_merge_pivot.html#reshaping-data-pivot_longer-pivot_wider",
    "title": "9  Data Wrangling II: Merging & reshaping",
    "section": "9.2 Reshaping Data: pivot_longer() & pivot_wider()",
    "text": "9.2 Reshaping Data: pivot_longer() & pivot_wider()\n\n9.2.1 Wide to Long\nReshaping data from wide to long format is useful when you want to store multiple observations per row. For example:\n\nbsp_df &lt;- data.frame(bula = c(\"NRW\", \"NDS\"), alo2018 = c(2, 2), alo2017 = c(1, 1))\nbsp_df\n\n#&gt;   bula alo2018 alo2017\n#&gt; 1  NRW       2       1\n#&gt; 2  NDS       2       1\n\n\nWe can use pivot_longer() to convert this wide format to long:\n\nbsp_df %&gt;% pivot_longer(cols = c(alo2018, alo2017), names_to = \"year\", values_to = \"alo\")\n\n#&gt; # A tibble: 4 × 3\n#&gt;   bula  year      alo\n#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 NRW   alo2018     2\n#&gt; 2 NRW   alo2017     1\n#&gt; 3 NDS   alo2018     2\n#&gt; 4 NDS   alo2017     1\n\n\nTo remove a prefix from the column names:\n\nbsp_df %&gt;% pivot_longer(cols = c(alo2018, alo2017), names_to = \"year\", values_to = \"alo\", names_prefix = \"alo\")\n\n#&gt; # A tibble: 4 × 3\n#&gt;   bula  year    alo\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 NRW   2018      2\n#&gt; 2 NRW   2017      1\n#&gt; 3 NDS   2018      2\n#&gt; 4 NDS   2017      1\n\n\n\n\n9.2.2 Long to Wide\nTo convert from long format back to wide:\n\nbsp_df2 &lt;- data.frame(land = c(\"NRW\", \"NDS\", \"NRW\", \"NDS\"), alo = c(2.1, 1.8, 2.4, 2.2), alter = c(\"age_1825\", \"age_1825\", \"age_2630\", \"age_2630\"))\nbsp_df2\n\n#&gt;   land alo    alter\n#&gt; 1  NRW 2.1 age_1825\n#&gt; 2  NDS 1.8 age_1825\n#&gt; 3  NRW 2.4 age_2630\n#&gt; 4  NDS 2.2 age_2630\n\n\n\nbsp_df2 %&gt;% pivot_wider(names_from = alter, values_from = alo)\n\n#&gt; # A tibble: 2 × 3\n#&gt;   land  age_1825 age_2630\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 NRW        2.1      2.4\n#&gt; 2 NDS        1.8      2.2\n\n\n\n\n9.2.3 Exercise",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Data Wrangling II: Merging & reshaping</span>"
    ]
  },
  {
    "objectID": "05_merge_pivot.html#exercises",
    "href": "05_merge_pivot.html#exercises",
    "title": "9  Data Wrangling II: Merging & reshaping",
    "section": "9.3 Exercises",
    "text": "9.3 Exercises\n\n9.3.1 Exercise 1: Joining\nJoin the selected observations from PENDDAT_cf_W13.dta with the household data to include the region where the respondents live, using hnr and welle as keys.\n\npend_ue11 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\", col_select = c(\"pnr\", \"welle\")) %&gt;% slice(1:10)\n\nhh_dat &lt;- haven::read_dta(\"./orig/HHENDDAT_cf_W13.dta\", col_select = c(\"hnr\", \"welle\", \"region\"))\n\npend_ue11 %&gt;% left_join(hh_dat, by = c(\"welle\"))\n\n#&gt; # A tibble: 18,466 × 4\n#&gt;           pnr welle                       hnr region   \n#&gt;         &lt;dbl&gt; &lt;dbl+lbl&gt;                 &lt;dbl&gt; &lt;dbl+lbl&gt;\n#&gt;  1 1000001901 1 [Wave 1 (2006/2007)] 10000019 4 [West] \n#&gt;  2 1000001901 1 [Wave 1 (2006/2007)] 10000020 4 [West] \n#&gt;  3 1000001901 1 [Wave 1 (2006/2007)] 10000023 4 [West] \n#&gt;  4 1000001901 1 [Wave 1 (2006/2007)] 10000026 4 [West] \n#&gt;  5 1000001901 1 [Wave 1 (2006/2007)] 10000031 4 [West] \n#&gt;  6 1000001901 1 [Wave 1 (2006/2007)] 10000032 4 [West] \n#&gt;  7 1000001901 1 [Wave 1 (2006/2007)] 10000035 4 [West] \n#&gt;  8 1000001901 1 [Wave 1 (2006/2007)] 10000040 4 [West] \n#&gt;  9 1000001901 1 [Wave 1 (2006/2007)] 10000043 4 [West] \n#&gt; 10 1000001901 1 [Wave 1 (2006/2007)] 10000055 3 [Süd]  \n#&gt; # ℹ 18,456 more rows\n\n\nBack to top\n\n\n9.3.2 Exercise 2: Reshaping\nBring the following data into long format:\n\npend_ue11b &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\", col_select = c(\"pnr\", \"welle\", \"famstand\")) %&gt;%\n  slice(200:210) %&gt;%\n  filter(welle %in% 2:3)\n\npend_ue11b %&gt;% pivot_wider(names_from = welle, values_from = famstand)\n\n#&gt; # A tibble: 3 × 3\n#&gt;          pnr `2`                                             `3`                \n#&gt;        &lt;dbl&gt; &lt;dbl+lbl&gt;                                       &lt;dbl+lbl&gt;          \n#&gt; 1 1000014501 -4 [Question mistakenly not asked]              3 [Married/civil p…\n#&gt; 2 1000014701  2 [Married/civil partnership, living together] 2 [Married/civil p…\n#&gt; 3 1000014702  2 [Married/civil partnership, living together] 2 [Married/civil p…\n\n\nUsing names_prefix = \"wave\":\n\npend_ue11b %&gt;% pivot_wider(names_from = welle, values_from = famstand, names_prefix = \"wave\")\n\n#&gt; # A tibble: 3 × 3\n#&gt;          pnr wave2                                           wave3              \n#&gt;        &lt;dbl&gt; &lt;dbl+lbl&gt;                                       &lt;dbl+lbl&gt;          \n#&gt; 1 1000014501 -4 [Question mistakenly not asked]              3 [Married/civil p…\n#&gt; 2 1000014701  2 [Married/civil partnership, living together] 2 [Married/civil p…\n#&gt; 3 1000014702  2 [Married/civil partnership, living together] 2 [Married/civil p…\n\n\nBack to top",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Data Wrangling II: Merging & reshaping</span>"
    ]
  },
  {
    "objectID": "05_merge_pivot.html#footnotes",
    "href": "05_merge_pivot.html#footnotes",
    "title": "9  Data Wrangling II: Merging & reshaping",
    "section": "",
    "text": "Using tidyexplain↩︎",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Data Wrangling II: Merging & reshaping</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html",
    "href": "06_labels_factor.html",
    "title": "10  Labels & factors",
    "section": "",
    "text": "10.1 Labels from Other Programs in R\nIn many software packages like Stata or SPSS, labels are often retained through various operations and then displayed automatically. This is not the case in R. Instead, in R, we can assign labels using the factor variable type. This approach might seem unusual for those who have worked extensively with Stata or SPSS, but it is quite useful in practice if you get accustomed to the workflow.\nGenerally, you can use value labels from other software packages in are. For example, when we create a count summary with count(), the labels from the .dta-file are displayed:\n# Counting occurrences and showing labels\npend_kap5 %&gt;% \n  count(PSM0100)\n\n# A tibble: 3 × 2\n  PSM0100                            n\n  &lt;dbl+lbl&gt;                      &lt;int&gt;\n1 -5 [Does not use the internet]    28\n2  1 [Yes]                         318\n3  2 [No]                          337\nThese are assigned as attributes() variables:\nattributes(pend_kap5$PSM0100)\n\n$label\n[1] \"Usage of social networks\"\n\n$format.stata\n[1] \"%39.0f\"\n\n$labels\nItem not surveyed in wave Does not use the internet           Details refused \n                       -9                        -5                        -2 \n               Don't know                       Yes                        No \n                       -1                         1                         2 \n\n$class\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"\nenframe() from the {tibble} (part of the {tidyverse}) package helps to get data.frame with an overview of all value labels stored in an attribute:\nattributes(pend_kap5$PSM0100)$labels %&gt;% enframe(value = \"variable_value\",name = \"label\")\n\n# A tibble: 6 × 2\n  label                     variable_value\n  &lt;chr&gt;                              &lt;dbl&gt;\n1 Item not surveyed in wave             -9\n2 Does not use the internet             -5\n3 Details refused                       -2\n4 Don't know                            -1\n5 Yes                                    1\n6 No                                     2\nHowever, managing attributes() is tedious and sometimes causes problems when working with the labelled variables.\nR’s native way to work with labels are factor variables. As mentioned in chapter 2, factor variables are strings with a predefined universe and ordering.\nHow can we use the attributes()-labels as factor to save typing?\n{haven} includes the function as_factor1, which allows us to directly create a factor variable from labels:\npend_kap5$PSM0100_fct &lt;- as_factor(pend_kap5$PSM0100) # create factor variable from attributes and values\n\n# view:\npend_kap5 %&gt;% select(contains(\"PSM0100\")) %&gt;% head()\n\n# A tibble: 6 × 2\n  PSM0100                        PSM0100_fct              \n  &lt;dbl+lbl&gt;                      &lt;fct&gt;                    \n1  2 [No]                        No                       \n2  1 [Yes]                       Yes                      \n3  2 [No]                        No                       \n4 -5 [Does not use the internet] Does not use the internet\n5 -5 [Does not use the internet] Does not use the internet\n6 -5 [Does not use the internet] Does not use the internet",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html#creating-or-editing-factor-manually",
    "href": "06_labels_factor.html#creating-or-editing-factor-manually",
    "title": "10  Labels & factors",
    "section": "10.2 Creating or editing factor manually",
    "text": "10.2 Creating or editing factor manually\nAlternatively, we can also label with factor() using the levels and labels options ourselves. The labels are assigned in order to the numbers from levels. Additionally, all unspecified levels automatically become NA:\n\npend_kap5$PSM0100_fct2 &lt;- factor(pend_kap5$PSM0100,\n                               levels = c(1,2),\n                               labels = c(\"Yes!\",\"No :-(\"))\n\n# view:\npend_kap5 %&gt;% select(contains(\"PSM0100\")) %&gt;% head()\n\n# A tibble: 6 × 3\n  PSM0100                        PSM0100_fct               PSM0100_fct2\n  &lt;dbl+lbl&gt;                      &lt;fct&gt;                     &lt;fct&gt;       \n1  2 [No]                        No                        No :-(      \n2  1 [Yes]                       Yes                       Yes!        \n3  2 [No]                        No                        No :-(      \n4 -5 [Does not use the internet] Does not use the internet &lt;NA&gt;        \n5 -5 [Does not use the internet] Does not use the internet &lt;NA&gt;        \n6 -5 [Does not use the internet] Does not use the internet &lt;NA&gt;        \n\n\nOr we can use the functions from {forcats} to recode a factor. {forcats} is part of the {tidyverse}. With fct_recode(), we can change the levels:\n\nlevels(pend_kap5$PSM0100_fct)\n\n[1] \"Item not surveyed in wave\" \"Does not use the internet\"\n[3] \"Details refused\"           \"Don't know\"               \n[5] \"Yes\"                       \"No\"                       \n\npend_kap5$PSM0100_fct3 &lt;- fct_recode(pend_kap5$PSM0100_fct,\n  `Uses social networks` =  \"Yes\", # use `` around words with spaces\n  )\nlevels(pend_kap5$PSM0100_fct3)\n\n[1] \"Item not surveyed in wave\" \"Does not use the internet\"\n[3] \"Details refused\"           \"Don't know\"               \n[5] \"Uses social networks\"      \"No\"                       \n\n\n\npend_kap5 %&gt;% select(contains(\"PSM0100\")) %&gt;% head()\n\n# A tibble: 6 × 4\n  PSM0100                        PSM0100_fct           PSM0100_fct2 PSM0100_fct3\n  &lt;dbl+lbl&gt;                      &lt;fct&gt;                 &lt;fct&gt;        &lt;fct&gt;       \n1  2 [No]                        No                    No :-(       No          \n2  1 [Yes]                       Yes                   Yes!         Uses social…\n3  2 [No]                        No                    No :-(       No          \n4 -5 [Does not use the internet] Does not use the int… &lt;NA&gt;         Does not us…\n5 -5 [Does not use the internet] Does not use the int… &lt;NA&gt;         Does not us…\n6 -5 [Does not use the internet] Does not use the int… &lt;NA&gt;         Does not us…\n\n\nMore fct_....() functions from {forcats} can be found in this Cheatsheet.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html#exercise",
    "href": "06_labels_factor.html#exercise",
    "title": "10  Labels & factors",
    "section": "10.3 Exercise",
    "text": "10.3 Exercise\n\npend_ue5 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                               col_select = c(\"pnr\",\"welle\",\"PD0400\")) %&gt;% \n  filter(PD0400&gt;0)\n\nEdit the value labels of PD0400: Religiousness, self-rating\n\n\nvaluelabel1Not at all religious2Rather not religious3Rather religious4Very religious\n\n\n\nFirst, use head() and a count with count() to get an overview.\nHow can you use the labels from the attributes() with as_factor() to create a variable PD0400_fct?\nCreate a factor() variable F411_01_fct2 with value labels: 1 = Not at all, 2 = Rather not, 3 = Rather yes, 4 = Very much\n\nBonus exercise: Use the labeled variable for a bar chart.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html#appendix",
    "href": "06_labels_factor.html#appendix",
    "title": "10  Labels & factors",
    "section": "10.4 Appendix",
    "text": "10.4 Appendix\n\n10.4.1 Remove labels with zap_... from {haven}\nThe label attributes() often cause problems in further processing. With haven::zap_labels(), we can remove value labels from a dataset, and with haven::zap_label(), we can remove variable labels.\n\npend_kap5\n\n# A tibble: 683 × 6\n          pnr welle             zpsex      PSM0100                 azges1 palter\n        &lt;dbl&gt; &lt;dbl+lbl&gt;         &lt;dbl+lbl&gt;  &lt;dbl+lbl&gt;               &lt;dbl+&gt; &lt;dbl+&gt;\n 1 1000002601 8 [Wave 8 (2014)] 2 [Female]  2 [No]                 22     34    \n 2 1000010402 8 [Wave 8 (2014)] 2 [Female]  1 [Yes]                40     30    \n 3 1000019102 8 [Wave 8 (2014)] 1 [Male]    2 [No]                 40     34    \n 4 1000031403 8 [Wave 8 (2014)] 1 [Male]   -5 [Does not use the i… 44     52    \n 5 1000032801 8 [Wave 8 (2014)] 2 [Female] -5 [Does not use the i… 44     58    \n 6 1000032802 8 [Wave 8 (2014)] 1 [Male]   -5 [Does not use the i… 43     62    \n 7 1000038201 8 [Wave 8 (2014)] 1 [Male]    1 [Yes]                43     61    \n 8 1000040003 8 [Wave 8 (2014)] 1 [Male]    2 [No]                 36     40    \n 9 1000051801 8 [Wave 8 (2014)] 2 [Female]  2 [No]                 31     44    \n10 1000053101 8 [Wave 8 (2014)] 1 [Male]    1 [Yes]                27     47    \n# ℹ 673 more rows\n\npend_kap5 %&gt;% \n  haven::zap_labels() # remove value labels\n\n# A tibble: 683 × 6\n          pnr welle zpsex PSM0100 azges1 palter\n        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 1000002601     8     2       2     22     34\n 2 1000010402     8     2       1     40     30\n 3 1000019102     8     1       2     40     34\n 4 1000031403     8     1      -5     44     52\n 5 1000032801     8     2      -5     44     58\n 6 1000032802     8     1      -5     43     62\n 7 1000038201     8     1       1     43     61\n 8 1000040003     8     1       2     36     40\n 9 1000051801     8     2       2     31     44\n10 1000053101     8     1       1     27     47\n# ℹ 673 more rows\n\n\n\n\n10.4.2 Creating labels in R and exporting to Stata\nIf we want to label a dataset for Stata, for example, {labelled} comes in handy again:\n\nfdz_install(\"labelled\")\n\n\nlibrary(labelled)\n\nError in library(labelled): es gibt kein Paket namens 'labelled'\n\n\n\npend_kap5$zpsex_num2 &lt;- as.numeric(pend_kap5$zpsex)\nattributes(pend_kap5$zpsex_num2)\n\nNULL\n\nval_labels(pend_kap5$zpsex_num2) &lt;- c(\"Männer Testtesttest\"=1,\"Frauen\"=2)\n\nError in val_labels(pend_kap5$zpsex_num2) &lt;- c(`Männer Testtesttest` = 1, : konnte Funktion \"val_labels&lt;-\" nicht finden\n\nattributes(pend_kap5$zpsex_num2)\n\nNULL\n\npend_kap5 %&gt;% count(zpsex_num2)\n\n# A tibble: 2 × 2\n  zpsex_num2     n\n       &lt;dbl&gt; &lt;int&gt;\n1          1   324\n2          2   359\n\n\n\npend_kap5 %&gt;% \n  select(zpsex_num2) %&gt;% \n  haven::write_dta(.,path = \"./data/pend_kap5.dta\")\n\n…in Stata:\n\nuse \"./data/pend_kap5.dta\" \ntab zpsex_num2 \n\n zpsex_num2 |      Freq.     Percent        Cum.\n------------+-----------------------------------\n          1 |        324       47.44       47.44\n          2 |        359       52.56      100.00\n------------+-----------------------------------\n      Total |        683      100.00\n\n\nMore on labels in {labelled}.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "06_labels_factor.html#footnotes",
    "href": "06_labels_factor.html#footnotes",
    "title": "10  Labels & factors",
    "section": "",
    "text": "Not to be confused with as.factor() from base R – the _ makes a difference!↩︎",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Labels & factors</span>"
    ]
  },
  {
    "objectID": "15_map.html",
    "href": "15_map.html",
    "title": "11  Creating map Visualizations with {ggplot2}",
    "section": "",
    "text": "11.1 Modify sf shape data.frames\nWe can use the familiar {dplyr} functions to amend the sf data. Here’s are rather silly example how to combine Saxony, Saxony-Anhalt and Thuringa into one unit:\nlan17_15länder &lt;- \n  lan17 %&gt;% \n  filter(GF==4) %&gt;%\n  mutate(newid = case_when(as.numeric(AGS)&gt;13 ~ \"17\",  TRUE ~ AGS)) %&gt;% # same ID for SN, SA, TH\n  summarise(geometry = st_union(geometry),.by = newid) # summarise -&gt; combine based on newid\n  \nggplot(lan17_15länder) + \n  geom_sf(size = .1, aes(fill = as.numeric(newid)) )  +\n  scale_fill_scico(palette = \"oslo\") + # requires scico package\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Creating map Visualizations with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "15_map.html#exercise",
    "href": "15_map.html#exercise",
    "title": "11  Creating map Visualizations with {ggplot2}",
    "section": "11.2 Exercise",
    "text": "11.2 Exercise\nCreate a map yourself - for the country, district, or municipality level.\n\nYou can find the shapefile for the year 2017 in the course folder under /orig in the Quickablage.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Creating map Visualizations with `{ggplot2}`</span>"
    ]
  },
  {
    "objectID": "references_translated.html",
    "href": "references_translated.html",
    "title": "Links & Further Reading",
    "section": "",
    "text": "%&gt;% vs. |&gt;\nIn this course, we have used the pipe %&gt;% from {tidyverse} (technically from the {magrittr} package). With the update to R 4.1, a pipe |&gt; was also introduced in base R, and help pages and other resources are slowly but surely replacing %&gt;% with |&gt;. For (almost) all applications we’ve learned, both pipes behave identically. Since older R versions are still installed at the IAB, we have stuck to the ‘old version’. However, there’s nothing wrong with switching to |&gt; after an update—or simply sticking with %&gt;%.\nYou can find more about the differences here between the two pipes. Additionally, this blog post offers a good overview of the pitfalls when switching from %&gt;% to |&gt;.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#anonymfun",
    "href": "references_translated.html#anonymfun",
    "title": "Links & Further Reading",
    "section": "Anonymous Functions: .x vs. \\(x)",
    "text": "Anonymous Functions: .x vs. \\(x)\nWith R 4.1.0, a new ‘anonymous function shorthand’ was introduced in base R, replacing the ‘formula syntax’ notation ~mean(.x) that we learned in Chapter 6. In the new base R, it would be written as \\(x) mean(x).\nFrom the {purrr} release notes for version 1.0.0 (December 2022): We believe that it’s better to use these new base tools because they work everywhere: the base pipe doesn’t require that you load magrittr and the new function shorthand works everywhere, not just in purrr functions. Additionally, being able to specify the argument name for the anonymous function can often lead to clearer code.\nAccordingly, the application in across() would look like this:\n\nsat_small &lt;- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",n_max = 16) %&gt;% \n    select(F1450_04,F1450_05,F1450_06) %&gt;% \n    slice(12:16)\n\n# formula syntax\nsat_small %&gt;% \n  mutate(across(matches(\"F1450\"), ~mean(.x)))\n# anonymous function shorthand\nsat_small %&gt;% \n  mutate(across(matches(\"F1450\"), \\(x) mean(x) ))\n\nIn this script, I have relied on the previous ‘formula syntax’ notation, as most help pages currently still use this syntax.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#introductions-to-r",
    "href": "references_translated.html#introductions-to-r",
    "title": "Links & Further Reading",
    "section": "Introductions to R",
    "text": "Introductions to R\nA collection of teaching scripts and materials from various contexts for self-learning:\nR for Data Science the standard work for data analysis with {tidyverse} - very intuitive introduction, focus on Data Science.\nProblem-oriented introductions to specific applications “do more with R”.\nTen simple rules for teaching yourself R.\nModern Data Analysis with R: A German-language introduction to {tidyverse}.\nR for the Rest of Us offers many tutorials and free courses, including many YouTube videos.\nStata 2 R is aimed at Stata users who want to switch to R. However, it shows the {data.table} package for data processing instead of {tidyverse}. {data.table} is very fast but has a somewhat more cumbersome syntax compared to {tidyverse}. For those working with very large datasets, it’s worth trying out {data.table}.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#rmarkdown",
    "href": "references_translated.html#rmarkdown",
    "title": "Links & Further Reading",
    "section": "RMarkdown",
    "text": "RMarkdown\n{rmarkdown} allows you to combine formatted text elements with Markdown and R code or output. Unlike an R script, an RMarkdown document contains not only commands but also text that can be formatted using Markdown commands. This way, graphics, tables, etc., can be created directly alongside the accompanying text. With R Markdown, we can create HTML, PDF, Word documents, PowerPoint and HTML presentations, websites, and books. This entire website was created with {R Markdown} or the related package {Quarto}.\nThe help pages and documentation for R Markdown are extensive, and the tutorials and cheatsheets are excellent. Therefore, here’s just a brief overview.\n\nMarkdown Syntax\nAn RMarkdown document in its basic form looks something like this:\n---\ntitle: \"My First RMarkdown Document\"\nauthor: \"My Name\"\ndate: \"2022-09-11\"\noutput: pdf_document\n---\n  \n# Heading 1\n\n## Subheading 2\n\nThis is an R Markdown document. \nMarkdown is a simple syntax for creating HTML, PDF, and MS Word documents. \nText can be **bold** and *italic*. \n\nWhen we click the **Knit** button, a document is created.\nThat contains both the content and the output of any embedded R code chunks within the document. \nAn R code chunk looks like this:\n\n```{r cars}\n# this is where the R code goes\nsummary(mtcars$qsec)\n```\n\n\n\n\n\n\n\n\n\n\n\nExample\nPaper on a sample dataset, written entirely in R Markdown\nYou can find the source code here.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#cheatsheets",
    "href": "references_translated.html#cheatsheets",
    "title": "Links & Further Reading",
    "section": "Cheatsheets",
    "text": "Cheatsheets\nA collection of cheatsheets for a wide range of applications is available here.\n\nData visualization with {ggplot2}.\nData manipulation with {dplyr}.\nReshaping/creating datasets with {tidyr}.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#ggplot2",
    "href": "references_translated.html#ggplot2",
    "title": "Links & Further Reading",
    "section": "{ggplot2}",
    "text": "{ggplot2}\nA significant strength of ggplot2 is the numerous extensions that allow you to\n\nCombine multiple plots with {patchwork}.\nCreate maps with sf, another link.\nUse advanced text formatting with {ggtext}.\nCreate animated graphics with {gganimate} - an introduction or here.\nInsert logos into {ggplot2} with {ggpath}.\n\nAn overview of extension packages for {ggplot2} can be found here.\nAlso, The R Graph Gallery provides an excellent overview of visualization possibilities with syntax examples for {ggplot2}.\n\nTutorial by Cédric Scherer.\nSession on more intuitive graphics by Cara Thompson.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#purrr",
    "href": "references_translated.html#purrr",
    "title": "Links & Further Reading",
    "section": "Advanced use of lapply()/map() with custom functions",
    "text": "Advanced use of lapply()/map() with custom functions\n\nComprehensive introduction to loops with map() and other functions from {purrr} Hendrik van Broekhuizen.\nModel series: Blog by Tim Tiefenbach on elegant possibilities.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#regex",
    "href": "references_translated.html#regex",
    "title": "Links & Further Reading",
    "section": "regex",
    "text": "regex\nFor working with text variables, regular expressions (regex) are a great help. They allow you to search for specific character sequences in text sections, replace them, etc. Joshua C. Fjelstul’s blog is a good starting point. There’s also a helpful cheatsheet for regex in R and the regex package {stringr}.",
    "crumbs": [
      "Links & Further Reading"
    ]
  },
  {
    "objectID": "references_translated.html#further-resources",
    "href": "references_translated.html#further-resources",
    "title": "Links & Further Reading",
    "section": "Further Resources",
    "text": "Further Resources\n{easystats} offers a collection of packages that make statistical analysis easier and more unified. However, this unification comes with somewhat limited flexibility—it’s a matter of taste and depends on the application. We have used {performance} and {effectsize} from the easystats universe.\nEvent History Models / Event History Modeling / Survival Analysis.",
    "crumbs": [
      "Links & Further Reading"
    ]
  }
]